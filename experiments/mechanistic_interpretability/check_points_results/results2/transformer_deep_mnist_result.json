{
  "experiment_name": "transformer_deep_mnist",
  "measurements": [
    {
      "step": 0,
      "loss": 2.376394271850586,
      "grad_norm": 1.9896682942039445
    },
    {
      "step": 5,
      "loss": 2.260869264602661,
      "grad_norm": 2.2455455874336177
    },
    {
      "step": 10,
      "loss": 2.1316590309143066,
      "grad_norm": 2.108683562800033
    },
    {
      "step": 15,
      "loss": 2.075162410736084,
      "grad_norm": 2.124283658653132
    },
    {
      "step": 20,
      "loss": 1.5224268436431885,
      "grad_norm": 1.7267836986620575
    },
    {
      "step": 25,
      "loss": 1.415400743484497,
      "grad_norm": 1.8150804510100054
    },
    {
      "step": 30,
      "loss": 1.4248206615447998,
      "grad_norm": 1.8864369057128918
    },
    {
      "step": 35,
      "loss": 1.1111481189727783,
      "grad_norm": 1.7159446704146273
    },
    {
      "step": 40,
      "loss": 0.9848721027374268,
      "grad_norm": 2.445033643125069
    },
    {
      "step": 45,
      "loss": 0.9411479234695435,
      "grad_norm": 2.505496256832184
    },
    {
      "step": 50,
      "loss": 0.6342277526855469,
      "grad_norm": 1.2984751820246965
    },
    {
      "step": 55,
      "loss": 0.7386025786399841,
      "grad_norm": 2.592126602379316
    },
    {
      "step": 60,
      "loss": 0.8279199600219727,
      "grad_norm": 1.9387179226500877
    },
    {
      "step": 65,
      "loss": 0.6652038097381592,
      "grad_norm": 2.1653031713061597
    },
    {
      "step": 70,
      "loss": 0.9342477917671204,
      "grad_norm": 2.86979427871606
    },
    {
      "step": 75,
      "loss": 0.829772412776947,
      "grad_norm": 3.040459026935389
    },
    {
      "step": 80,
      "loss": 0.3900119662284851,
      "grad_norm": 1.515241757107437
    },
    {
      "step": 85,
      "loss": 0.712226152420044,
      "grad_norm": 2.6514552335801356
    },
    {
      "step": 90,
      "loss": 0.7817531228065491,
      "grad_norm": 3.1627511366889567
    },
    {
      "step": 95,
      "loss": 0.540289044380188,
      "grad_norm": 2.772221307299296
    },
    {
      "step": 100,
      "loss": 0.5592779517173767,
      "grad_norm": 3.727364820527391
    },
    {
      "step": 105,
      "loss": 0.5898796319961548,
      "grad_norm": 2.253020431839048
    },
    {
      "step": 110,
      "loss": 0.4317049980163574,
      "grad_norm": 2.1693731345374374
    },
    {
      "step": 115,
      "loss": 0.3823257088661194,
      "grad_norm": 1.5104468549361483
    },
    {
      "step": 120,
      "loss": 0.34720832109451294,
      "grad_norm": 1.5395498591907202
    },
    {
      "step": 125,
      "loss": 0.37610334157943726,
      "grad_norm": 1.7562506150847055
    },
    {
      "step": 130,
      "loss": 0.5100836157798767,
      "grad_norm": 2.164793087750579
    },
    {
      "step": 135,
      "loss": 0.42499348521232605,
      "grad_norm": 1.6587846823911057
    },
    {
      "step": 140,
      "loss": 0.6031558513641357,
      "grad_norm": 2.4364435077645235
    },
    {
      "step": 145,
      "loss": 0.45268091559410095,
      "grad_norm": 2.7923220635622847
    },
    {
      "step": 150,
      "loss": 0.33059436082839966,
      "grad_norm": 1.9370151492368826
    },
    {
      "step": 155,
      "loss": 0.4959462881088257,
      "grad_norm": 2.797328914800878
    },
    {
      "step": 160,
      "loss": 0.46181660890579224,
      "grad_norm": 2.253523609579745
    },
    {
      "step": 165,
      "loss": 0.4621885418891907,
      "grad_norm": 2.179793699406774
    },
    {
      "step": 170,
      "loss": 0.3962109386920929,
      "grad_norm": 1.5978622323212957
    },
    {
      "step": 175,
      "loss": 0.5737245678901672,
      "grad_norm": 3.167536504706353
    },
    {
      "step": 180,
      "loss": 0.17477883398532867,
      "grad_norm": 1.3941499618478328
    },
    {
      "step": 185,
      "loss": 0.3531849980354309,
      "grad_norm": 2.0876927198579023
    },
    {
      "step": 190,
      "loss": 0.21677514910697937,
      "grad_norm": 1.6729498448390359
    },
    {
      "step": 195,
      "loss": 0.287625253200531,
      "grad_norm": 1.7673754225775218
    },
    {
      "step": 200,
      "loss": 0.29091784358024597,
      "grad_norm": 1.7057012487044239
    },
    {
      "step": 205,
      "loss": 0.3389540910720825,
      "grad_norm": 2.0078277704066525
    },
    {
      "step": 210,
      "loss": 0.32608562707901,
      "grad_norm": 1.7549863681243547
    },
    {
      "step": 215,
      "loss": 0.22117306292057037,
      "grad_norm": 1.7776768637928948
    },
    {
      "step": 220,
      "loss": 0.5271289348602295,
      "grad_norm": 3.1251060018037085
    },
    {
      "step": 225,
      "loss": 0.48724156618118286,
      "grad_norm": 2.4463219319077414
    },
    {
      "step": 230,
      "loss": 0.12256600707769394,
      "grad_norm": 0.9120554603139708
    },
    {
      "step": 235,
      "loss": 0.3814184069633484,
      "grad_norm": 1.9034635069656822
    },
    {
      "step": 240,
      "loss": 0.4795880615711212,
      "grad_norm": 2.1461337944894856
    },
    {
      "step": 245,
      "loss": 0.3294576108455658,
      "grad_norm": 1.721318856274179
    },
    {
      "step": 250,
      "loss": 0.31618940830230713,
      "grad_norm": 1.6151196790666493
    },
    {
      "step": 255,
      "loss": 0.2865470051765442,
      "grad_norm": 2.1179056477742058
    },
    {
      "step": 260,
      "loss": 0.39881718158721924,
      "grad_norm": 2.0735804089650727
    },
    {
      "step": 265,
      "loss": 0.2314746081829071,
      "grad_norm": 1.8701601675488846
    },
    {
      "step": 270,
      "loss": 0.38242268562316895,
      "grad_norm": 3.2202516312366596
    },
    {
      "step": 275,
      "loss": 0.3891071379184723,
      "grad_norm": 2.4504651317179933
    },
    {
      "step": 280,
      "loss": 0.2774393856525421,
      "grad_norm": 1.919550670287689
    },
    {
      "step": 285,
      "loss": 0.13117916882038116,
      "grad_norm": 1.19001323684123
    },
    {
      "step": 290,
      "loss": 0.2362690567970276,
      "grad_norm": 1.605890498928423
    },
    {
      "step": 295,
      "loss": 0.28600984811782837,
      "grad_norm": 1.4331529126566855
    },
    {
      "step": 300,
      "loss": 0.38117051124572754,
      "grad_norm": 1.9630613687496021
    },
    {
      "step": 305,
      "loss": 0.2686036229133606,
      "grad_norm": 1.4518665165050333
    },
    {
      "step": 310,
      "loss": 0.46102452278137207,
      "grad_norm": 2.448355972118828
    },
    {
      "step": 315,
      "loss": 0.3844223618507385,
      "grad_norm": 2.3166120367189627
    },
    {
      "step": 320,
      "loss": 0.23839855194091797,
      "grad_norm": 1.8926608226373107
    },
    {
      "step": 325,
      "loss": 0.30451497435569763,
      "grad_norm": 2.0140853917090196
    },
    {
      "step": 330,
      "loss": 0.2459489405155182,
      "grad_norm": 1.5832511593859553
    },
    {
      "step": 335,
      "loss": 0.4145810902118683,
      "grad_norm": 2.5098049887470504
    },
    {
      "step": 340,
      "loss": 0.2845975160598755,
      "grad_norm": 1.6094990019960196
    },
    {
      "step": 345,
      "loss": 0.15381799638271332,
      "grad_norm": 1.4044968161558435
    },
    {
      "step": 350,
      "loss": 0.49870020151138306,
      "grad_norm": 2.1990744251086416
    },
    {
      "step": 355,
      "loss": 0.2983078360557556,
      "grad_norm": 1.6221881380623613
    },
    {
      "step": 360,
      "loss": 0.2894282937049866,
      "grad_norm": 1.6330402724791202
    },
    {
      "step": 365,
      "loss": 0.38865071535110474,
      "grad_norm": 1.7515876825251817
    },
    {
      "step": 370,
      "loss": 0.11263569444417953,
      "grad_norm": 1.2868689764724872
    },
    {
      "step": 375,
      "loss": 0.20985083281993866,
      "grad_norm": 1.157827497377737
    },
    {
      "step": 380,
      "loss": 0.3550090789794922,
      "grad_norm": 1.4810842158156345
    },
    {
      "step": 385,
      "loss": 0.5358787775039673,
      "grad_norm": 3.9139232516693343
    },
    {
      "step": 390,
      "loss": 0.2721768021583557,
      "grad_norm": 1.875537237930281
    },
    {
      "step": 395,
      "loss": 0.16713473200798035,
      "grad_norm": 1.706907184335031
    },
    {
      "step": 400,
      "loss": 0.2381419539451599,
      "grad_norm": 1.1911469178586567
    },
    {
      "step": 405,
      "loss": 0.2623829245567322,
      "grad_norm": 1.3801019477095915
    },
    {
      "step": 410,
      "loss": 0.07301653176546097,
      "grad_norm": 0.7983639777346958
    },
    {
      "step": 415,
      "loss": 0.19559721648693085,
      "grad_norm": 1.6220191077335215
    },
    {
      "step": 420,
      "loss": 0.06486278772354126,
      "grad_norm": 0.6462964715184206
    },
    {
      "step": 425,
      "loss": 0.4200270175933838,
      "grad_norm": 2.2467565486951666
    },
    {
      "step": 430,
      "loss": 0.18130052089691162,
      "grad_norm": 1.854113624306176
    },
    {
      "step": 435,
      "loss": 0.35905328392982483,
      "grad_norm": 2.986435931910301
    },
    {
      "step": 440,
      "loss": 0.24240344762802124,
      "grad_norm": 1.2303795786692484
    },
    {
      "step": 445,
      "loss": 0.26451554894447327,
      "grad_norm": 2.0377318468791916
    },
    {
      "step": 450,
      "loss": 0.24555954337120056,
      "grad_norm": 1.7559644532526681
    },
    {
      "step": 455,
      "loss": 0.23988260328769684,
      "grad_norm": 1.5276875636949356
    },
    {
      "step": 460,
      "loss": 0.2827782928943634,
      "grad_norm": 2.2576243044057884
    },
    {
      "step": 465,
      "loss": 0.1349763125181198,
      "grad_norm": 1.2341079599262206
    },
    {
      "step": 470,
      "loss": 0.22876639664173126,
      "grad_norm": 1.1932009665617542
    },
    {
      "step": 475,
      "loss": 0.12795142829418182,
      "grad_norm": 1.0496366525215037
    },
    {
      "step": 480,
      "loss": 0.21753014624118805,
      "grad_norm": 1.1225876352267006
    },
    {
      "step": 485,
      "loss": 0.13968373835086823,
      "grad_norm": 1.382847499166155
    },
    {
      "step": 490,
      "loss": 0.1922922134399414,
      "grad_norm": 1.265268901199127
    },
    {
      "step": 495,
      "loss": 0.21759706735610962,
      "grad_norm": 1.6124496161499393
    },
    {
      "step": 500,
      "loss": 0.11440451443195343,
      "grad_norm": 1.0852352072098326
    },
    {
      "step": 505,
      "loss": 0.3414166569709778,
      "grad_norm": 1.6616504394099851
    },
    {
      "step": 510,
      "loss": 0.3058011531829834,
      "grad_norm": 1.3291446693827673
    },
    {
      "step": 515,
      "loss": 0.20967337489128113,
      "grad_norm": 1.252499223546775
    },
    {
      "step": 520,
      "loss": 0.2898571491241455,
      "grad_norm": 1.8710805654584062
    },
    {
      "step": 525,
      "loss": 0.27230000495910645,
      "grad_norm": 2.0043518859172367
    },
    {
      "step": 530,
      "loss": 0.1259947419166565,
      "grad_norm": 1.5572195797394568
    },
    {
      "step": 535,
      "loss": 0.37325990200042725,
      "grad_norm": 1.9200980348576762
    },
    {
      "step": 540,
      "loss": 0.10715294629335403,
      "grad_norm": 1.5119163645533347
    },
    {
      "step": 545,
      "loss": 0.31505274772644043,
      "grad_norm": 1.7864498891565135
    },
    {
      "step": 550,
      "loss": 0.2514825165271759,
      "grad_norm": 1.9820074988767213
    },
    {
      "step": 555,
      "loss": 0.16188490390777588,
      "grad_norm": 1.279938557162518
    },
    {
      "step": 560,
      "loss": 0.23724234104156494,
      "grad_norm": 1.4520337460225559
    },
    {
      "step": 565,
      "loss": 0.09421294927597046,
      "grad_norm": 1.0086371933286749
    },
    {
      "step": 570,
      "loss": 0.25941506028175354,
      "grad_norm": 1.679323964338541
    },
    {
      "step": 575,
      "loss": 0.13886511325836182,
      "grad_norm": 1.1348462910776305
    },
    {
      "step": 580,
      "loss": 0.2128826081752777,
      "grad_norm": 1.8212123405995724
    },
    {
      "step": 585,
      "loss": 0.208355113863945,
      "grad_norm": 1.6527226996653306
    },
    {
      "step": 590,
      "loss": 0.131400465965271,
      "grad_norm": 1.0461548197330686
    },
    {
      "step": 595,
      "loss": 0.1559140533208847,
      "grad_norm": 1.319832258872281
    },
    {
      "step": 600,
      "loss": 0.28974151611328125,
      "grad_norm": 1.8763163740556796
    },
    {
      "step": 605,
      "loss": 0.37059229612350464,
      "grad_norm": 1.7244087489798827
    },
    {
      "step": 610,
      "loss": 0.24077770113945007,
      "grad_norm": 1.6942003823084963
    },
    {
      "step": 615,
      "loss": 0.14776231348514557,
      "grad_norm": 1.5654040377370615
    },
    {
      "step": 620,
      "loss": 0.19913515448570251,
      "grad_norm": 1.8493855699361401
    },
    {
      "step": 625,
      "loss": 0.22299474477767944,
      "grad_norm": 1.5982676521838202
    },
    {
      "step": 630,
      "loss": 0.2653034031391144,
      "grad_norm": 1.5502168811108992
    },
    {
      "step": 635,
      "loss": 0.1666661947965622,
      "grad_norm": 1.5192861545865401
    },
    {
      "step": 640,
      "loss": 0.21771186590194702,
      "grad_norm": 2.21858017378423
    },
    {
      "step": 645,
      "loss": 0.21024999022483826,
      "grad_norm": 1.49836698377438
    },
    {
      "step": 650,
      "loss": 0.1836824119091034,
      "grad_norm": 1.2760851267638886
    },
    {
      "step": 655,
      "loss": 0.19994743168354034,
      "grad_norm": 1.8730964269533021
    },
    {
      "step": 660,
      "loss": 0.19739791750907898,
      "grad_norm": 2.413731890046659
    },
    {
      "step": 665,
      "loss": 0.32530146837234497,
      "grad_norm": 1.9982495082629965
    },
    {
      "step": 670,
      "loss": 0.22648492455482483,
      "grad_norm": 1.4499270373169397
    },
    {
      "step": 675,
      "loss": 0.21470370888710022,
      "grad_norm": 0.820365623357472
    },
    {
      "step": 680,
      "loss": 0.12341663986444473,
      "grad_norm": 1.6811989048990423
    },
    {
      "step": 685,
      "loss": 0.33664706349372864,
      "grad_norm": 2.3151655079567215
    },
    {
      "step": 690,
      "loss": 0.3029336631298065,
      "grad_norm": 1.981130717029654
    },
    {
      "step": 695,
      "loss": 0.4955683648586273,
      "grad_norm": 2.5622144414112134
    },
    {
      "step": 700,
      "loss": 0.09303343296051025,
      "grad_norm": 0.976948793075148
    },
    {
      "step": 705,
      "loss": 0.12669417262077332,
      "grad_norm": 1.02604599277436
    },
    {
      "step": 710,
      "loss": 0.36840587854385376,
      "grad_norm": 1.9674621304275828
    },
    {
      "step": 715,
      "loss": 0.24211987853050232,
      "grad_norm": 1.6648445092859177
    },
    {
      "step": 720,
      "loss": 0.23008164763450623,
      "grad_norm": 1.6958746452689752
    },
    {
      "step": 725,
      "loss": 0.18453572690486908,
      "grad_norm": 1.5467877566180113
    },
    {
      "step": 730,
      "loss": 0.1094757467508316,
      "grad_norm": 0.8740363125163554
    },
    {
      "step": 735,
      "loss": 0.24905475974082947,
      "grad_norm": 1.5019756554656207
    },
    {
      "step": 740,
      "loss": 0.13545747101306915,
      "grad_norm": 1.703386486237212
    },
    {
      "step": 745,
      "loss": 0.3496081531047821,
      "grad_norm": 2.887737164982149
    },
    {
      "step": 750,
      "loss": 0.2052059918642044,
      "grad_norm": 2.325623683071215
    },
    {
      "step": 755,
      "loss": 0.3068845868110657,
      "grad_norm": 1.8325708216087544
    },
    {
      "step": 760,
      "loss": 0.15712374448776245,
      "grad_norm": 1.2886434538180132
    },
    {
      "step": 765,
      "loss": 0.22953978180885315,
      "grad_norm": 1.5159878889883396
    },
    {
      "step": 770,
      "loss": 0.20236605405807495,
      "grad_norm": 1.7169254776769802
    },
    {
      "step": 775,
      "loss": 0.2215186208486557,
      "grad_norm": 1.8090973770461118
    },
    {
      "step": 780,
      "loss": 0.2449081540107727,
      "grad_norm": 1.7125902947054168
    },
    {
      "step": 785,
      "loss": 0.18544268608093262,
      "grad_norm": 1.6641376266517391
    },
    {
      "step": 790,
      "loss": 0.18182246387004852,
      "grad_norm": 1.5970487045373885
    },
    {
      "step": 795,
      "loss": 0.1559843271970749,
      "grad_norm": 1.7180525623849714
    },
    {
      "step": 800,
      "loss": 0.1054505929350853,
      "grad_norm": 0.7728016603529771
    },
    {
      "step": 805,
      "loss": 0.2488669455051422,
      "grad_norm": 2.1160171651504465
    },
    {
      "step": 810,
      "loss": 0.2382361739873886,
      "grad_norm": 2.2747151890296666
    },
    {
      "step": 815,
      "loss": 0.3043047785758972,
      "grad_norm": 1.9604774740082718
    },
    {
      "step": 820,
      "loss": 0.3331022262573242,
      "grad_norm": 2.385854517401105
    },
    {
      "step": 825,
      "loss": 0.10054058581590652,
      "grad_norm": 1.2368625631822658
    },
    {
      "step": 830,
      "loss": 0.15544438362121582,
      "grad_norm": 1.269536812584243
    },
    {
      "step": 835,
      "loss": 0.21714970469474792,
      "grad_norm": 1.3780423742367562
    },
    {
      "step": 840,
      "loss": 0.3259466886520386,
      "grad_norm": 2.4093253514117805
    },
    {
      "step": 845,
      "loss": 0.21306297183036804,
      "grad_norm": 3.4680177131801515
    },
    {
      "step": 850,
      "loss": 0.13339829444885254,
      "grad_norm": 1.443856984086992
    },
    {
      "step": 855,
      "loss": 0.14588171243667603,
      "grad_norm": 1.6097792440608996
    },
    {
      "step": 860,
      "loss": 0.2118271291255951,
      "grad_norm": 1.481500924015893
    },
    {
      "step": 865,
      "loss": 0.2637665867805481,
      "grad_norm": 2.3073232947833793
    },
    {
      "step": 870,
      "loss": 0.18597730994224548,
      "grad_norm": 1.8125818875092454
    },
    {
      "step": 875,
      "loss": 0.23984511196613312,
      "grad_norm": 1.5675315597696742
    },
    {
      "step": 880,
      "loss": 0.11043539643287659,
      "grad_norm": 1.2627529506201827
    },
    {
      "step": 885,
      "loss": 0.3094732165336609,
      "grad_norm": 1.8245653690973465
    },
    {
      "step": 890,
      "loss": 0.29896730184555054,
      "grad_norm": 1.3923202347061747
    },
    {
      "step": 895,
      "loss": 0.2222980558872223,
      "grad_norm": 1.7124803770864012
    },
    {
      "step": 900,
      "loss": 0.23217344284057617,
      "grad_norm": 1.441201668594976
    },
    {
      "step": 905,
      "loss": 0.1311802715063095,
      "grad_norm": 1.2693187325774324
    },
    {
      "step": 910,
      "loss": 0.07025665789842606,
      "grad_norm": 0.8080585684676277
    },
    {
      "step": 915,
      "loss": 0.14027753472328186,
      "grad_norm": 1.5084081834133711
    },
    {
      "step": 920,
      "loss": 0.41418343782424927,
      "grad_norm": 2.228222844840536
    },
    {
      "step": 925,
      "loss": 0.264488160610199,
      "grad_norm": 1.4259194813888743
    },
    {
      "step": 930,
      "loss": 0.19814275205135345,
      "grad_norm": 1.0556335641002348
    },
    {
      "step": 935,
      "loss": 0.1481999158859253,
      "grad_norm": 0.8093336090228036
    },
    {
      "step": 940,
      "loss": 0.09277984499931335,
      "grad_norm": 0.8780167195187867
    },
    {
      "step": 945,
      "loss": 0.24300462007522583,
      "grad_norm": 1.5171425029127226
    },
    {
      "step": 950,
      "loss": 0.3374066948890686,
      "grad_norm": 1.4010725499437224
    },
    {
      "step": 955,
      "loss": 0.2749336063861847,
      "grad_norm": 1.5861994905503114
    },
    {
      "step": 960,
      "loss": 0.13112764060497284,
      "grad_norm": 1.0746678074688123
    },
    {
      "step": 965,
      "loss": 0.08998064696788788,
      "grad_norm": 1.233735684498716
    },
    {
      "step": 970,
      "loss": 0.18139050900936127,
      "grad_norm": 1.6730485720063926
    },
    {
      "step": 975,
      "loss": 0.09020736068487167,
      "grad_norm": 1.0762243327252998
    },
    {
      "step": 980,
      "loss": 0.2647121250629425,
      "grad_norm": 1.6361472695517254
    },
    {
      "step": 985,
      "loss": 0.3195456564426422,
      "grad_norm": 2.049286584114259
    },
    {
      "step": 990,
      "loss": 0.20664101839065552,
      "grad_norm": 1.425109807910535
    },
    {
      "step": 995,
      "loss": 0.3248651623725891,
      "grad_norm": 2.1997341799555286
    },
    {
      "step": 1000,
      "loss": 0.31249552965164185,
      "grad_norm": 1.439494330323119
    },
    {
      "step": 1005,
      "loss": 0.3213100731372833,
      "grad_norm": 2.4133180041713698
    },
    {
      "step": 1010,
      "loss": 0.3439667224884033,
      "grad_norm": 1.8282571567279637
    },
    {
      "step": 1015,
      "loss": 0.17287224531173706,
      "grad_norm": 1.0364413956591767
    },
    {
      "step": 1020,
      "loss": 0.20881831645965576,
      "grad_norm": 1.232044645159125
    },
    {
      "step": 1025,
      "loss": 0.17335152626037598,
      "grad_norm": 1.1449672302969918
    },
    {
      "step": 1030,
      "loss": 0.29530566930770874,
      "grad_norm": 1.3687760749841251
    },
    {
      "step": 1035,
      "loss": 0.1289478838443756,
      "grad_norm": 1.0834288310131872
    },
    {
      "step": 1040,
      "loss": 0.14529934525489807,
      "grad_norm": 0.9268222594253904
    },
    {
      "step": 1045,
      "loss": 0.09169001877307892,
      "grad_norm": 1.474749422554212
    },
    {
      "step": 1050,
      "loss": 0.05013631284236908,
      "grad_norm": 0.7577056241474222
    },
    {
      "step": 1055,
      "loss": 0.16307225823402405,
      "grad_norm": 1.7309154459840046
    },
    {
      "step": 1060,
      "loss": 0.11237389594316483,
      "grad_norm": 1.2213035185484067
    },
    {
      "step": 1065,
      "loss": 0.3392675518989563,
      "grad_norm": 2.1097194205664116
    },
    {
      "step": 1070,
      "loss": 0.31957343220710754,
      "grad_norm": 1.6740166653191646
    },
    {
      "step": 1075,
      "loss": 0.11194761097431183,
      "grad_norm": 0.8029097319441327
    },
    {
      "step": 1080,
      "loss": 0.16006669402122498,
      "grad_norm": 1.024974081202481
    },
    {
      "step": 1085,
      "loss": 0.22106212377548218,
      "grad_norm": 1.7199495785665757
    },
    {
      "step": 1090,
      "loss": 0.11695665866136551,
      "grad_norm": 1.4958387989411874
    },
    {
      "step": 1095,
      "loss": 0.08665324002504349,
      "grad_norm": 1.271470998686318
    },
    {
      "step": 1100,
      "loss": 0.14858898520469666,
      "grad_norm": 1.6079463160483602
    },
    {
      "step": 1105,
      "loss": 0.09002676606178284,
      "grad_norm": 0.9887400150128528
    },
    {
      "step": 1110,
      "loss": 0.1272650510072708,
      "grad_norm": 1.510887058441154
    },
    {
      "step": 1115,
      "loss": 0.16995388269424438,
      "grad_norm": 1.124679444808094
    },
    {
      "step": 1120,
      "loss": 0.15140663087368011,
      "grad_norm": 1.3414080972334652
    },
    {
      "step": 1125,
      "loss": 0.2833572030067444,
      "grad_norm": 2.1384836405976055
    },
    {
      "step": 1130,
      "loss": 0.21587789058685303,
      "grad_norm": 1.8294156325261848
    },
    {
      "step": 1135,
      "loss": 0.22657716274261475,
      "grad_norm": 1.9487948375295847
    },
    {
      "step": 1140,
      "loss": 0.18268267810344696,
      "grad_norm": 1.5567777184687361
    },
    {
      "step": 1145,
      "loss": 0.21040183305740356,
      "grad_norm": 3.527238627266349
    },
    {
      "step": 1150,
      "loss": 0.17265158891677856,
      "grad_norm": 1.2281718885700283
    },
    {
      "step": 1155,
      "loss": 0.5387535095214844,
      "grad_norm": 2.435206538464593
    },
    {
      "step": 1160,
      "loss": 0.19238638877868652,
      "grad_norm": 1.89350452920994
    },
    {
      "step": 1165,
      "loss": 0.07830250263214111,
      "grad_norm": 0.9857140434123984
    },
    {
      "step": 1170,
      "loss": 0.22434425354003906,
      "grad_norm": 1.1269953470515295
    },
    {
      "step": 1175,
      "loss": 0.029153386130928993,
      "grad_norm": 0.4075009283129814
    },
    {
      "step": 1180,
      "loss": 0.32284867763519287,
      "grad_norm": 1.9328320070148868
    },
    {
      "step": 1185,
      "loss": 0.13201475143432617,
      "grad_norm": 1.213567004599543
    },
    {
      "step": 1190,
      "loss": 0.18605422973632812,
      "grad_norm": 1.6609709044463097
    },
    {
      "step": 1195,
      "loss": 0.08031438291072845,
      "grad_norm": 1.109125306898462
    },
    {
      "step": 1200,
      "loss": 0.04844480752944946,
      "grad_norm": 0.6606997836988222
    },
    {
      "step": 1205,
      "loss": 0.08213840425014496,
      "grad_norm": 0.9843484436540132
    },
    {
      "step": 1210,
      "loss": 0.16821902990341187,
      "grad_norm": 1.2037645609087653
    },
    {
      "step": 1215,
      "loss": 0.2537912428379059,
      "grad_norm": 1.6439886998087394
    },
    {
      "step": 1220,
      "loss": 0.22086790204048157,
      "grad_norm": 1.6931853692718815
    },
    {
      "step": 1225,
      "loss": 0.309081494808197,
      "grad_norm": 1.7583245367277907
    },
    {
      "step": 1230,
      "loss": 0.42952960729599,
      "grad_norm": 2.186626843488518
    },
    {
      "step": 1235,
      "loss": 0.08357145637273788,
      "grad_norm": 1.294168294585865
    },
    {
      "step": 1240,
      "loss": 0.06358478218317032,
      "grad_norm": 0.9333509110253487
    },
    {
      "step": 1245,
      "loss": 0.3065609335899353,
      "grad_norm": 2.007740004693461
    },
    {
      "step": 1250,
      "loss": 0.1191151887178421,
      "grad_norm": 0.9603365166466753
    },
    {
      "step": 1255,
      "loss": 0.09908518195152283,
      "grad_norm": 1.235428459171011
    },
    {
      "step": 1260,
      "loss": 0.21026284992694855,
      "grad_norm": 1.2863495729658307
    },
    {
      "step": 1265,
      "loss": 0.3922828435897827,
      "grad_norm": 2.619187614371619
    },
    {
      "step": 1270,
      "loss": 0.11857046186923981,
      "grad_norm": 1.2260472043495982
    },
    {
      "step": 1275,
      "loss": 0.22076119482517242,
      "grad_norm": 1.7250050044792236
    },
    {
      "step": 1280,
      "loss": 0.3386474847793579,
      "grad_norm": 1.9437220785073017
    },
    {
      "step": 1285,
      "loss": 0.1483672708272934,
      "grad_norm": 1.566130284435279
    },
    {
      "step": 1290,
      "loss": 0.19563616812229156,
      "grad_norm": 2.016298147841275
    },
    {
      "step": 1295,
      "loss": 0.26697221398353577,
      "grad_norm": 2.4002463279227495
    },
    {
      "step": 1300,
      "loss": 0.20105862617492676,
      "grad_norm": 1.5487608466707246
    },
    {
      "step": 1305,
      "loss": 0.1841181367635727,
      "grad_norm": 0.870261002322304
    },
    {
      "step": 1310,
      "loss": 0.23662221431732178,
      "grad_norm": 1.6054241064145622
    },
    {
      "step": 1315,
      "loss": 0.248286172747612,
      "grad_norm": 1.4866652766314534
    },
    {
      "step": 1320,
      "loss": 0.10821259766817093,
      "grad_norm": 1.5543577663420702
    },
    {
      "step": 1325,
      "loss": 0.03978203982114792,
      "grad_norm": 0.45958859410085084
    },
    {
      "step": 1330,
      "loss": 0.17848964035511017,
      "grad_norm": 1.7196947567535787
    },
    {
      "step": 1335,
      "loss": 0.25241976976394653,
      "grad_norm": 1.7997068091049162
    },
    {
      "step": 1340,
      "loss": 0.22067421674728394,
      "grad_norm": 1.6361873583279216
    },
    {
      "step": 1345,
      "loss": 0.14059904217720032,
      "grad_norm": 1.6213423112441574
    },
    {
      "step": 1350,
      "loss": 0.2625851631164551,
      "grad_norm": 1.3072278383735167
    },
    {
      "step": 1355,
      "loss": 0.10998484492301941,
      "grad_norm": 1.1391511699425692
    },
    {
      "step": 1360,
      "loss": 0.2549532949924469,
      "grad_norm": 1.3208557223522528
    },
    {
      "step": 1365,
      "loss": 0.0784582570195198,
      "grad_norm": 1.4587465340433914
    },
    {
      "step": 1370,
      "loss": 0.13378967344760895,
      "grad_norm": 1.4919376738384134
    },
    {
      "step": 1375,
      "loss": 0.128573477268219,
      "grad_norm": 1.4912319514068206
    },
    {
      "step": 1380,
      "loss": 0.1180291399359703,
      "grad_norm": 0.9138509071002892
    },
    {
      "step": 1385,
      "loss": 0.29489368200302124,
      "grad_norm": 1.9060531667941372
    },
    {
      "step": 1390,
      "loss": 0.146880105137825,
      "grad_norm": 1.2031974593500177
    },
    {
      "step": 1395,
      "loss": 0.19089093804359436,
      "grad_norm": 1.8531262138336169
    },
    {
      "step": 1400,
      "loss": 0.14735646545886993,
      "grad_norm": 1.316244915946701
    },
    {
      "step": 1405,
      "loss": 0.12470321357250214,
      "grad_norm": 1.6158567973800941
    },
    {
      "step": 1410,
      "loss": 0.27815771102905273,
      "grad_norm": 1.791352271423331
    },
    {
      "step": 1415,
      "loss": 0.04443158581852913,
      "grad_norm": 0.8628976740039636
    },
    {
      "step": 1420,
      "loss": 0.15876233577728271,
      "grad_norm": 1.3452585747583365
    },
    {
      "step": 1425,
      "loss": 0.18151932954788208,
      "grad_norm": 1.6084965121311896
    },
    {
      "step": 1430,
      "loss": 0.21481618285179138,
      "grad_norm": 1.4734960782333606
    },
    {
      "step": 1435,
      "loss": 0.35358595848083496,
      "grad_norm": 2.3263830713590665
    },
    {
      "step": 1440,
      "loss": 0.2324945479631424,
      "grad_norm": 1.4631667371681543
    },
    {
      "step": 1445,
      "loss": 0.09257160872220993,
      "grad_norm": 1.077073054120163
    },
    {
      "step": 1450,
      "loss": 0.08545173704624176,
      "grad_norm": 1.3066983475774852
    },
    {
      "step": 1455,
      "loss": 0.07735982537269592,
      "grad_norm": 1.1977176700777603
    },
    {
      "step": 1460,
      "loss": 0.11669168621301651,
      "grad_norm": 1.4828071605913584
    },
    {
      "step": 1465,
      "loss": 0.10413500666618347,
      "grad_norm": 1.126226787580312
    },
    {
      "step": 1470,
      "loss": 0.15308770537376404,
      "grad_norm": 0.8976015535584391
    },
    {
      "step": 1475,
      "loss": 0.03626265376806259,
      "grad_norm": 0.6277028322304333
    },
    {
      "step": 1480,
      "loss": 0.15138539671897888,
      "grad_norm": 1.5460445060468155
    },
    {
      "step": 1485,
      "loss": 0.1487259864807129,
      "grad_norm": 1.866879556339342
    },
    {
      "step": 1490,
      "loss": 0.06112584099173546,
      "grad_norm": 0.6371991350277356
    },
    {
      "step": 1495,
      "loss": 0.18752381205558777,
      "grad_norm": 1.5424446296467749
    },
    {
      "step": 1500,
      "loss": 0.1999790370464325,
      "grad_norm": 1.3694226434439303
    },
    {
      "step": 1505,
      "loss": 0.4089033007621765,
      "grad_norm": 2.1076504692557583
    },
    {
      "step": 1510,
      "loss": 0.25522786378860474,
      "grad_norm": 1.684272722485934
    },
    {
      "step": 1515,
      "loss": 0.09465233236551285,
      "grad_norm": 1.0085239021525851
    },
    {
      "step": 1520,
      "loss": 0.18536001443862915,
      "grad_norm": 1.6316251357070826
    },
    {
      "step": 1525,
      "loss": 0.08296965062618256,
      "grad_norm": 1.1832283621224566
    },
    {
      "step": 1530,
      "loss": 0.05881790071725845,
      "grad_norm": 0.5838450157342611
    },
    {
      "step": 1535,
      "loss": 0.09396238625049591,
      "grad_norm": 1.206235898457292
    },
    {
      "step": 1540,
      "loss": 0.11169026792049408,
      "grad_norm": 2.151778430236211
    },
    {
      "step": 1545,
      "loss": 0.1006355881690979,
      "grad_norm": 1.3241582404616261
    },
    {
      "step": 1550,
      "loss": 0.2551368474960327,
      "grad_norm": 1.63455106131513
    },
    {
      "step": 1555,
      "loss": 0.06704214960336685,
      "grad_norm": 1.5022108049086549
    },
    {
      "step": 1560,
      "loss": 0.18447314202785492,
      "grad_norm": 2.053113010664557
    },
    {
      "step": 1565,
      "loss": 0.09279586374759674,
      "grad_norm": 1.39741969339775
    },
    {
      "step": 1570,
      "loss": 0.17721351981163025,
      "grad_norm": 1.6782483680608495
    },
    {
      "step": 1575,
      "loss": 0.026878364384174347,
      "grad_norm": 0.44245817555748923
    },
    {
      "step": 1580,
      "loss": 0.2548460364341736,
      "grad_norm": 1.8150006288805927
    },
    {
      "step": 1585,
      "loss": 0.2265203595161438,
      "grad_norm": 1.5669603202163493
    },
    {
      "step": 1590,
      "loss": 0.11045791208744049,
      "grad_norm": 1.0485023852918138
    },
    {
      "step": 1595,
      "loss": 0.1470089554786682,
      "grad_norm": 1.4102886662855778
    },
    {
      "step": 1600,
      "loss": 0.1592216193675995,
      "grad_norm": 1.293101157377738
    },
    {
      "step": 1605,
      "loss": 0.20466046035289764,
      "grad_norm": 1.3569277147659833
    },
    {
      "step": 1610,
      "loss": 0.09306178241968155,
      "grad_norm": 1.0588634825375343
    },
    {
      "step": 1615,
      "loss": 0.1466672122478485,
      "grad_norm": 1.530045185720087
    },
    {
      "step": 1620,
      "loss": 0.018723053857684135,
      "grad_norm": 0.30118705103573545
    },
    {
      "step": 1625,
      "loss": 0.21159741282463074,
      "grad_norm": 1.7688277680256872
    },
    {
      "step": 1630,
      "loss": 0.20010635256767273,
      "grad_norm": 2.0299047806160813
    },
    {
      "step": 1635,
      "loss": 0.09880904853343964,
      "grad_norm": 0.8634395919984198
    },
    {
      "step": 1640,
      "loss": 0.024686399847269058,
      "grad_norm": 0.4590914011319565
    },
    {
      "step": 1645,
      "loss": 0.1762315183877945,
      "grad_norm": 2.513663508769629
    },
    {
      "step": 1650,
      "loss": 0.046683818101882935,
      "grad_norm": 0.8762220116760902
    },
    {
      "step": 1655,
      "loss": 0.09456094354391098,
      "grad_norm": 1.1407802321917824
    },
    {
      "step": 1660,
      "loss": 0.067829430103302,
      "grad_norm": 0.7439952728845426
    },
    {
      "step": 1665,
      "loss": 0.10510410368442535,
      "grad_norm": 0.9107941959104212
    },
    {
      "step": 1670,
      "loss": 0.11134855449199677,
      "grad_norm": 1.3240533967989945
    },
    {
      "step": 1675,
      "loss": 0.12797467410564423,
      "grad_norm": 1.147718824828023
    },
    {
      "step": 1680,
      "loss": 0.2058050036430359,
      "grad_norm": 1.53699148621226
    },
    {
      "step": 1685,
      "loss": 0.11261919140815735,
      "grad_norm": 1.2099555948507341
    },
    {
      "step": 1690,
      "loss": 0.13032278418540955,
      "grad_norm": 1.5994262992777875
    },
    {
      "step": 1695,
      "loss": 0.3319384455680847,
      "grad_norm": 1.6263236798465193
    },
    {
      "step": 1700,
      "loss": 0.15236163139343262,
      "grad_norm": 1.8847546921463654
    },
    {
      "step": 1705,
      "loss": 0.1801164150238037,
      "grad_norm": 1.6385372905803974
    },
    {
      "step": 1710,
      "loss": 0.16939258575439453,
      "grad_norm": 1.3758115612353197
    },
    {
      "step": 1715,
      "loss": 0.1938062608242035,
      "grad_norm": 1.7261580803476027
    },
    {
      "step": 1720,
      "loss": 0.13058426976203918,
      "grad_norm": 1.4357110362839536
    },
    {
      "step": 1725,
      "loss": 0.22114941477775574,
      "grad_norm": 1.3415403547889986
    },
    {
      "step": 1730,
      "loss": 0.11579733341932297,
      "grad_norm": 1.4516610649915538
    },
    {
      "step": 1735,
      "loss": 0.14516983926296234,
      "grad_norm": 1.3319884013119803
    },
    {
      "step": 1740,
      "loss": 0.1851864755153656,
      "grad_norm": 1.8336490201151954
    },
    {
      "step": 1745,
      "loss": 0.1350662261247635,
      "grad_norm": 1.5943640167626218
    },
    {
      "step": 1750,
      "loss": 0.26234954595565796,
      "grad_norm": 1.3563658909596137
    },
    {
      "step": 1755,
      "loss": 0.08880910277366638,
      "grad_norm": 1.624542878753034
    },
    {
      "step": 1760,
      "loss": 0.12545830011367798,
      "grad_norm": 1.0414526089127056
    },
    {
      "step": 1765,
      "loss": 0.18933169543743134,
      "grad_norm": 1.1382181876553037
    },
    {
      "step": 1770,
      "loss": 0.22543980181217194,
      "grad_norm": 1.7538599554402257
    },
    {
      "step": 1775,
      "loss": 0.08306924998760223,
      "grad_norm": 0.6766820946735671
    },
    {
      "step": 1780,
      "loss": 0.13909953832626343,
      "grad_norm": 1.7629508733791892
    },
    {
      "step": 1785,
      "loss": 0.3964674174785614,
      "grad_norm": 1.6112417240838521
    },
    {
      "step": 1790,
      "loss": 0.05764884129166603,
      "grad_norm": 0.5835046701094292
    },
    {
      "step": 1795,
      "loss": 0.17585310339927673,
      "grad_norm": 1.8114650759057174
    },
    {
      "step": 1800,
      "loss": 0.42980095744132996,
      "grad_norm": 2.126132912243998
    },
    {
      "step": 1805,
      "loss": 0.3226034641265869,
      "grad_norm": 1.9503545483494604
    },
    {
      "step": 1810,
      "loss": 0.13652503490447998,
      "grad_norm": 1.4555062633565452
    },
    {
      "step": 1815,
      "loss": 0.083737812936306,
      "grad_norm": 1.4256178783908067
    },
    {
      "step": 1820,
      "loss": 0.1890738606452942,
      "grad_norm": 1.3530275801769351
    },
    {
      "step": 1825,
      "loss": 0.13574615120887756,
      "grad_norm": 1.1513552512485574
    },
    {
      "step": 1830,
      "loss": 0.11247804760932922,
      "grad_norm": 1.1591555963032294
    },
    {
      "step": 1835,
      "loss": 0.2415526807308197,
      "grad_norm": 1.6124442691544112
    },
    {
      "step": 1840,
      "loss": 0.2558644711971283,
      "grad_norm": 1.8261477017921213
    },
    {
      "step": 1845,
      "loss": 0.2254517525434494,
      "grad_norm": 1.08117378355535
    },
    {
      "step": 1850,
      "loss": 0.1056579202413559,
      "grad_norm": 1.4862584796002736
    },
    {
      "step": 1855,
      "loss": 0.28885552287101746,
      "grad_norm": 1.5507546317630927
    },
    {
      "step": 1860,
      "loss": 0.17947842180728912,
      "grad_norm": 0.8380748791730938
    },
    {
      "step": 1865,
      "loss": 0.08424577116966248,
      "grad_norm": 1.1083697470337288
    },
    {
      "step": 1870,
      "loss": 0.30751368403434753,
      "grad_norm": 1.5481088396650071
    },
    {
      "step": 1875,
      "loss": 0.09855329990386963,
      "grad_norm": 1.8951353005858835
    },
    {
      "step": 1880,
      "loss": 0.20717717707157135,
      "grad_norm": 1.4007717934090451
    },
    {
      "step": 1885,
      "loss": 0.3582334518432617,
      "grad_norm": 1.7379975655947182
    },
    {
      "step": 1890,
      "loss": 0.1429206132888794,
      "grad_norm": 1.0122560714152242
    },
    {
      "step": 1895,
      "loss": 0.1840880811214447,
      "grad_norm": 1.9769441119196152
    },
    {
      "step": 1900,
      "loss": 0.15515868365764618,
      "grad_norm": 1.7858505939100777
    },
    {
      "step": 1905,
      "loss": 0.17638546228408813,
      "grad_norm": 1.6919750205170956
    },
    {
      "step": 1910,
      "loss": 0.20718348026275635,
      "grad_norm": 1.5910609541765142
    },
    {
      "step": 1915,
      "loss": 0.22104141116142273,
      "grad_norm": 2.0949936587778284
    },
    {
      "step": 1920,
      "loss": 0.05431528389453888,
      "grad_norm": 0.8311088879283796
    },
    {
      "step": 1925,
      "loss": 0.07921650260686874,
      "grad_norm": 0.9932138527502204
    },
    {
      "step": 1930,
      "loss": 0.06129999831318855,
      "grad_norm": 0.9411554071686318
    },
    {
      "step": 1935,
      "loss": 0.2528340816497803,
      "grad_norm": 1.244265267438418
    },
    {
      "step": 1940,
      "loss": 0.18243221938610077,
      "grad_norm": 1.8274346031399624
    },
    {
      "step": 1945,
      "loss": 0.31462109088897705,
      "grad_norm": 1.9746723758592153
    },
    {
      "step": 1950,
      "loss": 0.14353612065315247,
      "grad_norm": 1.2395624643581162
    },
    {
      "step": 1955,
      "loss": 0.08040661364793777,
      "grad_norm": 1.09027307980566
    },
    {
      "step": 1960,
      "loss": 0.06579826772212982,
      "grad_norm": 0.9413114996842443
    },
    {
      "step": 1965,
      "loss": 0.08499225229024887,
      "grad_norm": 1.0106857725222336
    },
    {
      "step": 1970,
      "loss": 0.04700322821736336,
      "grad_norm": 1.0084587790943789
    },
    {
      "step": 1975,
      "loss": 0.16836370527744293,
      "grad_norm": 1.3565601937058436
    },
    {
      "step": 1980,
      "loss": 0.05419620871543884,
      "grad_norm": 0.8838662852611525
    },
    {
      "step": 1985,
      "loss": 0.23762890696525574,
      "grad_norm": 1.7839762960195549
    },
    {
      "step": 1990,
      "loss": 0.1290348470211029,
      "grad_norm": 1.61705217105288
    },
    {
      "step": 1995,
      "loss": 0.23455002903938293,
      "grad_norm": 1.558518735138775
    }
  ],
  "final_accuracy": 0.9647,
  "total_steps": 2000,
  "checkpoint_steps": [
    100,
    1000,
    2000
  ],
  "elapsed_time": 57.839035749435425
}