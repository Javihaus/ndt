{
  "total_time": 130.39802312850952,
  "num_experiments": 3,
  "experiments": [
    {
      "experiment_name": "transformer_deep_mnist",
      "measurements": [
        {
          "step": 0,
          "loss": 2.376394271850586,
          "grad_norm": 1.9896682942039445
        },
        {
          "step": 5,
          "loss": 2.260869264602661,
          "grad_norm": 2.2455455874336177
        },
        {
          "step": 10,
          "loss": 2.1316590309143066,
          "grad_norm": 2.108683562800033
        },
        {
          "step": 15,
          "loss": 2.075162410736084,
          "grad_norm": 2.124283658653132
        },
        {
          "step": 20,
          "loss": 1.5224268436431885,
          "grad_norm": 1.7267836986620575
        },
        {
          "step": 25,
          "loss": 1.415400743484497,
          "grad_norm": 1.8150804510100054
        },
        {
          "step": 30,
          "loss": 1.4248206615447998,
          "grad_norm": 1.8864369057128918
        },
        {
          "step": 35,
          "loss": 1.1111481189727783,
          "grad_norm": 1.7159446704146273
        },
        {
          "step": 40,
          "loss": 0.9848721027374268,
          "grad_norm": 2.445033643125069
        },
        {
          "step": 45,
          "loss": 0.9411479234695435,
          "grad_norm": 2.505496256832184
        },
        {
          "step": 50,
          "loss": 0.6342277526855469,
          "grad_norm": 1.2984751820246965
        },
        {
          "step": 55,
          "loss": 0.7386025786399841,
          "grad_norm": 2.592126602379316
        },
        {
          "step": 60,
          "loss": 0.8279199600219727,
          "grad_norm": 1.9387179226500877
        },
        {
          "step": 65,
          "loss": 0.6652038097381592,
          "grad_norm": 2.1653031713061597
        },
        {
          "step": 70,
          "loss": 0.9342477917671204,
          "grad_norm": 2.86979427871606
        },
        {
          "step": 75,
          "loss": 0.829772412776947,
          "grad_norm": 3.040459026935389
        },
        {
          "step": 80,
          "loss": 0.3900119662284851,
          "grad_norm": 1.515241757107437
        },
        {
          "step": 85,
          "loss": 0.712226152420044,
          "grad_norm": 2.6514552335801356
        },
        {
          "step": 90,
          "loss": 0.7817531228065491,
          "grad_norm": 3.1627511366889567
        },
        {
          "step": 95,
          "loss": 0.540289044380188,
          "grad_norm": 2.772221307299296
        },
        {
          "step": 100,
          "loss": 0.5592779517173767,
          "grad_norm": 3.727364820527391
        },
        {
          "step": 105,
          "loss": 0.5898796319961548,
          "grad_norm": 2.253020431839048
        },
        {
          "step": 110,
          "loss": 0.4317049980163574,
          "grad_norm": 2.1693731345374374
        },
        {
          "step": 115,
          "loss": 0.3823257088661194,
          "grad_norm": 1.5104468549361483
        },
        {
          "step": 120,
          "loss": 0.34720832109451294,
          "grad_norm": 1.5395498591907202
        },
        {
          "step": 125,
          "loss": 0.37610334157943726,
          "grad_norm": 1.7562506150847055
        },
        {
          "step": 130,
          "loss": 0.5100836157798767,
          "grad_norm": 2.164793087750579
        },
        {
          "step": 135,
          "loss": 0.42499348521232605,
          "grad_norm": 1.6587846823911057
        },
        {
          "step": 140,
          "loss": 0.6031558513641357,
          "grad_norm": 2.4364435077645235
        },
        {
          "step": 145,
          "loss": 0.45268091559410095,
          "grad_norm": 2.7923220635622847
        },
        {
          "step": 150,
          "loss": 0.33059436082839966,
          "grad_norm": 1.9370151492368826
        },
        {
          "step": 155,
          "loss": 0.4959462881088257,
          "grad_norm": 2.797328914800878
        },
        {
          "step": 160,
          "loss": 0.46181660890579224,
          "grad_norm": 2.253523609579745
        },
        {
          "step": 165,
          "loss": 0.4621885418891907,
          "grad_norm": 2.179793699406774
        },
        {
          "step": 170,
          "loss": 0.3962109386920929,
          "grad_norm": 1.5978622323212957
        },
        {
          "step": 175,
          "loss": 0.5737245678901672,
          "grad_norm": 3.167536504706353
        },
        {
          "step": 180,
          "loss": 0.17477883398532867,
          "grad_norm": 1.3941499618478328
        },
        {
          "step": 185,
          "loss": 0.3531849980354309,
          "grad_norm": 2.0876927198579023
        },
        {
          "step": 190,
          "loss": 0.21677514910697937,
          "grad_norm": 1.6729498448390359
        },
        {
          "step": 195,
          "loss": 0.287625253200531,
          "grad_norm": 1.7673754225775218
        },
        {
          "step": 200,
          "loss": 0.29091784358024597,
          "grad_norm": 1.7057012487044239
        },
        {
          "step": 205,
          "loss": 0.3389540910720825,
          "grad_norm": 2.0078277704066525
        },
        {
          "step": 210,
          "loss": 0.32608562707901,
          "grad_norm": 1.7549863681243547
        },
        {
          "step": 215,
          "loss": 0.22117306292057037,
          "grad_norm": 1.7776768637928948
        },
        {
          "step": 220,
          "loss": 0.5271289348602295,
          "grad_norm": 3.1251060018037085
        },
        {
          "step": 225,
          "loss": 0.48724156618118286,
          "grad_norm": 2.4463219319077414
        },
        {
          "step": 230,
          "loss": 0.12256600707769394,
          "grad_norm": 0.9120554603139708
        },
        {
          "step": 235,
          "loss": 0.3814184069633484,
          "grad_norm": 1.9034635069656822
        },
        {
          "step": 240,
          "loss": 0.4795880615711212,
          "grad_norm": 2.1461337944894856
        },
        {
          "step": 245,
          "loss": 0.3294576108455658,
          "grad_norm": 1.721318856274179
        },
        {
          "step": 250,
          "loss": 0.31618940830230713,
          "grad_norm": 1.6151196790666493
        },
        {
          "step": 255,
          "loss": 0.2865470051765442,
          "grad_norm": 2.1179056477742058
        },
        {
          "step": 260,
          "loss": 0.39881718158721924,
          "grad_norm": 2.0735804089650727
        },
        {
          "step": 265,
          "loss": 0.2314746081829071,
          "grad_norm": 1.8701601675488846
        },
        {
          "step": 270,
          "loss": 0.38242268562316895,
          "grad_norm": 3.2202516312366596
        },
        {
          "step": 275,
          "loss": 0.3891071379184723,
          "grad_norm": 2.4504651317179933
        },
        {
          "step": 280,
          "loss": 0.2774393856525421,
          "grad_norm": 1.919550670287689
        },
        {
          "step": 285,
          "loss": 0.13117916882038116,
          "grad_norm": 1.19001323684123
        },
        {
          "step": 290,
          "loss": 0.2362690567970276,
          "grad_norm": 1.605890498928423
        },
        {
          "step": 295,
          "loss": 0.28600984811782837,
          "grad_norm": 1.4331529126566855
        },
        {
          "step": 300,
          "loss": 0.38117051124572754,
          "grad_norm": 1.9630613687496021
        },
        {
          "step": 305,
          "loss": 0.2686036229133606,
          "grad_norm": 1.4518665165050333
        },
        {
          "step": 310,
          "loss": 0.46102452278137207,
          "grad_norm": 2.448355972118828
        },
        {
          "step": 315,
          "loss": 0.3844223618507385,
          "grad_norm": 2.3166120367189627
        },
        {
          "step": 320,
          "loss": 0.23839855194091797,
          "grad_norm": 1.8926608226373107
        },
        {
          "step": 325,
          "loss": 0.30451497435569763,
          "grad_norm": 2.0140853917090196
        },
        {
          "step": 330,
          "loss": 0.2459489405155182,
          "grad_norm": 1.5832511593859553
        },
        {
          "step": 335,
          "loss": 0.4145810902118683,
          "grad_norm": 2.5098049887470504
        },
        {
          "step": 340,
          "loss": 0.2845975160598755,
          "grad_norm": 1.6094990019960196
        },
        {
          "step": 345,
          "loss": 0.15381799638271332,
          "grad_norm": 1.4044968161558435
        },
        {
          "step": 350,
          "loss": 0.49870020151138306,
          "grad_norm": 2.1990744251086416
        },
        {
          "step": 355,
          "loss": 0.2983078360557556,
          "grad_norm": 1.6221881380623613
        },
        {
          "step": 360,
          "loss": 0.2894282937049866,
          "grad_norm": 1.6330402724791202
        },
        {
          "step": 365,
          "loss": 0.38865071535110474,
          "grad_norm": 1.7515876825251817
        },
        {
          "step": 370,
          "loss": 0.11263569444417953,
          "grad_norm": 1.2868689764724872
        },
        {
          "step": 375,
          "loss": 0.20985083281993866,
          "grad_norm": 1.157827497377737
        },
        {
          "step": 380,
          "loss": 0.3550090789794922,
          "grad_norm": 1.4810842158156345
        },
        {
          "step": 385,
          "loss": 0.5358787775039673,
          "grad_norm": 3.9139232516693343
        },
        {
          "step": 390,
          "loss": 0.2721768021583557,
          "grad_norm": 1.875537237930281
        },
        {
          "step": 395,
          "loss": 0.16713473200798035,
          "grad_norm": 1.706907184335031
        },
        {
          "step": 400,
          "loss": 0.2381419539451599,
          "grad_norm": 1.1911469178586567
        },
        {
          "step": 405,
          "loss": 0.2623829245567322,
          "grad_norm": 1.3801019477095915
        },
        {
          "step": 410,
          "loss": 0.07301653176546097,
          "grad_norm": 0.7983639777346958
        },
        {
          "step": 415,
          "loss": 0.19559721648693085,
          "grad_norm": 1.6220191077335215
        },
        {
          "step": 420,
          "loss": 0.06486278772354126,
          "grad_norm": 0.6462964715184206
        },
        {
          "step": 425,
          "loss": 0.4200270175933838,
          "grad_norm": 2.2467565486951666
        },
        {
          "step": 430,
          "loss": 0.18130052089691162,
          "grad_norm": 1.854113624306176
        },
        {
          "step": 435,
          "loss": 0.35905328392982483,
          "grad_norm": 2.986435931910301
        },
        {
          "step": 440,
          "loss": 0.24240344762802124,
          "grad_norm": 1.2303795786692484
        },
        {
          "step": 445,
          "loss": 0.26451554894447327,
          "grad_norm": 2.0377318468791916
        },
        {
          "step": 450,
          "loss": 0.24555954337120056,
          "grad_norm": 1.7559644532526681
        },
        {
          "step": 455,
          "loss": 0.23988260328769684,
          "grad_norm": 1.5276875636949356
        },
        {
          "step": 460,
          "loss": 0.2827782928943634,
          "grad_norm": 2.2576243044057884
        },
        {
          "step": 465,
          "loss": 0.1349763125181198,
          "grad_norm": 1.2341079599262206
        },
        {
          "step": 470,
          "loss": 0.22876639664173126,
          "grad_norm": 1.1932009665617542
        },
        {
          "step": 475,
          "loss": 0.12795142829418182,
          "grad_norm": 1.0496366525215037
        },
        {
          "step": 480,
          "loss": 0.21753014624118805,
          "grad_norm": 1.1225876352267006
        },
        {
          "step": 485,
          "loss": 0.13968373835086823,
          "grad_norm": 1.382847499166155
        },
        {
          "step": 490,
          "loss": 0.1922922134399414,
          "grad_norm": 1.265268901199127
        },
        {
          "step": 495,
          "loss": 0.21759706735610962,
          "grad_norm": 1.6124496161499393
        },
        {
          "step": 500,
          "loss": 0.11440451443195343,
          "grad_norm": 1.0852352072098326
        },
        {
          "step": 505,
          "loss": 0.3414166569709778,
          "grad_norm": 1.6616504394099851
        },
        {
          "step": 510,
          "loss": 0.3058011531829834,
          "grad_norm": 1.3291446693827673
        },
        {
          "step": 515,
          "loss": 0.20967337489128113,
          "grad_norm": 1.252499223546775
        },
        {
          "step": 520,
          "loss": 0.2898571491241455,
          "grad_norm": 1.8710805654584062
        },
        {
          "step": 525,
          "loss": 0.27230000495910645,
          "grad_norm": 2.0043518859172367
        },
        {
          "step": 530,
          "loss": 0.1259947419166565,
          "grad_norm": 1.5572195797394568
        },
        {
          "step": 535,
          "loss": 0.37325990200042725,
          "grad_norm": 1.9200980348576762
        },
        {
          "step": 540,
          "loss": 0.10715294629335403,
          "grad_norm": 1.5119163645533347
        },
        {
          "step": 545,
          "loss": 0.31505274772644043,
          "grad_norm": 1.7864498891565135
        },
        {
          "step": 550,
          "loss": 0.2514825165271759,
          "grad_norm": 1.9820074988767213
        },
        {
          "step": 555,
          "loss": 0.16188490390777588,
          "grad_norm": 1.279938557162518
        },
        {
          "step": 560,
          "loss": 0.23724234104156494,
          "grad_norm": 1.4520337460225559
        },
        {
          "step": 565,
          "loss": 0.09421294927597046,
          "grad_norm": 1.0086371933286749
        },
        {
          "step": 570,
          "loss": 0.25941506028175354,
          "grad_norm": 1.679323964338541
        },
        {
          "step": 575,
          "loss": 0.13886511325836182,
          "grad_norm": 1.1348462910776305
        },
        {
          "step": 580,
          "loss": 0.2128826081752777,
          "grad_norm": 1.8212123405995724
        },
        {
          "step": 585,
          "loss": 0.208355113863945,
          "grad_norm": 1.6527226996653306
        },
        {
          "step": 590,
          "loss": 0.131400465965271,
          "grad_norm": 1.0461548197330686
        },
        {
          "step": 595,
          "loss": 0.1559140533208847,
          "grad_norm": 1.319832258872281
        },
        {
          "step": 600,
          "loss": 0.28974151611328125,
          "grad_norm": 1.8763163740556796
        },
        {
          "step": 605,
          "loss": 0.37059229612350464,
          "grad_norm": 1.7244087489798827
        },
        {
          "step": 610,
          "loss": 0.24077770113945007,
          "grad_norm": 1.6942003823084963
        },
        {
          "step": 615,
          "loss": 0.14776231348514557,
          "grad_norm": 1.5654040377370615
        },
        {
          "step": 620,
          "loss": 0.19913515448570251,
          "grad_norm": 1.8493855699361401
        },
        {
          "step": 625,
          "loss": 0.22299474477767944,
          "grad_norm": 1.5982676521838202
        },
        {
          "step": 630,
          "loss": 0.2653034031391144,
          "grad_norm": 1.5502168811108992
        },
        {
          "step": 635,
          "loss": 0.1666661947965622,
          "grad_norm": 1.5192861545865401
        },
        {
          "step": 640,
          "loss": 0.21771186590194702,
          "grad_norm": 2.21858017378423
        },
        {
          "step": 645,
          "loss": 0.21024999022483826,
          "grad_norm": 1.49836698377438
        },
        {
          "step": 650,
          "loss": 0.1836824119091034,
          "grad_norm": 1.2760851267638886
        },
        {
          "step": 655,
          "loss": 0.19994743168354034,
          "grad_norm": 1.8730964269533021
        },
        {
          "step": 660,
          "loss": 0.19739791750907898,
          "grad_norm": 2.413731890046659
        },
        {
          "step": 665,
          "loss": 0.32530146837234497,
          "grad_norm": 1.9982495082629965
        },
        {
          "step": 670,
          "loss": 0.22648492455482483,
          "grad_norm": 1.4499270373169397
        },
        {
          "step": 675,
          "loss": 0.21470370888710022,
          "grad_norm": 0.820365623357472
        },
        {
          "step": 680,
          "loss": 0.12341663986444473,
          "grad_norm": 1.6811989048990423
        },
        {
          "step": 685,
          "loss": 0.33664706349372864,
          "grad_norm": 2.3151655079567215
        },
        {
          "step": 690,
          "loss": 0.3029336631298065,
          "grad_norm": 1.981130717029654
        },
        {
          "step": 695,
          "loss": 0.4955683648586273,
          "grad_norm": 2.5622144414112134
        },
        {
          "step": 700,
          "loss": 0.09303343296051025,
          "grad_norm": 0.976948793075148
        },
        {
          "step": 705,
          "loss": 0.12669417262077332,
          "grad_norm": 1.02604599277436
        },
        {
          "step": 710,
          "loss": 0.36840587854385376,
          "grad_norm": 1.9674621304275828
        },
        {
          "step": 715,
          "loss": 0.24211987853050232,
          "grad_norm": 1.6648445092859177
        },
        {
          "step": 720,
          "loss": 0.23008164763450623,
          "grad_norm": 1.6958746452689752
        },
        {
          "step": 725,
          "loss": 0.18453572690486908,
          "grad_norm": 1.5467877566180113
        },
        {
          "step": 730,
          "loss": 0.1094757467508316,
          "grad_norm": 0.8740363125163554
        },
        {
          "step": 735,
          "loss": 0.24905475974082947,
          "grad_norm": 1.5019756554656207
        },
        {
          "step": 740,
          "loss": 0.13545747101306915,
          "grad_norm": 1.703386486237212
        },
        {
          "step": 745,
          "loss": 0.3496081531047821,
          "grad_norm": 2.887737164982149
        },
        {
          "step": 750,
          "loss": 0.2052059918642044,
          "grad_norm": 2.325623683071215
        },
        {
          "step": 755,
          "loss": 0.3068845868110657,
          "grad_norm": 1.8325708216087544
        },
        {
          "step": 760,
          "loss": 0.15712374448776245,
          "grad_norm": 1.2886434538180132
        },
        {
          "step": 765,
          "loss": 0.22953978180885315,
          "grad_norm": 1.5159878889883396
        },
        {
          "step": 770,
          "loss": 0.20236605405807495,
          "grad_norm": 1.7169254776769802
        },
        {
          "step": 775,
          "loss": 0.2215186208486557,
          "grad_norm": 1.8090973770461118
        },
        {
          "step": 780,
          "loss": 0.2449081540107727,
          "grad_norm": 1.7125902947054168
        },
        {
          "step": 785,
          "loss": 0.18544268608093262,
          "grad_norm": 1.6641376266517391
        },
        {
          "step": 790,
          "loss": 0.18182246387004852,
          "grad_norm": 1.5970487045373885
        },
        {
          "step": 795,
          "loss": 0.1559843271970749,
          "grad_norm": 1.7180525623849714
        },
        {
          "step": 800,
          "loss": 0.1054505929350853,
          "grad_norm": 0.7728016603529771
        },
        {
          "step": 805,
          "loss": 0.2488669455051422,
          "grad_norm": 2.1160171651504465
        },
        {
          "step": 810,
          "loss": 0.2382361739873886,
          "grad_norm": 2.2747151890296666
        },
        {
          "step": 815,
          "loss": 0.3043047785758972,
          "grad_norm": 1.9604774740082718
        },
        {
          "step": 820,
          "loss": 0.3331022262573242,
          "grad_norm": 2.385854517401105
        },
        {
          "step": 825,
          "loss": 0.10054058581590652,
          "grad_norm": 1.2368625631822658
        },
        {
          "step": 830,
          "loss": 0.15544438362121582,
          "grad_norm": 1.269536812584243
        },
        {
          "step": 835,
          "loss": 0.21714970469474792,
          "grad_norm": 1.3780423742367562
        },
        {
          "step": 840,
          "loss": 0.3259466886520386,
          "grad_norm": 2.4093253514117805
        },
        {
          "step": 845,
          "loss": 0.21306297183036804,
          "grad_norm": 3.4680177131801515
        },
        {
          "step": 850,
          "loss": 0.13339829444885254,
          "grad_norm": 1.443856984086992
        },
        {
          "step": 855,
          "loss": 0.14588171243667603,
          "grad_norm": 1.6097792440608996
        },
        {
          "step": 860,
          "loss": 0.2118271291255951,
          "grad_norm": 1.481500924015893
        },
        {
          "step": 865,
          "loss": 0.2637665867805481,
          "grad_norm": 2.3073232947833793
        },
        {
          "step": 870,
          "loss": 0.18597730994224548,
          "grad_norm": 1.8125818875092454
        },
        {
          "step": 875,
          "loss": 0.23984511196613312,
          "grad_norm": 1.5675315597696742
        },
        {
          "step": 880,
          "loss": 0.11043539643287659,
          "grad_norm": 1.2627529506201827
        },
        {
          "step": 885,
          "loss": 0.3094732165336609,
          "grad_norm": 1.8245653690973465
        },
        {
          "step": 890,
          "loss": 0.29896730184555054,
          "grad_norm": 1.3923202347061747
        },
        {
          "step": 895,
          "loss": 0.2222980558872223,
          "grad_norm": 1.7124803770864012
        },
        {
          "step": 900,
          "loss": 0.23217344284057617,
          "grad_norm": 1.441201668594976
        },
        {
          "step": 905,
          "loss": 0.1311802715063095,
          "grad_norm": 1.2693187325774324
        },
        {
          "step": 910,
          "loss": 0.07025665789842606,
          "grad_norm": 0.8080585684676277
        },
        {
          "step": 915,
          "loss": 0.14027753472328186,
          "grad_norm": 1.5084081834133711
        },
        {
          "step": 920,
          "loss": 0.41418343782424927,
          "grad_norm": 2.228222844840536
        },
        {
          "step": 925,
          "loss": 0.264488160610199,
          "grad_norm": 1.4259194813888743
        },
        {
          "step": 930,
          "loss": 0.19814275205135345,
          "grad_norm": 1.0556335641002348
        },
        {
          "step": 935,
          "loss": 0.1481999158859253,
          "grad_norm": 0.8093336090228036
        },
        {
          "step": 940,
          "loss": 0.09277984499931335,
          "grad_norm": 0.8780167195187867
        },
        {
          "step": 945,
          "loss": 0.24300462007522583,
          "grad_norm": 1.5171425029127226
        },
        {
          "step": 950,
          "loss": 0.3374066948890686,
          "grad_norm": 1.4010725499437224
        },
        {
          "step": 955,
          "loss": 0.2749336063861847,
          "grad_norm": 1.5861994905503114
        },
        {
          "step": 960,
          "loss": 0.13112764060497284,
          "grad_norm": 1.0746678074688123
        },
        {
          "step": 965,
          "loss": 0.08998064696788788,
          "grad_norm": 1.233735684498716
        },
        {
          "step": 970,
          "loss": 0.18139050900936127,
          "grad_norm": 1.6730485720063926
        },
        {
          "step": 975,
          "loss": 0.09020736068487167,
          "grad_norm": 1.0762243327252998
        },
        {
          "step": 980,
          "loss": 0.2647121250629425,
          "grad_norm": 1.6361472695517254
        },
        {
          "step": 985,
          "loss": 0.3195456564426422,
          "grad_norm": 2.049286584114259
        },
        {
          "step": 990,
          "loss": 0.20664101839065552,
          "grad_norm": 1.425109807910535
        },
        {
          "step": 995,
          "loss": 0.3248651623725891,
          "grad_norm": 2.1997341799555286
        },
        {
          "step": 1000,
          "loss": 0.31249552965164185,
          "grad_norm": 1.439494330323119
        },
        {
          "step": 1005,
          "loss": 0.3213100731372833,
          "grad_norm": 2.4133180041713698
        },
        {
          "step": 1010,
          "loss": 0.3439667224884033,
          "grad_norm": 1.8282571567279637
        },
        {
          "step": 1015,
          "loss": 0.17287224531173706,
          "grad_norm": 1.0364413956591767
        },
        {
          "step": 1020,
          "loss": 0.20881831645965576,
          "grad_norm": 1.232044645159125
        },
        {
          "step": 1025,
          "loss": 0.17335152626037598,
          "grad_norm": 1.1449672302969918
        },
        {
          "step": 1030,
          "loss": 0.29530566930770874,
          "grad_norm": 1.3687760749841251
        },
        {
          "step": 1035,
          "loss": 0.1289478838443756,
          "grad_norm": 1.0834288310131872
        },
        {
          "step": 1040,
          "loss": 0.14529934525489807,
          "grad_norm": 0.9268222594253904
        },
        {
          "step": 1045,
          "loss": 0.09169001877307892,
          "grad_norm": 1.474749422554212
        },
        {
          "step": 1050,
          "loss": 0.05013631284236908,
          "grad_norm": 0.7577056241474222
        },
        {
          "step": 1055,
          "loss": 0.16307225823402405,
          "grad_norm": 1.7309154459840046
        },
        {
          "step": 1060,
          "loss": 0.11237389594316483,
          "grad_norm": 1.2213035185484067
        },
        {
          "step": 1065,
          "loss": 0.3392675518989563,
          "grad_norm": 2.1097194205664116
        },
        {
          "step": 1070,
          "loss": 0.31957343220710754,
          "grad_norm": 1.6740166653191646
        },
        {
          "step": 1075,
          "loss": 0.11194761097431183,
          "grad_norm": 0.8029097319441327
        },
        {
          "step": 1080,
          "loss": 0.16006669402122498,
          "grad_norm": 1.024974081202481
        },
        {
          "step": 1085,
          "loss": 0.22106212377548218,
          "grad_norm": 1.7199495785665757
        },
        {
          "step": 1090,
          "loss": 0.11695665866136551,
          "grad_norm": 1.4958387989411874
        },
        {
          "step": 1095,
          "loss": 0.08665324002504349,
          "grad_norm": 1.271470998686318
        },
        {
          "step": 1100,
          "loss": 0.14858898520469666,
          "grad_norm": 1.6079463160483602
        },
        {
          "step": 1105,
          "loss": 0.09002676606178284,
          "grad_norm": 0.9887400150128528
        },
        {
          "step": 1110,
          "loss": 0.1272650510072708,
          "grad_norm": 1.510887058441154
        },
        {
          "step": 1115,
          "loss": 0.16995388269424438,
          "grad_norm": 1.124679444808094
        },
        {
          "step": 1120,
          "loss": 0.15140663087368011,
          "grad_norm": 1.3414080972334652
        },
        {
          "step": 1125,
          "loss": 0.2833572030067444,
          "grad_norm": 2.1384836405976055
        },
        {
          "step": 1130,
          "loss": 0.21587789058685303,
          "grad_norm": 1.8294156325261848
        },
        {
          "step": 1135,
          "loss": 0.22657716274261475,
          "grad_norm": 1.9487948375295847
        },
        {
          "step": 1140,
          "loss": 0.18268267810344696,
          "grad_norm": 1.5567777184687361
        },
        {
          "step": 1145,
          "loss": 0.21040183305740356,
          "grad_norm": 3.527238627266349
        },
        {
          "step": 1150,
          "loss": 0.17265158891677856,
          "grad_norm": 1.2281718885700283
        },
        {
          "step": 1155,
          "loss": 0.5387535095214844,
          "grad_norm": 2.435206538464593
        },
        {
          "step": 1160,
          "loss": 0.19238638877868652,
          "grad_norm": 1.89350452920994
        },
        {
          "step": 1165,
          "loss": 0.07830250263214111,
          "grad_norm": 0.9857140434123984
        },
        {
          "step": 1170,
          "loss": 0.22434425354003906,
          "grad_norm": 1.1269953470515295
        },
        {
          "step": 1175,
          "loss": 0.029153386130928993,
          "grad_norm": 0.4075009283129814
        },
        {
          "step": 1180,
          "loss": 0.32284867763519287,
          "grad_norm": 1.9328320070148868
        },
        {
          "step": 1185,
          "loss": 0.13201475143432617,
          "grad_norm": 1.213567004599543
        },
        {
          "step": 1190,
          "loss": 0.18605422973632812,
          "grad_norm": 1.6609709044463097
        },
        {
          "step": 1195,
          "loss": 0.08031438291072845,
          "grad_norm": 1.109125306898462
        },
        {
          "step": 1200,
          "loss": 0.04844480752944946,
          "grad_norm": 0.6606997836988222
        },
        {
          "step": 1205,
          "loss": 0.08213840425014496,
          "grad_norm": 0.9843484436540132
        },
        {
          "step": 1210,
          "loss": 0.16821902990341187,
          "grad_norm": 1.2037645609087653
        },
        {
          "step": 1215,
          "loss": 0.2537912428379059,
          "grad_norm": 1.6439886998087394
        },
        {
          "step": 1220,
          "loss": 0.22086790204048157,
          "grad_norm": 1.6931853692718815
        },
        {
          "step": 1225,
          "loss": 0.309081494808197,
          "grad_norm": 1.7583245367277907
        },
        {
          "step": 1230,
          "loss": 0.42952960729599,
          "grad_norm": 2.186626843488518
        },
        {
          "step": 1235,
          "loss": 0.08357145637273788,
          "grad_norm": 1.294168294585865
        },
        {
          "step": 1240,
          "loss": 0.06358478218317032,
          "grad_norm": 0.9333509110253487
        },
        {
          "step": 1245,
          "loss": 0.3065609335899353,
          "grad_norm": 2.007740004693461
        },
        {
          "step": 1250,
          "loss": 0.1191151887178421,
          "grad_norm": 0.9603365166466753
        },
        {
          "step": 1255,
          "loss": 0.09908518195152283,
          "grad_norm": 1.235428459171011
        },
        {
          "step": 1260,
          "loss": 0.21026284992694855,
          "grad_norm": 1.2863495729658307
        },
        {
          "step": 1265,
          "loss": 0.3922828435897827,
          "grad_norm": 2.619187614371619
        },
        {
          "step": 1270,
          "loss": 0.11857046186923981,
          "grad_norm": 1.2260472043495982
        },
        {
          "step": 1275,
          "loss": 0.22076119482517242,
          "grad_norm": 1.7250050044792236
        },
        {
          "step": 1280,
          "loss": 0.3386474847793579,
          "grad_norm": 1.9437220785073017
        },
        {
          "step": 1285,
          "loss": 0.1483672708272934,
          "grad_norm": 1.566130284435279
        },
        {
          "step": 1290,
          "loss": 0.19563616812229156,
          "grad_norm": 2.016298147841275
        },
        {
          "step": 1295,
          "loss": 0.26697221398353577,
          "grad_norm": 2.4002463279227495
        },
        {
          "step": 1300,
          "loss": 0.20105862617492676,
          "grad_norm": 1.5487608466707246
        },
        {
          "step": 1305,
          "loss": 0.1841181367635727,
          "grad_norm": 0.870261002322304
        },
        {
          "step": 1310,
          "loss": 0.23662221431732178,
          "grad_norm": 1.6054241064145622
        },
        {
          "step": 1315,
          "loss": 0.248286172747612,
          "grad_norm": 1.4866652766314534
        },
        {
          "step": 1320,
          "loss": 0.10821259766817093,
          "grad_norm": 1.5543577663420702
        },
        {
          "step": 1325,
          "loss": 0.03978203982114792,
          "grad_norm": 0.45958859410085084
        },
        {
          "step": 1330,
          "loss": 0.17848964035511017,
          "grad_norm": 1.7196947567535787
        },
        {
          "step": 1335,
          "loss": 0.25241976976394653,
          "grad_norm": 1.7997068091049162
        },
        {
          "step": 1340,
          "loss": 0.22067421674728394,
          "grad_norm": 1.6361873583279216
        },
        {
          "step": 1345,
          "loss": 0.14059904217720032,
          "grad_norm": 1.6213423112441574
        },
        {
          "step": 1350,
          "loss": 0.2625851631164551,
          "grad_norm": 1.3072278383735167
        },
        {
          "step": 1355,
          "loss": 0.10998484492301941,
          "grad_norm": 1.1391511699425692
        },
        {
          "step": 1360,
          "loss": 0.2549532949924469,
          "grad_norm": 1.3208557223522528
        },
        {
          "step": 1365,
          "loss": 0.0784582570195198,
          "grad_norm": 1.4587465340433914
        },
        {
          "step": 1370,
          "loss": 0.13378967344760895,
          "grad_norm": 1.4919376738384134
        },
        {
          "step": 1375,
          "loss": 0.128573477268219,
          "grad_norm": 1.4912319514068206
        },
        {
          "step": 1380,
          "loss": 0.1180291399359703,
          "grad_norm": 0.9138509071002892
        },
        {
          "step": 1385,
          "loss": 0.29489368200302124,
          "grad_norm": 1.9060531667941372
        },
        {
          "step": 1390,
          "loss": 0.146880105137825,
          "grad_norm": 1.2031974593500177
        },
        {
          "step": 1395,
          "loss": 0.19089093804359436,
          "grad_norm": 1.8531262138336169
        },
        {
          "step": 1400,
          "loss": 0.14735646545886993,
          "grad_norm": 1.316244915946701
        },
        {
          "step": 1405,
          "loss": 0.12470321357250214,
          "grad_norm": 1.6158567973800941
        },
        {
          "step": 1410,
          "loss": 0.27815771102905273,
          "grad_norm": 1.791352271423331
        },
        {
          "step": 1415,
          "loss": 0.04443158581852913,
          "grad_norm": 0.8628976740039636
        },
        {
          "step": 1420,
          "loss": 0.15876233577728271,
          "grad_norm": 1.3452585747583365
        },
        {
          "step": 1425,
          "loss": 0.18151932954788208,
          "grad_norm": 1.6084965121311896
        },
        {
          "step": 1430,
          "loss": 0.21481618285179138,
          "grad_norm": 1.4734960782333606
        },
        {
          "step": 1435,
          "loss": 0.35358595848083496,
          "grad_norm": 2.3263830713590665
        },
        {
          "step": 1440,
          "loss": 0.2324945479631424,
          "grad_norm": 1.4631667371681543
        },
        {
          "step": 1445,
          "loss": 0.09257160872220993,
          "grad_norm": 1.077073054120163
        },
        {
          "step": 1450,
          "loss": 0.08545173704624176,
          "grad_norm": 1.3066983475774852
        },
        {
          "step": 1455,
          "loss": 0.07735982537269592,
          "grad_norm": 1.1977176700777603
        },
        {
          "step": 1460,
          "loss": 0.11669168621301651,
          "grad_norm": 1.4828071605913584
        },
        {
          "step": 1465,
          "loss": 0.10413500666618347,
          "grad_norm": 1.126226787580312
        },
        {
          "step": 1470,
          "loss": 0.15308770537376404,
          "grad_norm": 0.8976015535584391
        },
        {
          "step": 1475,
          "loss": 0.03626265376806259,
          "grad_norm": 0.6277028322304333
        },
        {
          "step": 1480,
          "loss": 0.15138539671897888,
          "grad_norm": 1.5460445060468155
        },
        {
          "step": 1485,
          "loss": 0.1487259864807129,
          "grad_norm": 1.866879556339342
        },
        {
          "step": 1490,
          "loss": 0.06112584099173546,
          "grad_norm": 0.6371991350277356
        },
        {
          "step": 1495,
          "loss": 0.18752381205558777,
          "grad_norm": 1.5424446296467749
        },
        {
          "step": 1500,
          "loss": 0.1999790370464325,
          "grad_norm": 1.3694226434439303
        },
        {
          "step": 1505,
          "loss": 0.4089033007621765,
          "grad_norm": 2.1076504692557583
        },
        {
          "step": 1510,
          "loss": 0.25522786378860474,
          "grad_norm": 1.684272722485934
        },
        {
          "step": 1515,
          "loss": 0.09465233236551285,
          "grad_norm": 1.0085239021525851
        },
        {
          "step": 1520,
          "loss": 0.18536001443862915,
          "grad_norm": 1.6316251357070826
        },
        {
          "step": 1525,
          "loss": 0.08296965062618256,
          "grad_norm": 1.1832283621224566
        },
        {
          "step": 1530,
          "loss": 0.05881790071725845,
          "grad_norm": 0.5838450157342611
        },
        {
          "step": 1535,
          "loss": 0.09396238625049591,
          "grad_norm": 1.206235898457292
        },
        {
          "step": 1540,
          "loss": 0.11169026792049408,
          "grad_norm": 2.151778430236211
        },
        {
          "step": 1545,
          "loss": 0.1006355881690979,
          "grad_norm": 1.3241582404616261
        },
        {
          "step": 1550,
          "loss": 0.2551368474960327,
          "grad_norm": 1.63455106131513
        },
        {
          "step": 1555,
          "loss": 0.06704214960336685,
          "grad_norm": 1.5022108049086549
        },
        {
          "step": 1560,
          "loss": 0.18447314202785492,
          "grad_norm": 2.053113010664557
        },
        {
          "step": 1565,
          "loss": 0.09279586374759674,
          "grad_norm": 1.39741969339775
        },
        {
          "step": 1570,
          "loss": 0.17721351981163025,
          "grad_norm": 1.6782483680608495
        },
        {
          "step": 1575,
          "loss": 0.026878364384174347,
          "grad_norm": 0.44245817555748923
        },
        {
          "step": 1580,
          "loss": 0.2548460364341736,
          "grad_norm": 1.8150006288805927
        },
        {
          "step": 1585,
          "loss": 0.2265203595161438,
          "grad_norm": 1.5669603202163493
        },
        {
          "step": 1590,
          "loss": 0.11045791208744049,
          "grad_norm": 1.0485023852918138
        },
        {
          "step": 1595,
          "loss": 0.1470089554786682,
          "grad_norm": 1.4102886662855778
        },
        {
          "step": 1600,
          "loss": 0.1592216193675995,
          "grad_norm": 1.293101157377738
        },
        {
          "step": 1605,
          "loss": 0.20466046035289764,
          "grad_norm": 1.3569277147659833
        },
        {
          "step": 1610,
          "loss": 0.09306178241968155,
          "grad_norm": 1.0588634825375343
        },
        {
          "step": 1615,
          "loss": 0.1466672122478485,
          "grad_norm": 1.530045185720087
        },
        {
          "step": 1620,
          "loss": 0.018723053857684135,
          "grad_norm": 0.30118705103573545
        },
        {
          "step": 1625,
          "loss": 0.21159741282463074,
          "grad_norm": 1.7688277680256872
        },
        {
          "step": 1630,
          "loss": 0.20010635256767273,
          "grad_norm": 2.0299047806160813
        },
        {
          "step": 1635,
          "loss": 0.09880904853343964,
          "grad_norm": 0.8634395919984198
        },
        {
          "step": 1640,
          "loss": 0.024686399847269058,
          "grad_norm": 0.4590914011319565
        },
        {
          "step": 1645,
          "loss": 0.1762315183877945,
          "grad_norm": 2.513663508769629
        },
        {
          "step": 1650,
          "loss": 0.046683818101882935,
          "grad_norm": 0.8762220116760902
        },
        {
          "step": 1655,
          "loss": 0.09456094354391098,
          "grad_norm": 1.1407802321917824
        },
        {
          "step": 1660,
          "loss": 0.067829430103302,
          "grad_norm": 0.7439952728845426
        },
        {
          "step": 1665,
          "loss": 0.10510410368442535,
          "grad_norm": 0.9107941959104212
        },
        {
          "step": 1670,
          "loss": 0.11134855449199677,
          "grad_norm": 1.3240533967989945
        },
        {
          "step": 1675,
          "loss": 0.12797467410564423,
          "grad_norm": 1.147718824828023
        },
        {
          "step": 1680,
          "loss": 0.2058050036430359,
          "grad_norm": 1.53699148621226
        },
        {
          "step": 1685,
          "loss": 0.11261919140815735,
          "grad_norm": 1.2099555948507341
        },
        {
          "step": 1690,
          "loss": 0.13032278418540955,
          "grad_norm": 1.5994262992777875
        },
        {
          "step": 1695,
          "loss": 0.3319384455680847,
          "grad_norm": 1.6263236798465193
        },
        {
          "step": 1700,
          "loss": 0.15236163139343262,
          "grad_norm": 1.8847546921463654
        },
        {
          "step": 1705,
          "loss": 0.1801164150238037,
          "grad_norm": 1.6385372905803974
        },
        {
          "step": 1710,
          "loss": 0.16939258575439453,
          "grad_norm": 1.3758115612353197
        },
        {
          "step": 1715,
          "loss": 0.1938062608242035,
          "grad_norm": 1.7261580803476027
        },
        {
          "step": 1720,
          "loss": 0.13058426976203918,
          "grad_norm": 1.4357110362839536
        },
        {
          "step": 1725,
          "loss": 0.22114941477775574,
          "grad_norm": 1.3415403547889986
        },
        {
          "step": 1730,
          "loss": 0.11579733341932297,
          "grad_norm": 1.4516610649915538
        },
        {
          "step": 1735,
          "loss": 0.14516983926296234,
          "grad_norm": 1.3319884013119803
        },
        {
          "step": 1740,
          "loss": 0.1851864755153656,
          "grad_norm": 1.8336490201151954
        },
        {
          "step": 1745,
          "loss": 0.1350662261247635,
          "grad_norm": 1.5943640167626218
        },
        {
          "step": 1750,
          "loss": 0.26234954595565796,
          "grad_norm": 1.3563658909596137
        },
        {
          "step": 1755,
          "loss": 0.08880910277366638,
          "grad_norm": 1.624542878753034
        },
        {
          "step": 1760,
          "loss": 0.12545830011367798,
          "grad_norm": 1.0414526089127056
        },
        {
          "step": 1765,
          "loss": 0.18933169543743134,
          "grad_norm": 1.1382181876553037
        },
        {
          "step": 1770,
          "loss": 0.22543980181217194,
          "grad_norm": 1.7538599554402257
        },
        {
          "step": 1775,
          "loss": 0.08306924998760223,
          "grad_norm": 0.6766820946735671
        },
        {
          "step": 1780,
          "loss": 0.13909953832626343,
          "grad_norm": 1.7629508733791892
        },
        {
          "step": 1785,
          "loss": 0.3964674174785614,
          "grad_norm": 1.6112417240838521
        },
        {
          "step": 1790,
          "loss": 0.05764884129166603,
          "grad_norm": 0.5835046701094292
        },
        {
          "step": 1795,
          "loss": 0.17585310339927673,
          "grad_norm": 1.8114650759057174
        },
        {
          "step": 1800,
          "loss": 0.42980095744132996,
          "grad_norm": 2.126132912243998
        },
        {
          "step": 1805,
          "loss": 0.3226034641265869,
          "grad_norm": 1.9503545483494604
        },
        {
          "step": 1810,
          "loss": 0.13652503490447998,
          "grad_norm": 1.4555062633565452
        },
        {
          "step": 1815,
          "loss": 0.083737812936306,
          "grad_norm": 1.4256178783908067
        },
        {
          "step": 1820,
          "loss": 0.1890738606452942,
          "grad_norm": 1.3530275801769351
        },
        {
          "step": 1825,
          "loss": 0.13574615120887756,
          "grad_norm": 1.1513552512485574
        },
        {
          "step": 1830,
          "loss": 0.11247804760932922,
          "grad_norm": 1.1591555963032294
        },
        {
          "step": 1835,
          "loss": 0.2415526807308197,
          "grad_norm": 1.6124442691544112
        },
        {
          "step": 1840,
          "loss": 0.2558644711971283,
          "grad_norm": 1.8261477017921213
        },
        {
          "step": 1845,
          "loss": 0.2254517525434494,
          "grad_norm": 1.08117378355535
        },
        {
          "step": 1850,
          "loss": 0.1056579202413559,
          "grad_norm": 1.4862584796002736
        },
        {
          "step": 1855,
          "loss": 0.28885552287101746,
          "grad_norm": 1.5507546317630927
        },
        {
          "step": 1860,
          "loss": 0.17947842180728912,
          "grad_norm": 0.8380748791730938
        },
        {
          "step": 1865,
          "loss": 0.08424577116966248,
          "grad_norm": 1.1083697470337288
        },
        {
          "step": 1870,
          "loss": 0.30751368403434753,
          "grad_norm": 1.5481088396650071
        },
        {
          "step": 1875,
          "loss": 0.09855329990386963,
          "grad_norm": 1.8951353005858835
        },
        {
          "step": 1880,
          "loss": 0.20717717707157135,
          "grad_norm": 1.4007717934090451
        },
        {
          "step": 1885,
          "loss": 0.3582334518432617,
          "grad_norm": 1.7379975655947182
        },
        {
          "step": 1890,
          "loss": 0.1429206132888794,
          "grad_norm": 1.0122560714152242
        },
        {
          "step": 1895,
          "loss": 0.1840880811214447,
          "grad_norm": 1.9769441119196152
        },
        {
          "step": 1900,
          "loss": 0.15515868365764618,
          "grad_norm": 1.7858505939100777
        },
        {
          "step": 1905,
          "loss": 0.17638546228408813,
          "grad_norm": 1.6919750205170956
        },
        {
          "step": 1910,
          "loss": 0.20718348026275635,
          "grad_norm": 1.5910609541765142
        },
        {
          "step": 1915,
          "loss": 0.22104141116142273,
          "grad_norm": 2.0949936587778284
        },
        {
          "step": 1920,
          "loss": 0.05431528389453888,
          "grad_norm": 0.8311088879283796
        },
        {
          "step": 1925,
          "loss": 0.07921650260686874,
          "grad_norm": 0.9932138527502204
        },
        {
          "step": 1930,
          "loss": 0.06129999831318855,
          "grad_norm": 0.9411554071686318
        },
        {
          "step": 1935,
          "loss": 0.2528340816497803,
          "grad_norm": 1.244265267438418
        },
        {
          "step": 1940,
          "loss": 0.18243221938610077,
          "grad_norm": 1.8274346031399624
        },
        {
          "step": 1945,
          "loss": 0.31462109088897705,
          "grad_norm": 1.9746723758592153
        },
        {
          "step": 1950,
          "loss": 0.14353612065315247,
          "grad_norm": 1.2395624643581162
        },
        {
          "step": 1955,
          "loss": 0.08040661364793777,
          "grad_norm": 1.09027307980566
        },
        {
          "step": 1960,
          "loss": 0.06579826772212982,
          "grad_norm": 0.9413114996842443
        },
        {
          "step": 1965,
          "loss": 0.08499225229024887,
          "grad_norm": 1.0106857725222336
        },
        {
          "step": 1970,
          "loss": 0.04700322821736336,
          "grad_norm": 1.0084587790943789
        },
        {
          "step": 1975,
          "loss": 0.16836370527744293,
          "grad_norm": 1.3565601937058436
        },
        {
          "step": 1980,
          "loss": 0.05419620871543884,
          "grad_norm": 0.8838662852611525
        },
        {
          "step": 1985,
          "loss": 0.23762890696525574,
          "grad_norm": 1.7839762960195549
        },
        {
          "step": 1990,
          "loss": 0.1290348470211029,
          "grad_norm": 1.61705217105288
        },
        {
          "step": 1995,
          "loss": 0.23455002903938293,
          "grad_norm": 1.558518735138775
        }
      ],
      "final_accuracy": 0.9647,
      "total_steps": 2000,
      "checkpoint_steps": [
        100,
        1000,
        2000
      ],
      "elapsed_time": 57.839035749435425
    },
    {
      "experiment_name": "cnn_deep_mnist",
      "measurements": [
        {
          "step": 0,
          "loss": 2.2819700241088867,
          "grad_norm": 1.1963886978103524
        },
        {
          "step": 5,
          "loss": 2.1322858333587646,
          "grad_norm": 1.2610715823838161
        },
        {
          "step": 10,
          "loss": 1.7064021825790405,
          "grad_norm": 2.8790841616473544
        },
        {
          "step": 15,
          "loss": 1.246328592300415,
          "grad_norm": 6.516571171713251
        },
        {
          "step": 20,
          "loss": 0.7842127084732056,
          "grad_norm": 7.685547097237464
        },
        {
          "step": 25,
          "loss": 0.6279209852218628,
          "grad_norm": 9.730472629411997
        },
        {
          "step": 30,
          "loss": 0.4258177876472473,
          "grad_norm": 7.884722368758782
        },
        {
          "step": 35,
          "loss": 0.7868310809135437,
          "grad_norm": 9.414826973201292
        },
        {
          "step": 40,
          "loss": 0.34494543075561523,
          "grad_norm": 6.147271885101312
        },
        {
          "step": 45,
          "loss": 0.2837234139442444,
          "grad_norm": 6.608483745651781
        },
        {
          "step": 50,
          "loss": 0.41693800687789917,
          "grad_norm": 7.598367564981542
        },
        {
          "step": 55,
          "loss": 0.2110801637172699,
          "grad_norm": 4.756312479704529
        },
        {
          "step": 60,
          "loss": 0.4800364077091217,
          "grad_norm": 5.760114513347001
        },
        {
          "step": 65,
          "loss": 0.1180015355348587,
          "grad_norm": 3.575997621254422
        },
        {
          "step": 70,
          "loss": 0.3657858371734619,
          "grad_norm": 3.8558549303821605
        },
        {
          "step": 75,
          "loss": 0.24559181928634644,
          "grad_norm": 3.1255304369629426
        },
        {
          "step": 80,
          "loss": 0.14453786611557007,
          "grad_norm": 2.956915949405792
        },
        {
          "step": 85,
          "loss": 0.1779966652393341,
          "grad_norm": 5.611982529342406
        },
        {
          "step": 90,
          "loss": 0.09145035594701767,
          "grad_norm": 2.021702548167455
        },
        {
          "step": 95,
          "loss": 0.09265017509460449,
          "grad_norm": 2.262131267253499
        },
        {
          "step": 100,
          "loss": 0.3122689723968506,
          "grad_norm": 4.923629279593412
        },
        {
          "step": 105,
          "loss": 0.17765802145004272,
          "grad_norm": 2.833892885273029
        },
        {
          "step": 110,
          "loss": 0.1756618767976761,
          "grad_norm": 1.9493646126471103
        },
        {
          "step": 115,
          "loss": 0.18221385776996613,
          "grad_norm": 3.937272915853745
        },
        {
          "step": 120,
          "loss": 0.20412620902061462,
          "grad_norm": 4.3385623430764495
        },
        {
          "step": 125,
          "loss": 0.20808179676532745,
          "grad_norm": 2.76750852036488
        },
        {
          "step": 130,
          "loss": 0.10534921288490295,
          "grad_norm": 2.1114136323824284
        },
        {
          "step": 135,
          "loss": 0.16683249175548553,
          "grad_norm": 2.7788967893027747
        },
        {
          "step": 140,
          "loss": 0.08306333422660828,
          "grad_norm": 2.4651754302996296
        },
        {
          "step": 145,
          "loss": 0.14388513565063477,
          "grad_norm": 3.53193462334364
        },
        {
          "step": 150,
          "loss": 0.1609123796224594,
          "grad_norm": 3.75640081306723
        },
        {
          "step": 155,
          "loss": 0.03687775135040283,
          "grad_norm": 1.0666859788382737
        },
        {
          "step": 160,
          "loss": 0.060731854289770126,
          "grad_norm": 2.1045453938176184
        },
        {
          "step": 165,
          "loss": 0.12321016937494278,
          "grad_norm": 2.6200887998838187
        },
        {
          "step": 170,
          "loss": 0.07562903314828873,
          "grad_norm": 2.025786177535266
        },
        {
          "step": 175,
          "loss": 0.049498580396175385,
          "grad_norm": 1.3773882734999001
        },
        {
          "step": 180,
          "loss": 0.20569291710853577,
          "grad_norm": 4.2922634362182475
        },
        {
          "step": 185,
          "loss": 0.19248896837234497,
          "grad_norm": 2.1860844156221715
        },
        {
          "step": 190,
          "loss": 0.055673833936452866,
          "grad_norm": 1.336353962951321
        },
        {
          "step": 195,
          "loss": 0.10268458724021912,
          "grad_norm": 3.055170143203846
        },
        {
          "step": 200,
          "loss": 0.24710863828659058,
          "grad_norm": 4.635759846487911
        },
        {
          "step": 205,
          "loss": 0.0893656313419342,
          "grad_norm": 2.8967688394709197
        },
        {
          "step": 210,
          "loss": 0.1130460649728775,
          "grad_norm": 2.9128966863236205
        },
        {
          "step": 215,
          "loss": 0.10154454410076141,
          "grad_norm": 2.1455984445246927
        },
        {
          "step": 220,
          "loss": 0.09119680523872375,
          "grad_norm": 2.0010484700700517
        },
        {
          "step": 225,
          "loss": 0.16172517836093903,
          "grad_norm": 3.702437446072185
        },
        {
          "step": 230,
          "loss": 0.0816788375377655,
          "grad_norm": 2.7208039317299826
        },
        {
          "step": 235,
          "loss": 0.16255025565624237,
          "grad_norm": 2.2710378664922977
        },
        {
          "step": 240,
          "loss": 0.1864134669303894,
          "grad_norm": 4.0403436013105205
        },
        {
          "step": 245,
          "loss": 0.1219433918595314,
          "grad_norm": 2.700279260024572
        },
        {
          "step": 250,
          "loss": 0.22248020768165588,
          "grad_norm": 4.21720091897473
        },
        {
          "step": 255,
          "loss": 0.05160777270793915,
          "grad_norm": 1.9834437973670034
        },
        {
          "step": 260,
          "loss": 0.17663954198360443,
          "grad_norm": 2.966932502519338
        },
        {
          "step": 265,
          "loss": 0.03952528536319733,
          "grad_norm": 1.0508514283010704
        },
        {
          "step": 270,
          "loss": 0.09055563807487488,
          "grad_norm": 2.3122524440227266
        },
        {
          "step": 275,
          "loss": 0.048694901168346405,
          "grad_norm": 1.723680872896446
        },
        {
          "step": 280,
          "loss": 0.1669396609067917,
          "grad_norm": 2.1105559182714684
        },
        {
          "step": 285,
          "loss": 0.05732107162475586,
          "grad_norm": 1.4128578999409078
        },
        {
          "step": 290,
          "loss": 0.14556780457496643,
          "grad_norm": 2.46036025708386
        },
        {
          "step": 295,
          "loss": 0.2268683761358261,
          "grad_norm": 1.9182761853181838
        },
        {
          "step": 300,
          "loss": 0.06170637905597687,
          "grad_norm": 1.150902552855167
        },
        {
          "step": 305,
          "loss": 0.07413707673549652,
          "grad_norm": 1.196867737111253
        },
        {
          "step": 310,
          "loss": 0.08656739443540573,
          "grad_norm": 1.9700142276158743
        },
        {
          "step": 315,
          "loss": 0.10466448962688446,
          "grad_norm": 1.5690497775322974
        },
        {
          "step": 320,
          "loss": 0.07559115439653397,
          "grad_norm": 1.7546642108036723
        },
        {
          "step": 325,
          "loss": 0.05632958561182022,
          "grad_norm": 1.4822863325411333
        },
        {
          "step": 330,
          "loss": 0.08344286680221558,
          "grad_norm": 1.4833215171940317
        },
        {
          "step": 335,
          "loss": 0.07779692858457565,
          "grad_norm": 1.406120353640831
        },
        {
          "step": 340,
          "loss": 0.056650035083293915,
          "grad_norm": 1.1995106098571973
        },
        {
          "step": 345,
          "loss": 0.04357658326625824,
          "grad_norm": 1.0567235241460218
        },
        {
          "step": 350,
          "loss": 0.06800907105207443,
          "grad_norm": 1.685577111412159
        },
        {
          "step": 355,
          "loss": 0.06994814425706863,
          "grad_norm": 1.5233969618021135
        },
        {
          "step": 360,
          "loss": 0.019203990697860718,
          "grad_norm": 0.7392250115495179
        },
        {
          "step": 365,
          "loss": 0.034320056438446045,
          "grad_norm": 1.644631802520827
        },
        {
          "step": 370,
          "loss": 0.04753733426332474,
          "grad_norm": 1.4426580388220065
        },
        {
          "step": 375,
          "loss": 0.18082298338413239,
          "grad_norm": 3.6939467460238866
        },
        {
          "step": 380,
          "loss": 0.10660506784915924,
          "grad_norm": 2.058013600750371
        },
        {
          "step": 385,
          "loss": 0.016671596094965935,
          "grad_norm": 0.6811006271859411
        },
        {
          "step": 390,
          "loss": 0.07436623424291611,
          "grad_norm": 1.7273656084837077
        },
        {
          "step": 395,
          "loss": 0.021181220188736916,
          "grad_norm": 1.121328129588617
        },
        {
          "step": 400,
          "loss": 0.008608441799879074,
          "grad_norm": 0.3286728977060186
        },
        {
          "step": 405,
          "loss": 0.11612018942832947,
          "grad_norm": 2.7556670046661838
        },
        {
          "step": 410,
          "loss": 0.15298302471637726,
          "grad_norm": 3.2036200046608942
        },
        {
          "step": 415,
          "loss": 0.023442428559064865,
          "grad_norm": 1.2562759347361847
        },
        {
          "step": 420,
          "loss": 0.062289126217365265,
          "grad_norm": 1.9801969927961118
        },
        {
          "step": 425,
          "loss": 0.11522587388753891,
          "grad_norm": 3.007395658419301
        },
        {
          "step": 430,
          "loss": 0.06669668853282928,
          "grad_norm": 2.1198502616309973
        },
        {
          "step": 435,
          "loss": 0.047473255544900894,
          "grad_norm": 0.9328888797185179
        },
        {
          "step": 440,
          "loss": 0.05962618067860603,
          "grad_norm": 1.0873437883350952
        },
        {
          "step": 445,
          "loss": 0.03879118710756302,
          "grad_norm": 1.0995433467941353
        },
        {
          "step": 450,
          "loss": 0.01917373389005661,
          "grad_norm": 0.8477714264888851
        },
        {
          "step": 455,
          "loss": 0.05570881441235542,
          "grad_norm": 1.3459370456385678
        },
        {
          "step": 460,
          "loss": 0.02160249650478363,
          "grad_norm": 1.034452670687014
        },
        {
          "step": 465,
          "loss": 0.03179500997066498,
          "grad_norm": 0.9883979060129215
        },
        {
          "step": 470,
          "loss": 0.07607358694076538,
          "grad_norm": 1.6498298653730925
        },
        {
          "step": 475,
          "loss": 0.04579497501254082,
          "grad_norm": 1.4870352121238062
        },
        {
          "step": 480,
          "loss": 0.08997170627117157,
          "grad_norm": 1.6379206711043925
        },
        {
          "step": 485,
          "loss": 0.033627189695835114,
          "grad_norm": 1.1329938092986467
        },
        {
          "step": 490,
          "loss": 0.0761953592300415,
          "grad_norm": 1.8353498043459626
        },
        {
          "step": 495,
          "loss": 0.013406077399849892,
          "grad_norm": 0.5824088097409736
        },
        {
          "step": 500,
          "loss": 0.07570837438106537,
          "grad_norm": 1.7459791456649625
        },
        {
          "step": 505,
          "loss": 0.10254299640655518,
          "grad_norm": 2.2232158005492657
        },
        {
          "step": 510,
          "loss": 0.10337214171886444,
          "grad_norm": 1.9341038446028853
        },
        {
          "step": 515,
          "loss": 0.04575096443295479,
          "grad_norm": 1.6942005115220544
        },
        {
          "step": 520,
          "loss": 0.04648049548268318,
          "grad_norm": 1.2126565802746947
        },
        {
          "step": 525,
          "loss": 0.010891718789935112,
          "grad_norm": 0.45205794523645737
        },
        {
          "step": 530,
          "loss": 0.1911558359861374,
          "grad_norm": 2.080644939263085
        },
        {
          "step": 535,
          "loss": 0.10681270062923431,
          "grad_norm": 2.4959151381083777
        },
        {
          "step": 540,
          "loss": 0.15190036594867706,
          "grad_norm": 2.5455476213556727
        },
        {
          "step": 545,
          "loss": 0.028689246624708176,
          "grad_norm": 1.0237928053166743
        },
        {
          "step": 550,
          "loss": 0.085662841796875,
          "grad_norm": 1.4012217589648763
        },
        {
          "step": 555,
          "loss": 0.04340188950300217,
          "grad_norm": 1.4299238421847846
        },
        {
          "step": 560,
          "loss": 0.26574811339378357,
          "grad_norm": 2.0872587788159316
        },
        {
          "step": 565,
          "loss": 0.06285625696182251,
          "grad_norm": 1.6860508603292181
        },
        {
          "step": 570,
          "loss": 0.09140630066394806,
          "grad_norm": 2.4308051328742613
        },
        {
          "step": 575,
          "loss": 0.12800998985767365,
          "grad_norm": 2.7404814183302237
        },
        {
          "step": 580,
          "loss": 0.06484530121088028,
          "grad_norm": 1.8815834937404088
        },
        {
          "step": 585,
          "loss": 0.03078635036945343,
          "grad_norm": 1.001180066130578
        },
        {
          "step": 590,
          "loss": 0.06225600466132164,
          "grad_norm": 1.489649972274935
        },
        {
          "step": 595,
          "loss": 0.041683271527290344,
          "grad_norm": 1.188702884270189
        },
        {
          "step": 600,
          "loss": 0.1268034428358078,
          "grad_norm": 1.7886490854230837
        },
        {
          "step": 605,
          "loss": 0.031903594732284546,
          "grad_norm": 0.9398267454999994
        },
        {
          "step": 610,
          "loss": 0.006685634609311819,
          "grad_norm": 0.29626273489411825
        },
        {
          "step": 615,
          "loss": 0.1458912342786789,
          "grad_norm": 2.2553798901085034
        },
        {
          "step": 620,
          "loss": 0.08443772792816162,
          "grad_norm": 2.8384338179900905
        },
        {
          "step": 625,
          "loss": 0.004468307830393314,
          "grad_norm": 0.11523875281551188
        },
        {
          "step": 630,
          "loss": 0.012388002127408981,
          "grad_norm": 0.5659492443244762
        },
        {
          "step": 635,
          "loss": 0.12135432660579681,
          "grad_norm": 2.260830622026549
        },
        {
          "step": 640,
          "loss": 0.02037179470062256,
          "grad_norm": 1.0430052369134513
        },
        {
          "step": 645,
          "loss": 0.05947592854499817,
          "grad_norm": 1.7299661120138632
        },
        {
          "step": 650,
          "loss": 0.09318041801452637,
          "grad_norm": 1.8402305659832288
        },
        {
          "step": 655,
          "loss": 0.12961381673812866,
          "grad_norm": 1.8166076347410862
        },
        {
          "step": 660,
          "loss": 0.016398299485445023,
          "grad_norm": 0.5124429240813154
        },
        {
          "step": 665,
          "loss": 0.07067887485027313,
          "grad_norm": 1.8396508556338798
        },
        {
          "step": 670,
          "loss": 0.11568747460842133,
          "grad_norm": 2.0101959858182066
        },
        {
          "step": 675,
          "loss": 0.11782945692539215,
          "grad_norm": 2.672043451939843
        },
        {
          "step": 680,
          "loss": 0.10352934151887894,
          "grad_norm": 2.13705416791528
        },
        {
          "step": 685,
          "loss": 0.08646541088819504,
          "grad_norm": 2.3412610413096746
        },
        {
          "step": 690,
          "loss": 0.011804976500570774,
          "grad_norm": 0.39237809952819613
        },
        {
          "step": 695,
          "loss": 0.02190866693854332,
          "grad_norm": 0.46427294326239665
        },
        {
          "step": 700,
          "loss": 0.06752943992614746,
          "grad_norm": 1.6498988950535538
        },
        {
          "step": 705,
          "loss": 0.02205471880733967,
          "grad_norm": 1.1740305153033648
        },
        {
          "step": 710,
          "loss": 0.04985552653670311,
          "grad_norm": 1.5282938598308773
        },
        {
          "step": 715,
          "loss": 0.035104475915431976,
          "grad_norm": 1.6282796597273133
        },
        {
          "step": 720,
          "loss": 0.023538578301668167,
          "grad_norm": 0.9936810857717672
        },
        {
          "step": 725,
          "loss": 0.0525515116751194,
          "grad_norm": 1.683022283465494
        },
        {
          "step": 730,
          "loss": 0.030995884910225868,
          "grad_norm": 1.1044231379501512
        },
        {
          "step": 735,
          "loss": 0.026079244911670685,
          "grad_norm": 0.7590216306981648
        },
        {
          "step": 740,
          "loss": 0.012976977974176407,
          "grad_norm": 0.7571140698094554
        },
        {
          "step": 745,
          "loss": 0.025518441572785378,
          "grad_norm": 0.7922898277344685
        },
        {
          "step": 750,
          "loss": 0.2231927067041397,
          "grad_norm": 2.5631668415920736
        },
        {
          "step": 755,
          "loss": 0.06642644852399826,
          "grad_norm": 1.2516921681454376
        },
        {
          "step": 760,
          "loss": 0.021566227078437805,
          "grad_norm": 0.7418923166732229
        },
        {
          "step": 765,
          "loss": 0.07937051355838776,
          "grad_norm": 1.751739591609398
        },
        {
          "step": 770,
          "loss": 0.019046157598495483,
          "grad_norm": 0.8319402721828901
        },
        {
          "step": 775,
          "loss": 0.002154674381017685,
          "grad_norm": 0.10686058082316034
        },
        {
          "step": 780,
          "loss": 0.07228455692529678,
          "grad_norm": 1.7340579109893164
        },
        {
          "step": 785,
          "loss": 0.058648161590099335,
          "grad_norm": 1.8378783613438947
        },
        {
          "step": 790,
          "loss": 0.05162828788161278,
          "grad_norm": 1.7330371755875116
        },
        {
          "step": 795,
          "loss": 0.04268520697951317,
          "grad_norm": 1.490075545376422
        },
        {
          "step": 800,
          "loss": 0.1129092127084732,
          "grad_norm": 1.7294132406239322
        },
        {
          "step": 805,
          "loss": 0.06524694710969925,
          "grad_norm": 2.1740057165548365
        },
        {
          "step": 810,
          "loss": 0.06536498665809631,
          "grad_norm": 1.4913489615259143
        },
        {
          "step": 815,
          "loss": 0.009642476215958595,
          "grad_norm": 0.3145602533351891
        },
        {
          "step": 820,
          "loss": 0.009438902139663696,
          "grad_norm": 0.34238522164164625
        },
        {
          "step": 825,
          "loss": 0.03812280297279358,
          "grad_norm": 1.4353423297480017
        },
        {
          "step": 830,
          "loss": 0.06523603945970535,
          "grad_norm": 2.186180269502404
        },
        {
          "step": 835,
          "loss": 0.006212538108229637,
          "grad_norm": 0.1701842684557129
        },
        {
          "step": 840,
          "loss": 0.03551653400063515,
          "grad_norm": 1.0980917087909814
        },
        {
          "step": 845,
          "loss": 0.06223154813051224,
          "grad_norm": 1.458901564568007
        },
        {
          "step": 850,
          "loss": 0.02472132071852684,
          "grad_norm": 1.052431079198235
        },
        {
          "step": 855,
          "loss": 0.032081350684165955,
          "grad_norm": 0.980537127062757
        },
        {
          "step": 860,
          "loss": 0.054158151149749756,
          "grad_norm": 1.319489127698786
        },
        {
          "step": 865,
          "loss": 0.07480276376008987,
          "grad_norm": 1.5135530659802847
        },
        {
          "step": 870,
          "loss": 0.05452268198132515,
          "grad_norm": 1.6911830983466105
        },
        {
          "step": 875,
          "loss": 0.04121861234307289,
          "grad_norm": 1.0522559220629724
        },
        {
          "step": 880,
          "loss": 0.14294244349002838,
          "grad_norm": 2.6163344701473643
        },
        {
          "step": 885,
          "loss": 0.05822068825364113,
          "grad_norm": 1.6669397879111152
        },
        {
          "step": 890,
          "loss": 0.10814250260591507,
          "grad_norm": 1.6034786387647788
        },
        {
          "step": 895,
          "loss": 0.04876840487122536,
          "grad_norm": 1.1093022503826566
        },
        {
          "step": 900,
          "loss": 0.016426168382167816,
          "grad_norm": 0.5843590311089553
        },
        {
          "step": 905,
          "loss": 0.025124823674559593,
          "grad_norm": 0.6587694879210112
        },
        {
          "step": 910,
          "loss": 0.043434832245111465,
          "grad_norm": 1.5293645812741783
        },
        {
          "step": 915,
          "loss": 0.05350456014275551,
          "grad_norm": 1.2621811279071942
        },
        {
          "step": 920,
          "loss": 0.04498130455613136,
          "grad_norm": 1.1816599332273334
        },
        {
          "step": 925,
          "loss": 0.00616052933037281,
          "grad_norm": 0.23070884209797657
        },
        {
          "step": 930,
          "loss": 0.005369286052882671,
          "grad_norm": 0.1780219690509113
        },
        {
          "step": 935,
          "loss": 0.04395144432783127,
          "grad_norm": 1.4753276755706382
        },
        {
          "step": 940,
          "loss": 0.02685851790010929,
          "grad_norm": 0.8228182906399761
        },
        {
          "step": 945,
          "loss": 0.09731210768222809,
          "grad_norm": 1.3710374069329194
        },
        {
          "step": 950,
          "loss": 0.011159847490489483,
          "grad_norm": 0.6652007167795525
        },
        {
          "step": 955,
          "loss": 0.023034460842609406,
          "grad_norm": 0.6485895221109811
        },
        {
          "step": 960,
          "loss": 0.07318742573261261,
          "grad_norm": 1.7309945769818473
        },
        {
          "step": 965,
          "loss": 0.023233067244291306,
          "grad_norm": 0.9859211131884164
        },
        {
          "step": 970,
          "loss": 0.008256977424025536,
          "grad_norm": 0.4070810126284972
        },
        {
          "step": 975,
          "loss": 0.03134206309914589,
          "grad_norm": 1.4890328067715293
        },
        {
          "step": 980,
          "loss": 0.04647982493042946,
          "grad_norm": 1.1776558711057283
        },
        {
          "step": 985,
          "loss": 0.00528348283842206,
          "grad_norm": 0.19167434095012148
        },
        {
          "step": 990,
          "loss": 0.035325758159160614,
          "grad_norm": 1.1548948067363112
        },
        {
          "step": 995,
          "loss": 0.02173931710422039,
          "grad_norm": 0.7038157478755734
        },
        {
          "step": 1000,
          "loss": 0.02626267820596695,
          "grad_norm": 0.9815397814170659
        },
        {
          "step": 1005,
          "loss": 0.057496439665555954,
          "grad_norm": 1.5184020910255072
        },
        {
          "step": 1010,
          "loss": 0.08519037812948227,
          "grad_norm": 1.6333602671446712
        },
        {
          "step": 1015,
          "loss": 0.016160277649760246,
          "grad_norm": 0.8736394648904229
        },
        {
          "step": 1020,
          "loss": 0.01731068268418312,
          "grad_norm": 0.7812603617976777
        },
        {
          "step": 1025,
          "loss": 0.03409788757562637,
          "grad_norm": 1.4208420159474648
        },
        {
          "step": 1030,
          "loss": 0.01439752895385027,
          "grad_norm": 0.579813312397044
        },
        {
          "step": 1035,
          "loss": 0.0332789309322834,
          "grad_norm": 1.2026762049633597
        },
        {
          "step": 1040,
          "loss": 0.058810971677303314,
          "grad_norm": 1.8038661910172313
        },
        {
          "step": 1045,
          "loss": 0.1020544096827507,
          "grad_norm": 1.7129809629332966
        },
        {
          "step": 1050,
          "loss": 0.009953999891877174,
          "grad_norm": 0.4445905388767416
        },
        {
          "step": 1055,
          "loss": 0.09039755910634995,
          "grad_norm": 2.2014636380147605
        },
        {
          "step": 1060,
          "loss": 0.0230401661247015,
          "grad_norm": 1.0624752062011906
        },
        {
          "step": 1065,
          "loss": 0.0035110292956233025,
          "grad_norm": 0.15320420939368493
        },
        {
          "step": 1070,
          "loss": 0.024861091747879982,
          "grad_norm": 1.1628300583531057
        },
        {
          "step": 1075,
          "loss": 0.027506619691848755,
          "grad_norm": 0.9652632384581381
        },
        {
          "step": 1080,
          "loss": 0.017708798870444298,
          "grad_norm": 0.5630425052627405
        },
        {
          "step": 1085,
          "loss": 0.008270367048680782,
          "grad_norm": 0.29850156532624966
        },
        {
          "step": 1090,
          "loss": 0.033626116812229156,
          "grad_norm": 1.3424692991269112
        },
        {
          "step": 1095,
          "loss": 0.019704965874552727,
          "grad_norm": 0.9938053968548839
        },
        {
          "step": 1100,
          "loss": 0.0030115251429378986,
          "grad_norm": 0.10179957692579576
        },
        {
          "step": 1105,
          "loss": 0.00479543162509799,
          "grad_norm": 0.11473496176587283
        },
        {
          "step": 1110,
          "loss": 0.01830391399562359,
          "grad_norm": 0.7165018751392201
        },
        {
          "step": 1115,
          "loss": 0.027673248201608658,
          "grad_norm": 1.1073199684418837
        },
        {
          "step": 1120,
          "loss": 0.026071541011333466,
          "grad_norm": 1.0213543949638235
        },
        {
          "step": 1125,
          "loss": 0.02038429118692875,
          "grad_norm": 0.8653380392858161
        },
        {
          "step": 1130,
          "loss": 0.05793537199497223,
          "grad_norm": 1.338569708074194
        },
        {
          "step": 1135,
          "loss": 0.018020406365394592,
          "grad_norm": 0.6245973927877485
        },
        {
          "step": 1140,
          "loss": 0.01178425457328558,
          "grad_norm": 0.32415308723261615
        },
        {
          "step": 1145,
          "loss": 0.0161733515560627,
          "grad_norm": 0.7638625387266739
        },
        {
          "step": 1150,
          "loss": 0.01764773577451706,
          "grad_norm": 0.5762269240212077
        },
        {
          "step": 1155,
          "loss": 0.06241109222173691,
          "grad_norm": 1.3818229343150776
        },
        {
          "step": 1160,
          "loss": 0.024863654747605324,
          "grad_norm": 0.8851580803352822
        },
        {
          "step": 1165,
          "loss": 0.024538977071642876,
          "grad_norm": 1.1875344967183494
        },
        {
          "step": 1170,
          "loss": 0.0443025603890419,
          "grad_norm": 1.5511502746855006
        },
        {
          "step": 1175,
          "loss": 0.013940204866230488,
          "grad_norm": 0.5380487755819453
        },
        {
          "step": 1180,
          "loss": 0.3759426474571228,
          "grad_norm": 1.979140209737737
        },
        {
          "step": 1185,
          "loss": 0.06604243814945221,
          "grad_norm": 1.4501059943627197
        },
        {
          "step": 1190,
          "loss": 0.047563355416059494,
          "grad_norm": 1.4159816746333114
        },
        {
          "step": 1195,
          "loss": 0.016437748447060585,
          "grad_norm": 0.5976926273670361
        },
        {
          "step": 1200,
          "loss": 0.003520392579957843,
          "grad_norm": 0.14087260636855012
        },
        {
          "step": 1205,
          "loss": 0.015030174516141415,
          "grad_norm": 0.512096689298024
        },
        {
          "step": 1210,
          "loss": 0.03260432183742523,
          "grad_norm": 0.8777901895494122
        },
        {
          "step": 1215,
          "loss": 0.01413976401090622,
          "grad_norm": 0.7093742385017949
        },
        {
          "step": 1220,
          "loss": 0.02254369854927063,
          "grad_norm": 0.7797056278689295
        },
        {
          "step": 1225,
          "loss": 0.02692398615181446,
          "grad_norm": 0.6424331791812263
        },
        {
          "step": 1230,
          "loss": 0.0041034165769815445,
          "grad_norm": 0.1444039885168456
        },
        {
          "step": 1235,
          "loss": 0.002307793591171503,
          "grad_norm": 0.07829287442539085
        },
        {
          "step": 1240,
          "loss": 0.029661979526281357,
          "grad_norm": 0.876205823730005
        },
        {
          "step": 1245,
          "loss": 0.03267355263233185,
          "grad_norm": 1.1031120482856902
        },
        {
          "step": 1250,
          "loss": 0.0025603719986975193,
          "grad_norm": 0.11481271673017455
        },
        {
          "step": 1255,
          "loss": 0.07582258433103561,
          "grad_norm": 1.5724278006394024
        },
        {
          "step": 1260,
          "loss": 0.14625294506549835,
          "grad_norm": 1.36477674092128
        },
        {
          "step": 1265,
          "loss": 0.011696824803948402,
          "grad_norm": 0.38539012259954625
        },
        {
          "step": 1270,
          "loss": 0.054654061794281006,
          "grad_norm": 1.145696460116746
        },
        {
          "step": 1275,
          "loss": 0.014197949320077896,
          "grad_norm": 0.4454913176110585
        },
        {
          "step": 1280,
          "loss": 0.008937010541558266,
          "grad_norm": 0.2785004591638636
        },
        {
          "step": 1285,
          "loss": 0.02968946099281311,
          "grad_norm": 0.8340003173877468
        },
        {
          "step": 1290,
          "loss": 0.017620444297790527,
          "grad_norm": 0.46903757272381486
        },
        {
          "step": 1295,
          "loss": 0.0058544403873384,
          "grad_norm": 0.2901008155892259
        },
        {
          "step": 1300,
          "loss": 0.03148505091667175,
          "grad_norm": 1.329495143252033
        },
        {
          "step": 1305,
          "loss": 0.030923863872885704,
          "grad_norm": 1.2490838779486249
        },
        {
          "step": 1310,
          "loss": 0.0044219763949513435,
          "grad_norm": 0.15860172900753028
        },
        {
          "step": 1315,
          "loss": 0.084978848695755,
          "grad_norm": 1.503597267415622
        },
        {
          "step": 1320,
          "loss": 0.009293945506215096,
          "grad_norm": 0.28006349029258737
        },
        {
          "step": 1325,
          "loss": 0.026844477280974388,
          "grad_norm": 0.9801707932799426
        },
        {
          "step": 1330,
          "loss": 0.018118133768439293,
          "grad_norm": 0.6040677979704451
        },
        {
          "step": 1335,
          "loss": 0.014053916558623314,
          "grad_norm": 0.651981824933312
        },
        {
          "step": 1340,
          "loss": 0.07190656661987305,
          "grad_norm": 1.999520257997676
        },
        {
          "step": 1345,
          "loss": 0.037229280918836594,
          "grad_norm": 1.2520950139664564
        },
        {
          "step": 1350,
          "loss": 0.05765054002404213,
          "grad_norm": 1.5302764441055432
        },
        {
          "step": 1355,
          "loss": 0.07965510338544846,
          "grad_norm": 1.68209473689883
        },
        {
          "step": 1360,
          "loss": 0.04094424471259117,
          "grad_norm": 1.2182182587377919
        },
        {
          "step": 1365,
          "loss": 0.06437794119119644,
          "grad_norm": 1.7383693591003488
        },
        {
          "step": 1370,
          "loss": 0.010583932511508465,
          "grad_norm": 0.6287803864602212
        },
        {
          "step": 1375,
          "loss": 0.005173305980861187,
          "grad_norm": 0.19187761793756483
        },
        {
          "step": 1380,
          "loss": 0.05872474983334541,
          "grad_norm": 1.507675564534901
        },
        {
          "step": 1385,
          "loss": 0.014695009216666222,
          "grad_norm": 0.4653230235998036
        },
        {
          "step": 1390,
          "loss": 0.014594264328479767,
          "grad_norm": 0.4906123934795597
        },
        {
          "step": 1395,
          "loss": 0.04890528321266174,
          "grad_norm": 1.2602970672577787
        },
        {
          "step": 1400,
          "loss": 0.030582545325160027,
          "grad_norm": 0.8606090616679649
        },
        {
          "step": 1405,
          "loss": 0.017908403649926186,
          "grad_norm": 0.45901499553208464
        },
        {
          "step": 1410,
          "loss": 0.033228784799575806,
          "grad_norm": 1.2404386814449078
        },
        {
          "step": 1415,
          "loss": 0.028694139793515205,
          "grad_norm": 1.2260502216989821
        },
        {
          "step": 1420,
          "loss": 0.012180403806269169,
          "grad_norm": 0.46296679418631553
        },
        {
          "step": 1425,
          "loss": 0.012451179325580597,
          "grad_norm": 0.6893476279978158
        },
        {
          "step": 1430,
          "loss": 0.026522839441895485,
          "grad_norm": 0.8538148552500857
        },
        {
          "step": 1435,
          "loss": 0.12452047318220139,
          "grad_norm": 1.6730606461218767
        },
        {
          "step": 1440,
          "loss": 0.07917597144842148,
          "grad_norm": 1.4971034641337826
        },
        {
          "step": 1445,
          "loss": 0.0592130646109581,
          "grad_norm": 1.4978783422049753
        },
        {
          "step": 1450,
          "loss": 0.006105456035584211,
          "grad_norm": 0.25896795265314776
        },
        {
          "step": 1455,
          "loss": 0.09410794824361801,
          "grad_norm": 1.4384826347919457
        },
        {
          "step": 1460,
          "loss": 0.00850844569504261,
          "grad_norm": 0.43030295826358944
        },
        {
          "step": 1465,
          "loss": 0.04158348590135574,
          "grad_norm": 1.121599833719094
        },
        {
          "step": 1470,
          "loss": 0.011370931752026081,
          "grad_norm": 0.6010149698734514
        },
        {
          "step": 1475,
          "loss": 0.004225360695272684,
          "grad_norm": 0.21264225875740378
        },
        {
          "step": 1480,
          "loss": 0.013861517421901226,
          "grad_norm": 0.7608527174342105
        },
        {
          "step": 1485,
          "loss": 0.049021799117326736,
          "grad_norm": 1.208335499932762
        },
        {
          "step": 1490,
          "loss": 0.01029210165143013,
          "grad_norm": 0.5321477439142097
        },
        {
          "step": 1495,
          "loss": 0.023231854662299156,
          "grad_norm": 0.7855174525644025
        },
        {
          "step": 1500,
          "loss": 0.014094092883169651,
          "grad_norm": 0.5328891939412935
        },
        {
          "step": 1505,
          "loss": 0.003829043824225664,
          "grad_norm": 0.14422114179436446
        },
        {
          "step": 1510,
          "loss": 0.030549660325050354,
          "grad_norm": 1.1145041673166145
        },
        {
          "step": 1515,
          "loss": 0.01860133931040764,
          "grad_norm": 0.9668956001677729
        },
        {
          "step": 1520,
          "loss": 0.07197917252779007,
          "grad_norm": 2.082085436230482
        },
        {
          "step": 1525,
          "loss": 0.013639816083014011,
          "grad_norm": 0.777345353386141
        },
        {
          "step": 1530,
          "loss": 0.00651311781257391,
          "grad_norm": 0.27048203292457773
        },
        {
          "step": 1535,
          "loss": 0.02293136902153492,
          "grad_norm": 0.8746278373593308
        },
        {
          "step": 1540,
          "loss": 0.01067979633808136,
          "grad_norm": 0.4084804324650909
        },
        {
          "step": 1545,
          "loss": 0.045706454664468765,
          "grad_norm": 1.1426841759493305
        },
        {
          "step": 1550,
          "loss": 0.004422767087817192,
          "grad_norm": 0.17271887523109122
        },
        {
          "step": 1555,
          "loss": 0.032065149396657944,
          "grad_norm": 0.8485438821076806
        },
        {
          "step": 1560,
          "loss": 0.0518839955329895,
          "grad_norm": 1.2902160948394568
        },
        {
          "step": 1565,
          "loss": 0.1408359408378601,
          "grad_norm": 2.226503976477576
        },
        {
          "step": 1570,
          "loss": 0.01794060692191124,
          "grad_norm": 0.5526677006231918
        },
        {
          "step": 1575,
          "loss": 0.03836901858448982,
          "grad_norm": 1.054261305826593
        },
        {
          "step": 1580,
          "loss": 0.0021715424954891205,
          "grad_norm": 0.06511306775105394
        },
        {
          "step": 1585,
          "loss": 0.006132413633167744,
          "grad_norm": 0.20656374810293593
        },
        {
          "step": 1590,
          "loss": 0.052176110446453094,
          "grad_norm": 1.3571754114449455
        },
        {
          "step": 1595,
          "loss": 0.09522444754838943,
          "grad_norm": 1.4971120471328838
        },
        {
          "step": 1600,
          "loss": 0.07675982266664505,
          "grad_norm": 1.3664687499691996
        },
        {
          "step": 1605,
          "loss": 0.010453549213707447,
          "grad_norm": 0.37666978486919445
        },
        {
          "step": 1610,
          "loss": 0.04020459204912186,
          "grad_norm": 1.131578536163369
        },
        {
          "step": 1615,
          "loss": 0.05957099795341492,
          "grad_norm": 1.4227586709137898
        },
        {
          "step": 1620,
          "loss": 0.00895996019244194,
          "grad_norm": 0.28809794762534463
        },
        {
          "step": 1625,
          "loss": 0.01748974248766899,
          "grad_norm": 0.6013929389109536
        },
        {
          "step": 1630,
          "loss": 0.0636730045080185,
          "grad_norm": 1.2908796758387104
        },
        {
          "step": 1635,
          "loss": 0.005682955961674452,
          "grad_norm": 0.22407641379152976
        },
        {
          "step": 1640,
          "loss": 0.06155332177877426,
          "grad_norm": 1.2870318646787167
        },
        {
          "step": 1645,
          "loss": 0.048390328884124756,
          "grad_norm": 0.9773894685829506
        },
        {
          "step": 1650,
          "loss": 0.02725672349333763,
          "grad_norm": 1.070314579819805
        },
        {
          "step": 1655,
          "loss": 0.06331444531679153,
          "grad_norm": 1.1103104958498298
        },
        {
          "step": 1660,
          "loss": 0.12521770596504211,
          "grad_norm": 1.6269310875628544
        },
        {
          "step": 1665,
          "loss": 0.08146242797374725,
          "grad_norm": 0.9444641922876528
        },
        {
          "step": 1670,
          "loss": 0.0067797331139445305,
          "grad_norm": 0.2929403144655294
        },
        {
          "step": 1675,
          "loss": 0.01325957477092743,
          "grad_norm": 0.4762438631381204
        },
        {
          "step": 1680,
          "loss": 0.11087502539157867,
          "grad_norm": 1.4657507413169022
        },
        {
          "step": 1685,
          "loss": 0.06021903082728386,
          "grad_norm": 1.3044418004302918
        },
        {
          "step": 1690,
          "loss": 0.059034425765275955,
          "grad_norm": 1.6785876459332716
        },
        {
          "step": 1695,
          "loss": 0.020823786035180092,
          "grad_norm": 0.9089424920988383
        },
        {
          "step": 1700,
          "loss": 0.006027098745107651,
          "grad_norm": 0.34294961775121524
        },
        {
          "step": 1705,
          "loss": 0.002811580430716276,
          "grad_norm": 0.1788532580381153
        },
        {
          "step": 1710,
          "loss": 0.05635502189397812,
          "grad_norm": 0.9242879139372658
        },
        {
          "step": 1715,
          "loss": 0.019246315583586693,
          "grad_norm": 0.5903133064660152
        },
        {
          "step": 1720,
          "loss": 0.05633274465799332,
          "grad_norm": 1.5042845962699591
        },
        {
          "step": 1725,
          "loss": 0.0016773288371041417,
          "grad_norm": 0.08580911884789476
        },
        {
          "step": 1730,
          "loss": 0.004268051125109196,
          "grad_norm": 0.214136421690664
        },
        {
          "step": 1735,
          "loss": 0.11559174209833145,
          "grad_norm": 1.029427788527724
        },
        {
          "step": 1740,
          "loss": 0.046669550240039825,
          "grad_norm": 1.5501555562114908
        },
        {
          "step": 1745,
          "loss": 0.013170764781534672,
          "grad_norm": 0.49103732234297626
        },
        {
          "step": 1750,
          "loss": 0.11421655118465424,
          "grad_norm": 1.4251421563363844
        },
        {
          "step": 1755,
          "loss": 0.05842851102352142,
          "grad_norm": 1.2643952520692512
        },
        {
          "step": 1760,
          "loss": 0.037434257566928864,
          "grad_norm": 1.0821984742338562
        },
        {
          "step": 1765,
          "loss": 0.026096101850271225,
          "grad_norm": 0.9476886534230289
        },
        {
          "step": 1770,
          "loss": 0.003998848609626293,
          "grad_norm": 0.24047132977789534
        },
        {
          "step": 1775,
          "loss": 0.0038216665852814913,
          "grad_norm": 0.17501046278069493
        },
        {
          "step": 1780,
          "loss": 0.002335228957235813,
          "grad_norm": 0.10008710342840405
        },
        {
          "step": 1785,
          "loss": 0.05766913294792175,
          "grad_norm": 1.8089074435885273
        },
        {
          "step": 1790,
          "loss": 0.004683814477175474,
          "grad_norm": 0.3356412286241755
        },
        {
          "step": 1795,
          "loss": 0.014671334065496922,
          "grad_norm": 0.6300448951969831
        },
        {
          "step": 1800,
          "loss": 0.06737232208251953,
          "grad_norm": 1.734800919304507
        },
        {
          "step": 1805,
          "loss": 0.016595959663391113,
          "grad_norm": 0.5753626175844685
        },
        {
          "step": 1810,
          "loss": 0.016948817297816277,
          "grad_norm": 0.5903886707011256
        },
        {
          "step": 1815,
          "loss": 0.010639936663210392,
          "grad_norm": 0.4079917310793718
        },
        {
          "step": 1820,
          "loss": 0.04284755885601044,
          "grad_norm": 1.1998245804899454
        },
        {
          "step": 1825,
          "loss": 0.052635565400123596,
          "grad_norm": 1.33405630107629
        },
        {
          "step": 1830,
          "loss": 0.01502910628914833,
          "grad_norm": 0.800923902873184
        },
        {
          "step": 1835,
          "loss": 0.028261948376893997,
          "grad_norm": 0.9299309824913828
        },
        {
          "step": 1840,
          "loss": 0.0258147194981575,
          "grad_norm": 0.8492454280662703
        },
        {
          "step": 1845,
          "loss": 0.02249956503510475,
          "grad_norm": 0.7692229833132231
        },
        {
          "step": 1850,
          "loss": 0.1677580177783966,
          "grad_norm": 2.218150805735547
        },
        {
          "step": 1855,
          "loss": 0.043804772198200226,
          "grad_norm": 1.3832329344659788
        },
        {
          "step": 1860,
          "loss": 0.06988559663295746,
          "grad_norm": 1.9654098087252183
        },
        {
          "step": 1865,
          "loss": 0.0038882119115442038,
          "grad_norm": 0.1718443369564626
        },
        {
          "step": 1870,
          "loss": 0.002279700478538871,
          "grad_norm": 0.06671142115647118
        },
        {
          "step": 1875,
          "loss": 0.07019300758838654,
          "grad_norm": 1.81582711808124
        },
        {
          "step": 1880,
          "loss": 0.09419095516204834,
          "grad_norm": 1.420647479686948
        },
        {
          "step": 1885,
          "loss": 0.009854561649262905,
          "grad_norm": 0.345646259438619
        },
        {
          "step": 1890,
          "loss": 0.09333783388137817,
          "grad_norm": 1.597695172339479
        },
        {
          "step": 1895,
          "loss": 0.005665440112352371,
          "grad_norm": 0.22690664980245548
        },
        {
          "step": 1900,
          "loss": 0.057295192033052444,
          "grad_norm": 1.042207537101607
        },
        {
          "step": 1905,
          "loss": 0.045023880898952484,
          "grad_norm": 1.2316046883517136
        },
        {
          "step": 1910,
          "loss": 0.009745080955326557,
          "grad_norm": 0.515301049346421
        },
        {
          "step": 1915,
          "loss": 0.004785803612321615,
          "grad_norm": 0.1953739266329311
        },
        {
          "step": 1920,
          "loss": 0.017727943137288094,
          "grad_norm": 0.678869386764567
        },
        {
          "step": 1925,
          "loss": 0.03736624866724014,
          "grad_norm": 1.4122184461004827
        },
        {
          "step": 1930,
          "loss": 0.005912058521062136,
          "grad_norm": 0.18042086191823936
        },
        {
          "step": 1935,
          "loss": 0.038040220737457275,
          "grad_norm": 1.0317070113023168
        },
        {
          "step": 1940,
          "loss": 0.021859679371118546,
          "grad_norm": 0.7101541595781132
        },
        {
          "step": 1945,
          "loss": 0.024768931791186333,
          "grad_norm": 1.0434004999487163
        },
        {
          "step": 1950,
          "loss": 0.004911178257316351,
          "grad_norm": 0.24186387399755913
        },
        {
          "step": 1955,
          "loss": 0.008760904893279076,
          "grad_norm": 0.37899225967226513
        },
        {
          "step": 1960,
          "loss": 0.004903290420770645,
          "grad_norm": 0.22882070178359892
        },
        {
          "step": 1965,
          "loss": 0.010893075726926327,
          "grad_norm": 0.4403860889198804
        },
        {
          "step": 1970,
          "loss": 0.0009715580381453037,
          "grad_norm": 0.03733180624178177
        },
        {
          "step": 1975,
          "loss": 0.0010604870039969683,
          "grad_norm": 0.029944986280113998
        },
        {
          "step": 1980,
          "loss": 0.007832502014935017,
          "grad_norm": 0.3924534387415307
        },
        {
          "step": 1985,
          "loss": 0.02940937504172325,
          "grad_norm": 0.8541677388211385
        },
        {
          "step": 1990,
          "loss": 0.015435327775776386,
          "grad_norm": 0.46201587182525966
        },
        {
          "step": 1995,
          "loss": 0.05398877337574959,
          "grad_norm": 1.3163583847874671
        }
      ],
      "final_accuracy": 0.9904,
      "total_steps": 2000,
      "checkpoint_steps": [
        100,
        1000,
        2000
      ],
      "elapsed_time": 37.032334089279175
    },
    {
      "experiment_name": "mlp_narrow_mnist",
      "measurements": [
        {
          "step": 0,
          "loss": 2.290389060974121,
          "grad_norm": 0.18035638080698652
        },
        {
          "step": 5,
          "loss": 2.282527446746826,
          "grad_norm": 0.21393772621239665
        },
        {
          "step": 10,
          "loss": 2.2423481941223145,
          "grad_norm": 0.28128916843909585
        },
        {
          "step": 15,
          "loss": 2.1963040828704834,
          "grad_norm": 0.4114774405200231
        },
        {
          "step": 20,
          "loss": 2.12166166305542,
          "grad_norm": 0.552152769373745
        },
        {
          "step": 25,
          "loss": 1.9971939325332642,
          "grad_norm": 0.8597712480352929
        },
        {
          "step": 30,
          "loss": 1.913945198059082,
          "grad_norm": 1.2729146217044438
        },
        {
          "step": 35,
          "loss": 1.6895673274993896,
          "grad_norm": 1.3994567408086298
        },
        {
          "step": 40,
          "loss": 1.5532054901123047,
          "grad_norm": 1.2241804979991882
        },
        {
          "step": 45,
          "loss": 1.3848475217819214,
          "grad_norm": 1.8158031742211704
        },
        {
          "step": 50,
          "loss": 1.4967257976531982,
          "grad_norm": 1.9511399177353197
        },
        {
          "step": 55,
          "loss": 1.206747055053711,
          "grad_norm": 2.3229277935732595
        },
        {
          "step": 60,
          "loss": 1.177074909210205,
          "grad_norm": 2.7046629510930553
        },
        {
          "step": 65,
          "loss": 0.9451709985733032,
          "grad_norm": 1.5831537521024732
        },
        {
          "step": 70,
          "loss": 1.005781888961792,
          "grad_norm": 3.8149180205100546
        },
        {
          "step": 75,
          "loss": 0.8216824531555176,
          "grad_norm": 2.3155638506507112
        },
        {
          "step": 80,
          "loss": 0.8727471232414246,
          "grad_norm": 2.6244097449529287
        },
        {
          "step": 85,
          "loss": 0.811814546585083,
          "grad_norm": 4.093607772476438
        },
        {
          "step": 90,
          "loss": 0.4693956673145294,
          "grad_norm": 2.043368633437123
        },
        {
          "step": 95,
          "loss": 0.7190843820571899,
          "grad_norm": 3.0414368990767278
        },
        {
          "step": 100,
          "loss": 0.7767764925956726,
          "grad_norm": 2.7469159322715626
        },
        {
          "step": 105,
          "loss": 0.6600235104560852,
          "grad_norm": 2.236747292467748
        },
        {
          "step": 110,
          "loss": 0.7320908308029175,
          "grad_norm": 2.0545085257519315
        },
        {
          "step": 115,
          "loss": 0.5818806290626526,
          "grad_norm": 4.210281948873101
        },
        {
          "step": 120,
          "loss": 0.7827619314193726,
          "grad_norm": 3.1267003352393132
        },
        {
          "step": 125,
          "loss": 0.5227538347244263,
          "grad_norm": 2.3288049953196155
        },
        {
          "step": 130,
          "loss": 0.6142101287841797,
          "grad_norm": 3.0672683815598987
        },
        {
          "step": 135,
          "loss": 0.5509839653968811,
          "grad_norm": 2.5628596556739596
        },
        {
          "step": 140,
          "loss": 0.44687992334365845,
          "grad_norm": 2.2955816314406294
        },
        {
          "step": 145,
          "loss": 0.44260406494140625,
          "grad_norm": 1.9938724775355936
        },
        {
          "step": 150,
          "loss": 0.6376875638961792,
          "grad_norm": 2.447752657454405
        },
        {
          "step": 155,
          "loss": 0.7456804513931274,
          "grad_norm": 2.8093576755915146
        },
        {
          "step": 160,
          "loss": 0.5017727613449097,
          "grad_norm": 3.1528969006229217
        },
        {
          "step": 165,
          "loss": 0.5465472936630249,
          "grad_norm": 3.3620559433838997
        },
        {
          "step": 170,
          "loss": 0.6122530102729797,
          "grad_norm": 3.647396061173295
        },
        {
          "step": 175,
          "loss": 0.372539758682251,
          "grad_norm": 2.121420755264689
        },
        {
          "step": 180,
          "loss": 0.5849167108535767,
          "grad_norm": 3.8270088893312098
        },
        {
          "step": 185,
          "loss": 0.5439666509628296,
          "grad_norm": 3.219149333341058
        },
        {
          "step": 190,
          "loss": 0.5184099078178406,
          "grad_norm": 2.6710390072858363
        },
        {
          "step": 195,
          "loss": 0.405484676361084,
          "grad_norm": 3.3396212623528867
        },
        {
          "step": 200,
          "loss": 0.5100359320640564,
          "grad_norm": 2.7550876401048923
        },
        {
          "step": 205,
          "loss": 0.4116431176662445,
          "grad_norm": 1.7766739172540513
        },
        {
          "step": 210,
          "loss": 0.5843092203140259,
          "grad_norm": 3.9463362325694513
        },
        {
          "step": 215,
          "loss": 0.3778625726699829,
          "grad_norm": 4.148331371680575
        },
        {
          "step": 220,
          "loss": 0.5458613038063049,
          "grad_norm": 2.962027626427445
        },
        {
          "step": 225,
          "loss": 0.32057520747184753,
          "grad_norm": 1.934723555924643
        },
        {
          "step": 230,
          "loss": 0.38472825288772583,
          "grad_norm": 3.536488667642789
        },
        {
          "step": 235,
          "loss": 0.47039276361465454,
          "grad_norm": 3.1846116866916416
        },
        {
          "step": 240,
          "loss": 0.6216497421264648,
          "grad_norm": 3.554612587908053
        },
        {
          "step": 245,
          "loss": 0.6217340230941772,
          "grad_norm": 3.5358448553807063
        },
        {
          "step": 250,
          "loss": 0.5196610689163208,
          "grad_norm": 3.5412684597079513
        },
        {
          "step": 255,
          "loss": 0.42123594880104065,
          "grad_norm": 3.847239281798424
        },
        {
          "step": 260,
          "loss": 0.3885483145713806,
          "grad_norm": 1.8926980154557367
        },
        {
          "step": 265,
          "loss": 0.37995970249176025,
          "grad_norm": 3.388864927134949
        },
        {
          "step": 270,
          "loss": 0.39294731616973877,
          "grad_norm": 2.130074303096894
        },
        {
          "step": 275,
          "loss": 0.33062106370925903,
          "grad_norm": 2.1007494290003126
        },
        {
          "step": 280,
          "loss": 0.5767114758491516,
          "grad_norm": 2.692709142562021
        },
        {
          "step": 285,
          "loss": 0.5854614973068237,
          "grad_norm": 2.7288050240675297
        },
        {
          "step": 290,
          "loss": 0.39246511459350586,
          "grad_norm": 1.865322215919884
        },
        {
          "step": 295,
          "loss": 0.3240790367126465,
          "grad_norm": 2.0779641537095115
        },
        {
          "step": 300,
          "loss": 0.2340930849313736,
          "grad_norm": 2.8864123744892938
        },
        {
          "step": 305,
          "loss": 0.4710500240325928,
          "grad_norm": 2.2300685777396074
        },
        {
          "step": 310,
          "loss": 0.31645339727401733,
          "grad_norm": 2.5497919645689824
        },
        {
          "step": 315,
          "loss": 0.49191170930862427,
          "grad_norm": 2.915257056129327
        },
        {
          "step": 320,
          "loss": 0.3993168771266937,
          "grad_norm": 2.6598352047765466
        },
        {
          "step": 325,
          "loss": 0.3857441544532776,
          "grad_norm": 3.0189687000060648
        },
        {
          "step": 330,
          "loss": 0.4614506959915161,
          "grad_norm": 2.696871656755908
        },
        {
          "step": 335,
          "loss": 0.23664668202400208,
          "grad_norm": 2.617494004395386
        },
        {
          "step": 340,
          "loss": 0.5309691429138184,
          "grad_norm": 3.252457602088025
        },
        {
          "step": 345,
          "loss": 0.2079583704471588,
          "grad_norm": 1.7578119894439477
        },
        {
          "step": 350,
          "loss": 0.19451063871383667,
          "grad_norm": 1.8139245659377716
        },
        {
          "step": 355,
          "loss": 0.4452071189880371,
          "grad_norm": 2.847344200745591
        },
        {
          "step": 360,
          "loss": 0.44296374917030334,
          "grad_norm": 2.205129546518481
        },
        {
          "step": 365,
          "loss": 0.4448711574077606,
          "grad_norm": 2.0347116900918523
        },
        {
          "step": 370,
          "loss": 0.31498944759368896,
          "grad_norm": 3.0292588745365694
        },
        {
          "step": 375,
          "loss": 0.3051098585128784,
          "grad_norm": 2.444038417146964
        },
        {
          "step": 380,
          "loss": 0.5693202018737793,
          "grad_norm": 3.9842848182354267
        },
        {
          "step": 385,
          "loss": 0.2271035611629486,
          "grad_norm": 1.5071140880514236
        },
        {
          "step": 390,
          "loss": 0.27544814348220825,
          "grad_norm": 2.621286447259967
        },
        {
          "step": 395,
          "loss": 0.2567537724971771,
          "grad_norm": 2.4155570005517446
        },
        {
          "step": 400,
          "loss": 0.3862682580947876,
          "grad_norm": 2.4592368959683824
        },
        {
          "step": 405,
          "loss": 0.31997567415237427,
          "grad_norm": 2.2496148242081295
        },
        {
          "step": 410,
          "loss": 0.35840165615081787,
          "grad_norm": 1.6429343388189663
        },
        {
          "step": 415,
          "loss": 0.2904893159866333,
          "grad_norm": 1.8906039387947609
        },
        {
          "step": 420,
          "loss": 0.44226258993148804,
          "grad_norm": 2.167032733950164
        },
        {
          "step": 425,
          "loss": 0.3154028058052063,
          "grad_norm": 1.7001327116799891
        },
        {
          "step": 430,
          "loss": 0.26208609342575073,
          "grad_norm": 3.051942838730751
        },
        {
          "step": 435,
          "loss": 0.2130163609981537,
          "grad_norm": 1.8326748236471921
        },
        {
          "step": 440,
          "loss": 0.3077356815338135,
          "grad_norm": 1.7176440781198745
        },
        {
          "step": 445,
          "loss": 0.5168492794036865,
          "grad_norm": 3.506411447886711
        },
        {
          "step": 450,
          "loss": 0.22674450278282166,
          "grad_norm": 2.1463984912912077
        },
        {
          "step": 455,
          "loss": 0.5190837383270264,
          "grad_norm": 2.8897861520164234
        },
        {
          "step": 460,
          "loss": 0.2802910804748535,
          "grad_norm": 1.9763191227623933
        },
        {
          "step": 465,
          "loss": 0.36030587553977966,
          "grad_norm": 3.712821907230109
        },
        {
          "step": 470,
          "loss": 0.5175761580467224,
          "grad_norm": 3.5114280581693644
        },
        {
          "step": 475,
          "loss": 0.2635886073112488,
          "grad_norm": 1.6051732718960594
        },
        {
          "step": 480,
          "loss": 0.2926977276802063,
          "grad_norm": 1.8302226091546174
        },
        {
          "step": 485,
          "loss": 0.4255959391593933,
          "grad_norm": 1.8834202448702437
        },
        {
          "step": 490,
          "loss": 0.24297848343849182,
          "grad_norm": 1.3918989527455463
        },
        {
          "step": 495,
          "loss": 0.4855186939239502,
          "grad_norm": 3.276476148246515
        },
        {
          "step": 500,
          "loss": 0.3228050470352173,
          "grad_norm": 3.264055043209753
        },
        {
          "step": 505,
          "loss": 0.45439326763153076,
          "grad_norm": 3.336659098912071
        },
        {
          "step": 510,
          "loss": 0.5745495557785034,
          "grad_norm": 3.7232787021475136
        },
        {
          "step": 515,
          "loss": 0.4702003598213196,
          "grad_norm": 3.9935116273774485
        },
        {
          "step": 520,
          "loss": 0.2670522928237915,
          "grad_norm": 2.4006681270085912
        },
        {
          "step": 525,
          "loss": 0.33755189180374146,
          "grad_norm": 3.3184782263607278
        },
        {
          "step": 530,
          "loss": 0.41769105195999146,
          "grad_norm": 2.2263046010660594
        },
        {
          "step": 535,
          "loss": 0.22994990646839142,
          "grad_norm": 1.5693833517691607
        },
        {
          "step": 540,
          "loss": 0.523549497127533,
          "grad_norm": 2.7450798585751923
        },
        {
          "step": 545,
          "loss": 0.411175400018692,
          "grad_norm": 2.8155117218736616
        },
        {
          "step": 550,
          "loss": 0.26745322346687317,
          "grad_norm": 1.91620382142743
        },
        {
          "step": 555,
          "loss": 0.4146289527416229,
          "grad_norm": 3.4369605026126693
        },
        {
          "step": 560,
          "loss": 0.328407883644104,
          "grad_norm": 2.0195161143341567
        },
        {
          "step": 565,
          "loss": 0.37439873814582825,
          "grad_norm": 2.678110352271656
        },
        {
          "step": 570,
          "loss": 0.33003121614456177,
          "grad_norm": 2.2140855822205836
        },
        {
          "step": 575,
          "loss": 0.18202611804008484,
          "grad_norm": 1.920915454986484
        },
        {
          "step": 580,
          "loss": 0.3109150528907776,
          "grad_norm": 1.577687046335014
        },
        {
          "step": 585,
          "loss": 0.18872538208961487,
          "grad_norm": 2.190877579762718
        },
        {
          "step": 590,
          "loss": 0.5509949326515198,
          "grad_norm": 2.024778273290206
        },
        {
          "step": 595,
          "loss": 0.19113995134830475,
          "grad_norm": 1.817909388058848
        },
        {
          "step": 600,
          "loss": 0.27020183205604553,
          "grad_norm": 1.495515152519836
        },
        {
          "step": 605,
          "loss": 0.29429173469543457,
          "grad_norm": 1.5140098133218702
        },
        {
          "step": 610,
          "loss": 0.3639007806777954,
          "grad_norm": 2.081322692127611
        },
        {
          "step": 615,
          "loss": 0.3092205226421356,
          "grad_norm": 2.249788279582665
        },
        {
          "step": 620,
          "loss": 0.5988622903823853,
          "grad_norm": 3.0013384935132845
        },
        {
          "step": 625,
          "loss": 0.21197731792926788,
          "grad_norm": 2.0240174530453645
        },
        {
          "step": 630,
          "loss": 0.42260438203811646,
          "grad_norm": 3.12623908489549
        },
        {
          "step": 635,
          "loss": 0.41331788897514343,
          "grad_norm": 2.304931270405805
        },
        {
          "step": 640,
          "loss": 0.2904845178127289,
          "grad_norm": 1.7368112536185984
        },
        {
          "step": 645,
          "loss": 0.42340654134750366,
          "grad_norm": 2.7850560235271287
        },
        {
          "step": 650,
          "loss": 0.29923027753829956,
          "grad_norm": 2.8114803485503153
        },
        {
          "step": 655,
          "loss": 0.4054184556007385,
          "grad_norm": 2.497978284635035
        },
        {
          "step": 660,
          "loss": 0.21345317363739014,
          "grad_norm": 1.9901131621286727
        },
        {
          "step": 665,
          "loss": 0.2260979861021042,
          "grad_norm": 1.5698377935932404
        },
        {
          "step": 670,
          "loss": 0.4069661498069763,
          "grad_norm": 2.9009486713927473
        },
        {
          "step": 675,
          "loss": 0.46488258242607117,
          "grad_norm": 3.909607664536035
        },
        {
          "step": 680,
          "loss": 0.41611218452453613,
          "grad_norm": 2.6132549783445085
        },
        {
          "step": 685,
          "loss": 0.5376018285751343,
          "grad_norm": 3.2189686665892396
        },
        {
          "step": 690,
          "loss": 0.2835156321525574,
          "grad_norm": 2.1814038251772536
        },
        {
          "step": 695,
          "loss": 0.2659383714199066,
          "grad_norm": 1.9286069946463142
        },
        {
          "step": 700,
          "loss": 0.38541877269744873,
          "grad_norm": 2.799904313485998
        },
        {
          "step": 705,
          "loss": 0.31203195452690125,
          "grad_norm": 2.2371720912897897
        },
        {
          "step": 710,
          "loss": 0.20455443859100342,
          "grad_norm": 1.8624407380589778
        },
        {
          "step": 715,
          "loss": 0.4343715012073517,
          "grad_norm": 1.866796243285436
        },
        {
          "step": 720,
          "loss": 0.271449476480484,
          "grad_norm": 1.5614246009396482
        },
        {
          "step": 725,
          "loss": 0.26568377017974854,
          "grad_norm": 2.055958682843969
        },
        {
          "step": 730,
          "loss": 0.2989843487739563,
          "grad_norm": 2.8789827493027866
        },
        {
          "step": 735,
          "loss": 0.3439224064350128,
          "grad_norm": 1.5061964795579732
        },
        {
          "step": 740,
          "loss": 0.11196921765804291,
          "grad_norm": 1.1235666356483145
        },
        {
          "step": 745,
          "loss": 0.17627540230751038,
          "grad_norm": 1.3224877236137909
        },
        {
          "step": 750,
          "loss": 0.25564929842948914,
          "grad_norm": 1.6813357091021819
        },
        {
          "step": 755,
          "loss": 0.18438579142093658,
          "grad_norm": 1.0582946504519772
        },
        {
          "step": 760,
          "loss": 0.3860798478126526,
          "grad_norm": 1.8287806344514164
        },
        {
          "step": 765,
          "loss": 0.4438071846961975,
          "grad_norm": 3.2820519022866543
        },
        {
          "step": 770,
          "loss": 0.3539341986179352,
          "grad_norm": 2.393254990286707
        },
        {
          "step": 775,
          "loss": 0.2282681167125702,
          "grad_norm": 1.740251997825789
        },
        {
          "step": 780,
          "loss": 0.29169517755508423,
          "grad_norm": 1.9867954108656427
        },
        {
          "step": 785,
          "loss": 0.20222249627113342,
          "grad_norm": 1.8065317455903933
        },
        {
          "step": 790,
          "loss": 0.1671079397201538,
          "grad_norm": 2.1974518218086696
        },
        {
          "step": 795,
          "loss": 0.28318333625793457,
          "grad_norm": 1.7425577353519326
        },
        {
          "step": 800,
          "loss": 0.30092722177505493,
          "grad_norm": 2.5864652458303654
        },
        {
          "step": 805,
          "loss": 0.38108545541763306,
          "grad_norm": 2.721050203769541
        },
        {
          "step": 810,
          "loss": 0.5328771471977234,
          "grad_norm": 3.409908041478384
        },
        {
          "step": 815,
          "loss": 0.2664126455783844,
          "grad_norm": 1.5123774730679398
        },
        {
          "step": 820,
          "loss": 0.2988739013671875,
          "grad_norm": 1.804618459421761
        },
        {
          "step": 825,
          "loss": 0.23611405491828918,
          "grad_norm": 1.950355568032097
        },
        {
          "step": 830,
          "loss": 0.36966630816459656,
          "grad_norm": 2.5962732433700513
        },
        {
          "step": 835,
          "loss": 0.4512367248535156,
          "grad_norm": 3.767842488185161
        },
        {
          "step": 840,
          "loss": 0.2741658091545105,
          "grad_norm": 1.5503468154071267
        },
        {
          "step": 845,
          "loss": 0.3918188810348511,
          "grad_norm": 2.584370953102739
        },
        {
          "step": 850,
          "loss": 0.2277924120426178,
          "grad_norm": 2.16060135666716
        },
        {
          "step": 855,
          "loss": 0.21519547700881958,
          "grad_norm": 1.9718142624392487
        },
        {
          "step": 860,
          "loss": 0.2407582402229309,
          "grad_norm": 2.44057831926434
        },
        {
          "step": 865,
          "loss": 0.2710299789905548,
          "grad_norm": 1.9338641887927328
        },
        {
          "step": 870,
          "loss": 0.14669877290725708,
          "grad_norm": 1.2778804354742825
        },
        {
          "step": 875,
          "loss": 0.2043127715587616,
          "grad_norm": 1.6770140043317554
        },
        {
          "step": 880,
          "loss": 0.24119338393211365,
          "grad_norm": 1.7622873592595667
        },
        {
          "step": 885,
          "loss": 0.30037248134613037,
          "grad_norm": 1.8520092898201224
        },
        {
          "step": 890,
          "loss": 0.2742684483528137,
          "grad_norm": 1.8743159689633089
        },
        {
          "step": 895,
          "loss": 0.3020891845226288,
          "grad_norm": 1.464176136681246
        },
        {
          "step": 900,
          "loss": 0.12772899866104126,
          "grad_norm": 1.0895015046494387
        },
        {
          "step": 905,
          "loss": 0.2991113066673279,
          "grad_norm": 1.9870033328709
        },
        {
          "step": 910,
          "loss": 0.25503405928611755,
          "grad_norm": 1.5355463461851198
        },
        {
          "step": 915,
          "loss": 0.43837371468544006,
          "grad_norm": 2.818711117936109
        },
        {
          "step": 920,
          "loss": 0.25683099031448364,
          "grad_norm": 2.536579896192708
        },
        {
          "step": 925,
          "loss": 0.13842083513736725,
          "grad_norm": 1.0239683134043676
        },
        {
          "step": 930,
          "loss": 0.5541282296180725,
          "grad_norm": 3.2382193416746694
        },
        {
          "step": 935,
          "loss": 0.2798938751220703,
          "grad_norm": 2.1973902168766015
        },
        {
          "step": 940,
          "loss": 0.21225057542324066,
          "grad_norm": 1.542211950727845
        },
        {
          "step": 945,
          "loss": 0.22233512997627258,
          "grad_norm": 1.9543010136937673
        },
        {
          "step": 950,
          "loss": 0.2583739459514618,
          "grad_norm": 2.2383470393244322
        },
        {
          "step": 955,
          "loss": 0.35876521468162537,
          "grad_norm": 1.599526800265104
        },
        {
          "step": 960,
          "loss": 0.4895893931388855,
          "grad_norm": 2.0793492535159075
        },
        {
          "step": 965,
          "loss": 0.5260034799575806,
          "grad_norm": 3.0353014942244774
        },
        {
          "step": 970,
          "loss": 0.3425781726837158,
          "grad_norm": 1.556338363181329
        },
        {
          "step": 975,
          "loss": 0.3264983296394348,
          "grad_norm": 2.748052209257378
        },
        {
          "step": 980,
          "loss": 0.4616994559764862,
          "grad_norm": 2.5603343305632995
        },
        {
          "step": 985,
          "loss": 0.3425107002258301,
          "grad_norm": 1.5160284815877751
        },
        {
          "step": 990,
          "loss": 0.33366841077804565,
          "grad_norm": 2.966326516161023
        },
        {
          "step": 995,
          "loss": 0.4493435025215149,
          "grad_norm": 2.744695021754508
        },
        {
          "step": 1000,
          "loss": 0.342097669839859,
          "grad_norm": 2.2382310572341573
        },
        {
          "step": 1005,
          "loss": 0.31839749217033386,
          "grad_norm": 1.9649264821603423
        },
        {
          "step": 1010,
          "loss": 0.25569236278533936,
          "grad_norm": 1.9762955189618243
        },
        {
          "step": 1015,
          "loss": 0.1820417046546936,
          "grad_norm": 2.14505157779205
        },
        {
          "step": 1020,
          "loss": 0.1959955096244812,
          "grad_norm": 2.420799816499515
        },
        {
          "step": 1025,
          "loss": 0.22547411918640137,
          "grad_norm": 1.2724180960180105
        },
        {
          "step": 1030,
          "loss": 0.3030948042869568,
          "grad_norm": 2.0556356020880435
        },
        {
          "step": 1035,
          "loss": 0.2494911551475525,
          "grad_norm": 1.4877445068652788
        },
        {
          "step": 1040,
          "loss": 0.40228432416915894,
          "grad_norm": 2.7316810966389244
        },
        {
          "step": 1045,
          "loss": 0.1738293319940567,
          "grad_norm": 1.3929849605145108
        },
        {
          "step": 1050,
          "loss": 0.21441873908042908,
          "grad_norm": 2.11498743558229
        },
        {
          "step": 1055,
          "loss": 0.37370556592941284,
          "grad_norm": 2.114747565183743
        },
        {
          "step": 1060,
          "loss": 0.21285486221313477,
          "grad_norm": 2.014464961684145
        },
        {
          "step": 1065,
          "loss": 0.3404759168624878,
          "grad_norm": 2.013567850501714
        },
        {
          "step": 1070,
          "loss": 0.17008012533187866,
          "grad_norm": 1.3792527623696371
        },
        {
          "step": 1075,
          "loss": 0.5844253301620483,
          "grad_norm": 2.6838971339857522
        },
        {
          "step": 1080,
          "loss": 0.2965054512023926,
          "grad_norm": 1.5911075949526818
        },
        {
          "step": 1085,
          "loss": 0.1920091211795807,
          "grad_norm": 1.9285206380260784
        },
        {
          "step": 1090,
          "loss": 0.17982155084609985,
          "grad_norm": 1.6332265509847472
        },
        {
          "step": 1095,
          "loss": 0.24514716863632202,
          "grad_norm": 1.6960072864610054
        },
        {
          "step": 1100,
          "loss": 0.11595350503921509,
          "grad_norm": 1.4376904723003563
        },
        {
          "step": 1105,
          "loss": 0.35210204124450684,
          "grad_norm": 2.5312069492578626
        },
        {
          "step": 1110,
          "loss": 0.20064878463745117,
          "grad_norm": 2.039548380125102
        },
        {
          "step": 1115,
          "loss": 0.18026423454284668,
          "grad_norm": 2.108072331158665
        },
        {
          "step": 1120,
          "loss": 0.20822551846504211,
          "grad_norm": 1.1678599392092954
        },
        {
          "step": 1125,
          "loss": 0.21097834408283234,
          "grad_norm": 2.1398546710347217
        },
        {
          "step": 1130,
          "loss": 0.05146905779838562,
          "grad_norm": 0.591955528209176
        },
        {
          "step": 1135,
          "loss": 0.15108846127986908,
          "grad_norm": 1.6838277230685808
        },
        {
          "step": 1140,
          "loss": 0.19297239184379578,
          "grad_norm": 1.9260123214650775
        },
        {
          "step": 1145,
          "loss": 0.3331852853298187,
          "grad_norm": 1.7673962234514782
        },
        {
          "step": 1150,
          "loss": 0.21601060032844543,
          "grad_norm": 2.363351463780217
        },
        {
          "step": 1155,
          "loss": 0.2822341322898865,
          "grad_norm": 2.25656414718465
        },
        {
          "step": 1160,
          "loss": 0.11373679339885712,
          "grad_norm": 1.307376525990881
        },
        {
          "step": 1165,
          "loss": 0.3517580032348633,
          "grad_norm": 2.328727810745254
        },
        {
          "step": 1170,
          "loss": 0.20251736044883728,
          "grad_norm": 2.148764345268051
        },
        {
          "step": 1175,
          "loss": 0.32289737462997437,
          "grad_norm": 2.4733172566182393
        },
        {
          "step": 1180,
          "loss": 0.20919151604175568,
          "grad_norm": 1.9997356798681436
        },
        {
          "step": 1185,
          "loss": 0.4549635648727417,
          "grad_norm": 1.900050274949811
        },
        {
          "step": 1190,
          "loss": 0.16992291808128357,
          "grad_norm": 1.9813822267983154
        },
        {
          "step": 1195,
          "loss": 0.41335105895996094,
          "grad_norm": 2.7694632389380027
        },
        {
          "step": 1200,
          "loss": 0.14578299224376678,
          "grad_norm": 1.9256710696081014
        },
        {
          "step": 1205,
          "loss": 0.1306113302707672,
          "grad_norm": 1.4628115754157986
        },
        {
          "step": 1210,
          "loss": 0.20221467316150665,
          "grad_norm": 2.5274548406627737
        },
        {
          "step": 1215,
          "loss": 0.28917133808135986,
          "grad_norm": 2.2573738371264063
        },
        {
          "step": 1220,
          "loss": 0.24404799938201904,
          "grad_norm": 2.6002200961718898
        },
        {
          "step": 1225,
          "loss": 0.13555684685707092,
          "grad_norm": 1.8267251381403316
        },
        {
          "step": 1230,
          "loss": 0.08279028534889221,
          "grad_norm": 1.1752204162230953
        },
        {
          "step": 1235,
          "loss": 0.08968658745288849,
          "grad_norm": 1.3236110135576216
        },
        {
          "step": 1240,
          "loss": 0.13441410660743713,
          "grad_norm": 0.8833643439144102
        },
        {
          "step": 1245,
          "loss": 0.14048685133457184,
          "grad_norm": 1.2236099622499375
        },
        {
          "step": 1250,
          "loss": 0.3625173568725586,
          "grad_norm": 2.7326935671088193
        },
        {
          "step": 1255,
          "loss": 0.12039592862129211,
          "grad_norm": 1.2687400372850322
        },
        {
          "step": 1260,
          "loss": 0.20617027580738068,
          "grad_norm": 1.7602449613684732
        },
        {
          "step": 1265,
          "loss": 0.2623395323753357,
          "grad_norm": 2.4118118094372725
        },
        {
          "step": 1270,
          "loss": 0.2321469932794571,
          "grad_norm": 1.4619825494753358
        },
        {
          "step": 1275,
          "loss": 0.1214025467634201,
          "grad_norm": 1.5436907115959464
        },
        {
          "step": 1280,
          "loss": 0.2563752233982086,
          "grad_norm": 1.542977133505944
        },
        {
          "step": 1285,
          "loss": 0.0949050784111023,
          "grad_norm": 1.0600212939053444
        },
        {
          "step": 1290,
          "loss": 0.36625000834465027,
          "grad_norm": 2.4302302821945476
        },
        {
          "step": 1295,
          "loss": 0.37006622552871704,
          "grad_norm": 1.8500236895502438
        },
        {
          "step": 1300,
          "loss": 0.28385448455810547,
          "grad_norm": 2.409586737096226
        },
        {
          "step": 1305,
          "loss": 0.2423911839723587,
          "grad_norm": 2.421921755325521
        },
        {
          "step": 1310,
          "loss": 0.10197461396455765,
          "grad_norm": 1.1774211277800828
        },
        {
          "step": 1315,
          "loss": 0.154829740524292,
          "grad_norm": 0.9587365185347305
        },
        {
          "step": 1320,
          "loss": 0.36683595180511475,
          "grad_norm": 2.4127258314368794
        },
        {
          "step": 1325,
          "loss": 0.11841221153736115,
          "grad_norm": 1.394490813151141
        },
        {
          "step": 1330,
          "loss": 0.25848379731178284,
          "grad_norm": 2.135362737241556
        },
        {
          "step": 1335,
          "loss": 0.31512147188186646,
          "grad_norm": 1.4372138104668088
        },
        {
          "step": 1340,
          "loss": 0.3824266791343689,
          "grad_norm": 2.293065212824121
        },
        {
          "step": 1345,
          "loss": 0.21008139848709106,
          "grad_norm": 1.6349417387158267
        },
        {
          "step": 1350,
          "loss": 0.3172457814216614,
          "grad_norm": 1.8558699909968606
        },
        {
          "step": 1355,
          "loss": 0.24559719860553741,
          "grad_norm": 1.8080094477716964
        },
        {
          "step": 1360,
          "loss": 0.32358402013778687,
          "grad_norm": 2.946407400650728
        },
        {
          "step": 1365,
          "loss": 0.1320098638534546,
          "grad_norm": 1.4681140605664105
        },
        {
          "step": 1370,
          "loss": 0.3152470588684082,
          "grad_norm": 1.715756911716858
        },
        {
          "step": 1375,
          "loss": 0.24489013850688934,
          "grad_norm": 1.56590418921033
        },
        {
          "step": 1380,
          "loss": 0.2161097675561905,
          "grad_norm": 2.004952212299877
        },
        {
          "step": 1385,
          "loss": 0.21251066029071808,
          "grad_norm": 2.0462682640051093
        },
        {
          "step": 1390,
          "loss": 0.1675850749015808,
          "grad_norm": 1.3284221664605276
        },
        {
          "step": 1395,
          "loss": 0.32741695642471313,
          "grad_norm": 1.667403739234444
        },
        {
          "step": 1400,
          "loss": 0.2810867428779602,
          "grad_norm": 2.169387781401904
        },
        {
          "step": 1405,
          "loss": 0.11793653666973114,
          "grad_norm": 0.9904979856369824
        },
        {
          "step": 1410,
          "loss": 0.2522937059402466,
          "grad_norm": 2.0327340275078143
        },
        {
          "step": 1415,
          "loss": 0.163772851228714,
          "grad_norm": 1.3908712089559156
        },
        {
          "step": 1420,
          "loss": 0.22908943891525269,
          "grad_norm": 1.6706386955284616
        },
        {
          "step": 1425,
          "loss": 0.21874311566352844,
          "grad_norm": 2.5805156614889686
        },
        {
          "step": 1430,
          "loss": 0.272221177816391,
          "grad_norm": 2.686274471199066
        },
        {
          "step": 1435,
          "loss": 0.42873886227607727,
          "grad_norm": 2.1549111048004956
        },
        {
          "step": 1440,
          "loss": 0.27119767665863037,
          "grad_norm": 2.316285457711168
        },
        {
          "step": 1445,
          "loss": 0.30132347345352173,
          "grad_norm": 1.9185072878591451
        },
        {
          "step": 1450,
          "loss": 0.15241852402687073,
          "grad_norm": 1.7342254452962638
        },
        {
          "step": 1455,
          "loss": 0.23650458455085754,
          "grad_norm": 1.5277945923480052
        },
        {
          "step": 1460,
          "loss": 0.2806224226951599,
          "grad_norm": 2.13270954543298
        },
        {
          "step": 1465,
          "loss": 0.18143361806869507,
          "grad_norm": 1.6230002682277531
        },
        {
          "step": 1470,
          "loss": 0.2694401144981384,
          "grad_norm": 2.2206559220825253
        },
        {
          "step": 1475,
          "loss": 0.4080314636230469,
          "grad_norm": 2.448967266631838
        },
        {
          "step": 1480,
          "loss": 0.17351530492305756,
          "grad_norm": 1.4410795706619048
        },
        {
          "step": 1485,
          "loss": 0.14289841055870056,
          "grad_norm": 2.110828756015493
        },
        {
          "step": 1490,
          "loss": 0.29080939292907715,
          "grad_norm": 2.729786592700036
        },
        {
          "step": 1495,
          "loss": 0.304161012172699,
          "grad_norm": 2.495531290769228
        },
        {
          "step": 1500,
          "loss": 0.18767008185386658,
          "grad_norm": 1.485821560956073
        },
        {
          "step": 1505,
          "loss": 0.17852288484573364,
          "grad_norm": 1.9667363778463842
        },
        {
          "step": 1510,
          "loss": 0.2982116937637329,
          "grad_norm": 1.9237996805337974
        },
        {
          "step": 1515,
          "loss": 0.18456998467445374,
          "grad_norm": 1.4344661090706738
        },
        {
          "step": 1520,
          "loss": 0.11860533058643341,
          "grad_norm": 1.3247939240160023
        },
        {
          "step": 1525,
          "loss": 0.12300250679254532,
          "grad_norm": 1.560716458491605
        },
        {
          "step": 1530,
          "loss": 0.17786714434623718,
          "grad_norm": 1.6090620417185748
        },
        {
          "step": 1535,
          "loss": 0.11554794758558273,
          "grad_norm": 1.228555712286393
        },
        {
          "step": 1540,
          "loss": 0.08000781387090683,
          "grad_norm": 1.1839980918847255
        },
        {
          "step": 1545,
          "loss": 0.14671650528907776,
          "grad_norm": 1.4501574858427417
        },
        {
          "step": 1550,
          "loss": 0.3144969046115875,
          "grad_norm": 2.6115527308382385
        },
        {
          "step": 1555,
          "loss": 0.30513548851013184,
          "grad_norm": 1.7850904300268797
        },
        {
          "step": 1560,
          "loss": 0.16010938584804535,
          "grad_norm": 2.0732307565441506
        },
        {
          "step": 1565,
          "loss": 0.19276678562164307,
          "grad_norm": 1.8101046164515249
        },
        {
          "step": 1570,
          "loss": 0.22682853043079376,
          "grad_norm": 2.144217694932228
        },
        {
          "step": 1575,
          "loss": 0.07965253293514252,
          "grad_norm": 0.8683309578351136
        },
        {
          "step": 1580,
          "loss": 0.25955426692962646,
          "grad_norm": 2.1683160595668216
        },
        {
          "step": 1585,
          "loss": 0.18087098002433777,
          "grad_norm": 1.7689758003226725
        },
        {
          "step": 1590,
          "loss": 0.29005342721939087,
          "grad_norm": 2.5665866764422938
        },
        {
          "step": 1595,
          "loss": 0.13832658529281616,
          "grad_norm": 1.6233332058430594
        },
        {
          "step": 1600,
          "loss": 0.38327500224113464,
          "grad_norm": 3.2330268864911766
        },
        {
          "step": 1605,
          "loss": 0.19859987497329712,
          "grad_norm": 2.2013744920467477
        },
        {
          "step": 1610,
          "loss": 0.3489300310611725,
          "grad_norm": 2.259466909516826
        },
        {
          "step": 1615,
          "loss": 0.3657590448856354,
          "grad_norm": 2.4148484615927677
        },
        {
          "step": 1620,
          "loss": 0.05133702605962753,
          "grad_norm": 0.6382896648260963
        },
        {
          "step": 1625,
          "loss": 0.33177536725997925,
          "grad_norm": 1.7328955091062486
        },
        {
          "step": 1630,
          "loss": 0.16944003105163574,
          "grad_norm": 1.9469090412889996
        },
        {
          "step": 1635,
          "loss": 0.17210623621940613,
          "grad_norm": 1.3195011286456444
        },
        {
          "step": 1640,
          "loss": 0.29511839151382446,
          "grad_norm": 2.3549150141182116
        },
        {
          "step": 1645,
          "loss": 0.1424711048603058,
          "grad_norm": 1.1356201822460419
        },
        {
          "step": 1650,
          "loss": 0.30701857805252075,
          "grad_norm": 2.1858808771309177
        },
        {
          "step": 1655,
          "loss": 0.30401086807250977,
          "grad_norm": 2.2414264783389837
        },
        {
          "step": 1660,
          "loss": 0.1837012767791748,
          "grad_norm": 1.9637644376427275
        },
        {
          "step": 1665,
          "loss": 0.2562338709831238,
          "grad_norm": 1.482438388106172
        },
        {
          "step": 1670,
          "loss": 0.05050646886229515,
          "grad_norm": 1.025422087903262
        },
        {
          "step": 1675,
          "loss": 0.24454651772975922,
          "grad_norm": 1.7316154425341266
        },
        {
          "step": 1680,
          "loss": 0.1874801367521286,
          "grad_norm": 1.3548627931471242
        },
        {
          "step": 1685,
          "loss": 0.25117501616477966,
          "grad_norm": 2.5866238243524333
        },
        {
          "step": 1690,
          "loss": 0.28426647186279297,
          "grad_norm": 2.898211940106121
        },
        {
          "step": 1695,
          "loss": 0.08239559829235077,
          "grad_norm": 1.0646114493568017
        },
        {
          "step": 1700,
          "loss": 0.24353840947151184,
          "grad_norm": 2.5925751835810456
        },
        {
          "step": 1705,
          "loss": 0.2630201578140259,
          "grad_norm": 1.5675671426760311
        },
        {
          "step": 1710,
          "loss": 0.25486207008361816,
          "grad_norm": 1.854393987917387
        },
        {
          "step": 1715,
          "loss": 0.2774352729320526,
          "grad_norm": 2.13530400594312
        },
        {
          "step": 1720,
          "loss": 0.40086203813552856,
          "grad_norm": 2.4509117408868604
        },
        {
          "step": 1725,
          "loss": 0.31439417600631714,
          "grad_norm": 2.672020744982942
        },
        {
          "step": 1730,
          "loss": 0.35479646921157837,
          "grad_norm": 3.024597869700315
        },
        {
          "step": 1735,
          "loss": 0.20763739943504333,
          "grad_norm": 1.536814261419475
        },
        {
          "step": 1740,
          "loss": 0.24021390080451965,
          "grad_norm": 3.0497556212512116
        },
        {
          "step": 1745,
          "loss": 0.27767854928970337,
          "grad_norm": 1.9360516493146775
        },
        {
          "step": 1750,
          "loss": 0.1555313766002655,
          "grad_norm": 1.0792899877306332
        },
        {
          "step": 1755,
          "loss": 0.2029845416545868,
          "grad_norm": 1.9928833090521894
        },
        {
          "step": 1760,
          "loss": 0.17743083834648132,
          "grad_norm": 1.9584330100495015
        },
        {
          "step": 1765,
          "loss": 0.27180802822113037,
          "grad_norm": 1.868655665513781
        },
        {
          "step": 1770,
          "loss": 0.2429015189409256,
          "grad_norm": 1.9810868468978373
        },
        {
          "step": 1775,
          "loss": 0.0786128044128418,
          "grad_norm": 1.2284587490796484
        },
        {
          "step": 1780,
          "loss": 0.27127307653427124,
          "grad_norm": 2.154986130815325
        },
        {
          "step": 1785,
          "loss": 0.07528312504291534,
          "grad_norm": 1.1706328998983477
        },
        {
          "step": 1790,
          "loss": 0.21201995015144348,
          "grad_norm": 1.5687813118806273
        },
        {
          "step": 1795,
          "loss": 0.1948804259300232,
          "grad_norm": 1.4756015149662813
        },
        {
          "step": 1800,
          "loss": 0.16444192826747894,
          "grad_norm": 2.076930167343459
        },
        {
          "step": 1805,
          "loss": 0.2505432367324829,
          "grad_norm": 1.855757448768757
        },
        {
          "step": 1810,
          "loss": 0.2573055624961853,
          "grad_norm": 2.289281717008934
        },
        {
          "step": 1815,
          "loss": 0.3898029029369354,
          "grad_norm": 2.284604656030286
        },
        {
          "step": 1820,
          "loss": 0.13026876747608185,
          "grad_norm": 1.8968738664807492
        },
        {
          "step": 1825,
          "loss": 0.10875969380140305,
          "grad_norm": 1.320651175480476
        },
        {
          "step": 1830,
          "loss": 0.1973291039466858,
          "grad_norm": 2.152183968920648
        },
        {
          "step": 1835,
          "loss": 0.1429883986711502,
          "grad_norm": 1.453468897287407
        },
        {
          "step": 1840,
          "loss": 0.21231023967266083,
          "grad_norm": 1.8699477112726295
        },
        {
          "step": 1845,
          "loss": 0.1544308066368103,
          "grad_norm": 1.453502402378288
        },
        {
          "step": 1850,
          "loss": 0.13146263360977173,
          "grad_norm": 1.5170137770627545
        },
        {
          "step": 1855,
          "loss": 0.1671745330095291,
          "grad_norm": 1.3160467107264346
        },
        {
          "step": 1860,
          "loss": 0.1630348116159439,
          "grad_norm": 1.325651015704705
        },
        {
          "step": 1865,
          "loss": 0.27040284872055054,
          "grad_norm": 2.0828422625310665
        },
        {
          "step": 1870,
          "loss": 0.05810222029685974,
          "grad_norm": 0.7747030919659579
        },
        {
          "step": 1875,
          "loss": 0.08071884512901306,
          "grad_norm": 2.035719806574598
        },
        {
          "step": 1880,
          "loss": 0.2652667760848999,
          "grad_norm": 1.4976375571539855
        },
        {
          "step": 1885,
          "loss": 0.1995408535003662,
          "grad_norm": 1.7939084807708476
        },
        {
          "step": 1890,
          "loss": 0.08887811750173569,
          "grad_norm": 1.2709928440213383
        },
        {
          "step": 1895,
          "loss": 0.20573017001152039,
          "grad_norm": 1.7795291589016116
        },
        {
          "step": 1900,
          "loss": 0.2076561152935028,
          "grad_norm": 1.7132021377177746
        },
        {
          "step": 1905,
          "loss": 0.16364935040473938,
          "grad_norm": 1.229292471241425
        },
        {
          "step": 1910,
          "loss": 0.1349954903125763,
          "grad_norm": 1.1831397356501843
        },
        {
          "step": 1915,
          "loss": 0.31824034452438354,
          "grad_norm": 1.6180154583175617
        },
        {
          "step": 1920,
          "loss": 0.1352476179599762,
          "grad_norm": 2.050429587241258
        },
        {
          "step": 1925,
          "loss": 0.058328453451395035,
          "grad_norm": 0.7185395908873183
        },
        {
          "step": 1930,
          "loss": 0.23575955629348755,
          "grad_norm": 1.7478841198338846
        },
        {
          "step": 1935,
          "loss": 0.3311229944229126,
          "grad_norm": 2.046174762347835
        },
        {
          "step": 1940,
          "loss": 0.25858041644096375,
          "grad_norm": 1.8843783299073433
        },
        {
          "step": 1945,
          "loss": 0.2952263653278351,
          "grad_norm": 2.425886161756939
        },
        {
          "step": 1950,
          "loss": 0.044152483344078064,
          "grad_norm": 0.5959000467137999
        },
        {
          "step": 1955,
          "loss": 0.14520364999771118,
          "grad_norm": 1.5057535070238894
        },
        {
          "step": 1960,
          "loss": 0.2468685507774353,
          "grad_norm": 2.069055554765002
        },
        {
          "step": 1965,
          "loss": 0.15361303091049194,
          "grad_norm": 1.8658124524890023
        },
        {
          "step": 1970,
          "loss": 0.19842112064361572,
          "grad_norm": 1.562699271327725
        },
        {
          "step": 1975,
          "loss": 0.23357939720153809,
          "grad_norm": 1.7500664730230329
        },
        {
          "step": 1980,
          "loss": 0.1553601622581482,
          "grad_norm": 1.1029042799409432
        },
        {
          "step": 1985,
          "loss": 0.07915709167718887,
          "grad_norm": 1.2666574345337174
        },
        {
          "step": 1990,
          "loss": 0.15413112938404083,
          "grad_norm": 1.3363037641395343
        },
        {
          "step": 1995,
          "loss": 0.22384265065193176,
          "grad_norm": 1.7255576676811852
        }
      ],
      "final_accuracy": 0.9437,
      "total_steps": 2000,
      "checkpoint_steps": [
        100,
        1000,
        2000
      ],
      "elapsed_time": 35.50213098526001
    }
  ]
}