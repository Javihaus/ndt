{
  "total_time": 69.79573917388916,
  "num_experiments": 3,
  "experiments": [
    {
      "experiment_name": "transformer_deep_mnist",
      "measurements": [
        {
          "step": 1000,
          "loss": 0.12818124890327454,
          "grad_norm": 0.9980146559557901
        },
        {
          "step": 1005,
          "loss": 0.09122681617736816,
          "grad_norm": 1.2838671688528316
        },
        {
          "step": 1010,
          "loss": 0.07237865775823593,
          "grad_norm": 0.8892996217943615
        },
        {
          "step": 1015,
          "loss": 0.07938127219676971,
          "grad_norm": 0.9770123961353798
        },
        {
          "step": 1020,
          "loss": 0.13471463322639465,
          "grad_norm": 1.1067849554857097
        },
        {
          "step": 1025,
          "loss": 0.06200508773326874,
          "grad_norm": 0.8224129967642472
        },
        {
          "step": 1030,
          "loss": 0.11296655982732773,
          "grad_norm": 1.043269993890015
        },
        {
          "step": 1035,
          "loss": 0.2069939225912094,
          "grad_norm": 1.747443177458189
        },
        {
          "step": 1040,
          "loss": 0.13535332679748535,
          "grad_norm": 1.8497356228007296
        },
        {
          "step": 1045,
          "loss": 0.23248255252838135,
          "grad_norm": 1.7969683117204227
        },
        {
          "step": 1050,
          "loss": 0.1779511421918869,
          "grad_norm": 1.7788157945815548
        },
        {
          "step": 1055,
          "loss": 0.08291768282651901,
          "grad_norm": 1.0217307884378661
        },
        {
          "step": 1060,
          "loss": 0.09599168598651886,
          "grad_norm": 1.2047579807336912
        },
        {
          "step": 1065,
          "loss": 0.19627103209495544,
          "grad_norm": 1.7223647231676076
        },
        {
          "step": 1070,
          "loss": 0.2227514684200287,
          "grad_norm": 1.925396595833445
        },
        {
          "step": 1075,
          "loss": 0.1756151020526886,
          "grad_norm": 1.2249643020049037
        },
        {
          "step": 1080,
          "loss": 0.22076432406902313,
          "grad_norm": 1.4553466794030145
        },
        {
          "step": 1085,
          "loss": 0.07803168892860413,
          "grad_norm": 1.0912199825770197
        },
        {
          "step": 1090,
          "loss": 0.34590721130371094,
          "grad_norm": 1.7522922151130451
        },
        {
          "step": 1095,
          "loss": 0.14505743980407715,
          "grad_norm": 1.494365114832361
        },
        {
          "step": 1100,
          "loss": 0.18489807844161987,
          "grad_norm": 1.228053867436038
        },
        {
          "step": 1105,
          "loss": 0.1340639293193817,
          "grad_norm": 1.3291411424207258
        },
        {
          "step": 1110,
          "loss": 0.16014710068702698,
          "grad_norm": 0.839591254192305
        },
        {
          "step": 1115,
          "loss": 0.1280500292778015,
          "grad_norm": 1.0185825432092224
        },
        {
          "step": 1120,
          "loss": 0.2868620753288269,
          "grad_norm": 1.6992809128033983
        },
        {
          "step": 1125,
          "loss": 0.1645529866218567,
          "grad_norm": 1.7115248339590847
        },
        {
          "step": 1130,
          "loss": 0.1321573704481125,
          "grad_norm": 0.46013822406939353
        },
        {
          "step": 1135,
          "loss": 0.09643229842185974,
          "grad_norm": 1.2810762214441944
        },
        {
          "step": 1140,
          "loss": 0.1825110763311386,
          "grad_norm": 1.6858146617264098
        },
        {
          "step": 1145,
          "loss": 0.01160769909620285,
          "grad_norm": 0.1156620701340427
        },
        {
          "step": 1150,
          "loss": 0.16290660202503204,
          "grad_norm": 1.682531232394043
        },
        {
          "step": 1155,
          "loss": 0.08200100064277649,
          "grad_norm": 0.9225054746714634
        },
        {
          "step": 1160,
          "loss": 0.2635161578655243,
          "grad_norm": 1.7742733342224966
        },
        {
          "step": 1165,
          "loss": 0.0477091446518898,
          "grad_norm": 0.7919127316599759
        },
        {
          "step": 1170,
          "loss": 0.3146212697029114,
          "grad_norm": 1.764383910790364
        },
        {
          "step": 1175,
          "loss": 0.15083986520767212,
          "grad_norm": 1.2844352005674107
        },
        {
          "step": 1180,
          "loss": 0.08845017850399017,
          "grad_norm": 1.1785996375468142
        },
        {
          "step": 1185,
          "loss": 0.11921481788158417,
          "grad_norm": 1.51780536007079
        },
        {
          "step": 1190,
          "loss": 0.22511358559131622,
          "grad_norm": 2.2547041558936822
        },
        {
          "step": 1195,
          "loss": 0.05615271255373955,
          "grad_norm": 0.8047539192954409
        },
        {
          "step": 1200,
          "loss": 0.13937729597091675,
          "grad_norm": 1.1548688291491942
        },
        {
          "step": 1205,
          "loss": 0.0976557582616806,
          "grad_norm": 1.5751379574349724
        },
        {
          "step": 1210,
          "loss": 0.1631958782672882,
          "grad_norm": 1.3418191811571571
        },
        {
          "step": 1215,
          "loss": 0.30712687969207764,
          "grad_norm": 1.874204201958294
        },
        {
          "step": 1220,
          "loss": 0.2759988307952881,
          "grad_norm": 1.667446027135992
        },
        {
          "step": 1225,
          "loss": 0.20249223709106445,
          "grad_norm": 1.4643306923984272
        },
        {
          "step": 1230,
          "loss": 0.1428309679031372,
          "grad_norm": 1.4254719414439385
        },
        {
          "step": 1235,
          "loss": 0.09695243090391159,
          "grad_norm": 1.1781340833085043
        },
        {
          "step": 1240,
          "loss": 0.16225150227546692,
          "grad_norm": 0.81782112458235
        },
        {
          "step": 1245,
          "loss": 0.055504731833934784,
          "grad_norm": 0.9677849646901308
        },
        {
          "step": 1250,
          "loss": 0.1735140085220337,
          "grad_norm": 1.4324903662582829
        },
        {
          "step": 1255,
          "loss": 0.20651981234550476,
          "grad_norm": 1.9481669782077238
        },
        {
          "step": 1260,
          "loss": 0.13302350044250488,
          "grad_norm": 1.270649100796475
        },
        {
          "step": 1265,
          "loss": 0.19512949883937836,
          "grad_norm": 1.374863346175352
        },
        {
          "step": 1270,
          "loss": 0.1590057760477066,
          "grad_norm": 1.160399553160318
        },
        {
          "step": 1275,
          "loss": 0.2142919898033142,
          "grad_norm": 1.5454876362487449
        },
        {
          "step": 1280,
          "loss": 0.27672165632247925,
          "grad_norm": 1.1904043171437935
        },
        {
          "step": 1285,
          "loss": 0.30822688341140747,
          "grad_norm": 1.6516597833670283
        },
        {
          "step": 1290,
          "loss": 0.25025737285614014,
          "grad_norm": 1.755550844239266
        },
        {
          "step": 1295,
          "loss": 0.1930203139781952,
          "grad_norm": 1.2983480914807501
        },
        {
          "step": 1300,
          "loss": 0.1155586987733841,
          "grad_norm": 1.340955246280414
        },
        {
          "step": 1305,
          "loss": 0.038808830082416534,
          "grad_norm": 0.6225556571928266
        },
        {
          "step": 1310,
          "loss": 0.15775935351848602,
          "grad_norm": 1.6479579547878536
        },
        {
          "step": 1315,
          "loss": 0.18680931627750397,
          "grad_norm": 1.7632271233677912
        },
        {
          "step": 1320,
          "loss": 0.23842957615852356,
          "grad_norm": 1.523556774023581
        },
        {
          "step": 1325,
          "loss": 0.14851625263690948,
          "grad_norm": 1.464183699114201
        },
        {
          "step": 1330,
          "loss": 0.1779872179031372,
          "grad_norm": 1.6209306883499555
        },
        {
          "step": 1335,
          "loss": 0.15520155429840088,
          "grad_norm": 1.6737104127500297
        },
        {
          "step": 1340,
          "loss": 0.18318897485733032,
          "grad_norm": 2.0630569572204074
        },
        {
          "step": 1345,
          "loss": 0.18632201850414276,
          "grad_norm": 1.6289711951004553
        },
        {
          "step": 1350,
          "loss": 0.04470151662826538,
          "grad_norm": 0.4542041234650261
        },
        {
          "step": 1355,
          "loss": 0.20535553991794586,
          "grad_norm": 2.0031472511173782
        },
        {
          "step": 1360,
          "loss": 0.09289002418518066,
          "grad_norm": 1.0347769259209898
        },
        {
          "step": 1365,
          "loss": 0.1747499257326126,
          "grad_norm": 1.3648439427072343
        },
        {
          "step": 1370,
          "loss": 0.13572311401367188,
          "grad_norm": 1.692059883607169
        },
        {
          "step": 1375,
          "loss": 0.07587097585201263,
          "grad_norm": 0.9253794437116647
        },
        {
          "step": 1380,
          "loss": 0.08179765939712524,
          "grad_norm": 0.6075477764118187
        },
        {
          "step": 1385,
          "loss": 0.18953189253807068,
          "grad_norm": 1.5116605908234835
        },
        {
          "step": 1390,
          "loss": 0.065589539706707,
          "grad_norm": 1.1894174181317665
        },
        {
          "step": 1395,
          "loss": 0.1043497622013092,
          "grad_norm": 1.08315294184619
        },
        {
          "step": 1400,
          "loss": 0.23436835408210754,
          "grad_norm": 1.6660199711200887
        },
        {
          "step": 1405,
          "loss": 0.073250912129879,
          "grad_norm": 1.0469791934590051
        },
        {
          "step": 1410,
          "loss": 0.032423123717308044,
          "grad_norm": 0.6894352618631833
        },
        {
          "step": 1415,
          "loss": 0.11862656474113464,
          "grad_norm": 1.473738828015737
        },
        {
          "step": 1420,
          "loss": 0.13406451046466827,
          "grad_norm": 1.0703138130193184
        },
        {
          "step": 1425,
          "loss": 0.1550695300102234,
          "grad_norm": 1.51698658307178
        },
        {
          "step": 1430,
          "loss": 0.1432780921459198,
          "grad_norm": 1.343283639240326
        },
        {
          "step": 1435,
          "loss": 0.1208987683057785,
          "grad_norm": 1.2995105893272085
        },
        {
          "step": 1440,
          "loss": 0.07807337492704391,
          "grad_norm": 1.357002267621235
        },
        {
          "step": 1445,
          "loss": 0.11658190190792084,
          "grad_norm": 1.3805081520220257
        },
        {
          "step": 1450,
          "loss": 0.23053178191184998,
          "grad_norm": 2.4991057716019847
        },
        {
          "step": 1455,
          "loss": 0.10736846923828125,
          "grad_norm": 1.7928010286743588
        },
        {
          "step": 1460,
          "loss": 0.17107418179512024,
          "grad_norm": 1.856300549546836
        },
        {
          "step": 1465,
          "loss": 0.2634400725364685,
          "grad_norm": 1.7977119650598912
        },
        {
          "step": 1470,
          "loss": 0.26122862100601196,
          "grad_norm": 1.5822903837849422
        },
        {
          "step": 1475,
          "loss": 0.1668088138103485,
          "grad_norm": 1.5985242156081094
        },
        {
          "step": 1480,
          "loss": 0.1216241866350174,
          "grad_norm": 1.1500451296128014
        },
        {
          "step": 1485,
          "loss": 0.12026101350784302,
          "grad_norm": 1.0380004997809187
        },
        {
          "step": 1490,
          "loss": 0.24325791001319885,
          "grad_norm": 1.1222386327431277
        },
        {
          "step": 1495,
          "loss": 0.1374933272600174,
          "grad_norm": 1.6125711101137565
        },
        {
          "step": 1500,
          "loss": 0.20226863026618958,
          "grad_norm": 1.362293640546444
        },
        {
          "step": 1505,
          "loss": 0.23011192679405212,
          "grad_norm": 1.2488869511434606
        },
        {
          "step": 1510,
          "loss": 0.1440686583518982,
          "grad_norm": 1.9165038148057612
        },
        {
          "step": 1515,
          "loss": 0.18883991241455078,
          "grad_norm": 1.4062193323553944
        },
        {
          "step": 1520,
          "loss": 0.14366082847118378,
          "grad_norm": 1.7061649302170774
        },
        {
          "step": 1525,
          "loss": 0.12224519997835159,
          "grad_norm": 1.236341751658367
        },
        {
          "step": 1530,
          "loss": 0.13111689686775208,
          "grad_norm": 1.5566659893446002
        },
        {
          "step": 1535,
          "loss": 0.1979498714208603,
          "grad_norm": 1.653078316585054
        },
        {
          "step": 1540,
          "loss": 0.15841719508171082,
          "grad_norm": 1.5207967814511842
        },
        {
          "step": 1545,
          "loss": 0.23611843585968018,
          "grad_norm": 1.746299711269039
        },
        {
          "step": 1550,
          "loss": 0.12436006963253021,
          "grad_norm": 1.2198042012083712
        },
        {
          "step": 1555,
          "loss": 0.12331266701221466,
          "grad_norm": 1.5210175898229186
        },
        {
          "step": 1560,
          "loss": 0.2820679545402527,
          "grad_norm": 2.312509252550088
        },
        {
          "step": 1565,
          "loss": 0.13788241147994995,
          "grad_norm": 1.1371225607875048
        },
        {
          "step": 1570,
          "loss": 0.07362989336252213,
          "grad_norm": 0.8733307699798827
        },
        {
          "step": 1575,
          "loss": 0.05952797085046768,
          "grad_norm": 0.933025082977009
        },
        {
          "step": 1580,
          "loss": 0.1586959809064865,
          "grad_norm": 1.4048783667657105
        },
        {
          "step": 1585,
          "loss": 0.13180392980575562,
          "grad_norm": 1.1758597400793618
        },
        {
          "step": 1590,
          "loss": 0.24956685304641724,
          "grad_norm": 1.2186433894475721
        },
        {
          "step": 1595,
          "loss": 0.31171613931655884,
          "grad_norm": 1.6555443695930088
        },
        {
          "step": 1600,
          "loss": 0.1106051653623581,
          "grad_norm": 1.0473949562506508
        },
        {
          "step": 1605,
          "loss": 0.0684579387307167,
          "grad_norm": 0.6619906316418607
        },
        {
          "step": 1610,
          "loss": 0.09356555342674255,
          "grad_norm": 1.1473969613365707
        },
        {
          "step": 1615,
          "loss": 0.01850617304444313,
          "grad_norm": 0.4626790662817778
        },
        {
          "step": 1620,
          "loss": 0.24613238871097565,
          "grad_norm": 1.6501960571943288
        },
        {
          "step": 1625,
          "loss": 0.10801995545625687,
          "grad_norm": 1.1734219521325515
        },
        {
          "step": 1630,
          "loss": 0.4168335199356079,
          "grad_norm": 1.896509322827981
        },
        {
          "step": 1635,
          "loss": 0.029749952256679535,
          "grad_norm": 0.37433957871639695
        },
        {
          "step": 1640,
          "loss": 0.2022201418876648,
          "grad_norm": 1.5404074279486508
        },
        {
          "step": 1645,
          "loss": 0.12144945561885834,
          "grad_norm": 1.4010537832553778
        },
        {
          "step": 1650,
          "loss": 0.07627305388450623,
          "grad_norm": 0.8478040433940074
        },
        {
          "step": 1655,
          "loss": 0.2925734519958496,
          "grad_norm": 1.6563048842215753
        },
        {
          "step": 1660,
          "loss": 0.20336267352104187,
          "grad_norm": 2.2956165628219614
        },
        {
          "step": 1665,
          "loss": 0.06868255883455276,
          "grad_norm": 0.923445003342447
        },
        {
          "step": 1670,
          "loss": 0.1570768505334854,
          "grad_norm": 1.3946821294612917
        },
        {
          "step": 1675,
          "loss": 0.10628508031368256,
          "grad_norm": 0.7854499003939034
        },
        {
          "step": 1680,
          "loss": 0.24644735455513,
          "grad_norm": 1.938609347132993
        },
        {
          "step": 1685,
          "loss": 0.06137256324291229,
          "grad_norm": 0.7839951954238001
        },
        {
          "step": 1690,
          "loss": 0.11358201503753662,
          "grad_norm": 1.2047477452277455
        },
        {
          "step": 1695,
          "loss": 0.1341519057750702,
          "grad_norm": 1.6388072951720358
        },
        {
          "step": 1700,
          "loss": 0.14867104589939117,
          "grad_norm": 1.6383884599194596
        },
        {
          "step": 1705,
          "loss": 0.09458987414836884,
          "grad_norm": 1.4760391240366508
        },
        {
          "step": 1710,
          "loss": 0.18611371517181396,
          "grad_norm": 2.2257762058921307
        },
        {
          "step": 1715,
          "loss": 0.1815413385629654,
          "grad_norm": 1.4574732956966063
        },
        {
          "step": 1720,
          "loss": 0.3277992606163025,
          "grad_norm": 1.988212106891926
        },
        {
          "step": 1725,
          "loss": 0.09345956146717072,
          "grad_norm": 1.075903146036762
        },
        {
          "step": 1730,
          "loss": 0.0488082654774189,
          "grad_norm": 0.7973128921483997
        },
        {
          "step": 1735,
          "loss": 0.09353962540626526,
          "grad_norm": 1.0004320646794282
        },
        {
          "step": 1740,
          "loss": 0.05974747985601425,
          "grad_norm": 0.8131093266548097
        },
        {
          "step": 1745,
          "loss": 0.23002150654792786,
          "grad_norm": 1.925053110945144
        },
        {
          "step": 1750,
          "loss": 0.23195256292819977,
          "grad_norm": 2.0055079177348927
        },
        {
          "step": 1755,
          "loss": 0.3239588737487793,
          "grad_norm": 2.255907382413057
        },
        {
          "step": 1760,
          "loss": 0.15008845925331116,
          "grad_norm": 1.444426096837739
        },
        {
          "step": 1765,
          "loss": 0.23196198046207428,
          "grad_norm": 1.7999458446418821
        },
        {
          "step": 1770,
          "loss": 0.10184022784233093,
          "grad_norm": 1.1566212497585242
        },
        {
          "step": 1775,
          "loss": 0.05392422899603844,
          "grad_norm": 0.7368324159174601
        },
        {
          "step": 1780,
          "loss": 0.10822955518960953,
          "grad_norm": 1.3993744719334325
        },
        {
          "step": 1785,
          "loss": 0.11828634142875671,
          "grad_norm": 1.7573366418662275
        },
        {
          "step": 1790,
          "loss": 0.13593490421772003,
          "grad_norm": 1.1354537835936938
        },
        {
          "step": 1795,
          "loss": 0.1311023235321045,
          "grad_norm": 0.9256561862987139
        },
        {
          "step": 1800,
          "loss": 0.2729598581790924,
          "grad_norm": 1.4492713190084838
        },
        {
          "step": 1805,
          "loss": 0.10490253567695618,
          "grad_norm": 0.9696867873742404
        },
        {
          "step": 1810,
          "loss": 0.14194491505622864,
          "grad_norm": 1.145448252536181
        },
        {
          "step": 1815,
          "loss": 0.15103067457675934,
          "grad_norm": 1.2403771273213322
        },
        {
          "step": 1820,
          "loss": 0.1296287477016449,
          "grad_norm": 1.1527137727596537
        },
        {
          "step": 1825,
          "loss": 0.16765493154525757,
          "grad_norm": 1.6417166190191683
        },
        {
          "step": 1830,
          "loss": 0.09374208003282547,
          "grad_norm": 1.818375887042359
        },
        {
          "step": 1835,
          "loss": 0.177458718419075,
          "grad_norm": 1.660827298384793
        },
        {
          "step": 1840,
          "loss": 0.2295546531677246,
          "grad_norm": 2.006778070354529
        },
        {
          "step": 1845,
          "loss": 0.06661146879196167,
          "grad_norm": 1.045433827057844
        },
        {
          "step": 1850,
          "loss": 0.16573454439640045,
          "grad_norm": 1.233949848259977
        },
        {
          "step": 1855,
          "loss": 0.10605956614017487,
          "grad_norm": 1.3503076218670966
        },
        {
          "step": 1860,
          "loss": 0.16725191473960876,
          "grad_norm": 1.7372561810900653
        },
        {
          "step": 1865,
          "loss": 0.058274753391742706,
          "grad_norm": 1.0239460656693968
        },
        {
          "step": 1870,
          "loss": 0.08766667544841766,
          "grad_norm": 1.96375114329891
        },
        {
          "step": 1875,
          "loss": 0.03119099885225296,
          "grad_norm": 0.4613044689544332
        },
        {
          "step": 1880,
          "loss": 0.1182682067155838,
          "grad_norm": 0.8113346044968969
        },
        {
          "step": 1885,
          "loss": 0.027805771678686142,
          "grad_norm": 1.0216192873275125
        },
        {
          "step": 1890,
          "loss": 0.14244398474693298,
          "grad_norm": 1.21126159520027
        },
        {
          "step": 1895,
          "loss": 0.2037794142961502,
          "grad_norm": 2.1665263398958654
        },
        {
          "step": 1900,
          "loss": 0.2264156937599182,
          "grad_norm": 1.7612239658948783
        },
        {
          "step": 1905,
          "loss": 0.09526174515485764,
          "grad_norm": 1.3239130967443609
        },
        {
          "step": 1910,
          "loss": 0.036317214369773865,
          "grad_norm": 0.5162883457155081
        },
        {
          "step": 1915,
          "loss": 0.22509650886058807,
          "grad_norm": 1.928223070305968
        },
        {
          "step": 1920,
          "loss": 0.08946911990642548,
          "grad_norm": 1.1781586330513354
        },
        {
          "step": 1925,
          "loss": 0.1922151893377304,
          "grad_norm": 1.3129448257406915
        },
        {
          "step": 1930,
          "loss": 0.21662430465221405,
          "grad_norm": 1.2038625638744604
        },
        {
          "step": 1935,
          "loss": 0.16705644130706787,
          "grad_norm": 1.3031837474028602
        },
        {
          "step": 1940,
          "loss": 0.3054709732532501,
          "grad_norm": 1.7014533295060954
        },
        {
          "step": 1945,
          "loss": 0.08515562117099762,
          "grad_norm": 1.1821047596800456
        },
        {
          "step": 1950,
          "loss": 0.1767362356185913,
          "grad_norm": 1.5425046364174166
        },
        {
          "step": 1955,
          "loss": 0.06173696368932724,
          "grad_norm": 1.2887778567508885
        },
        {
          "step": 1960,
          "loss": 0.13759884238243103,
          "grad_norm": 1.1820733970714443
        },
        {
          "step": 1965,
          "loss": 0.08956748247146606,
          "grad_norm": 1.1646065751443913
        },
        {
          "step": 1970,
          "loss": 0.21325446665287018,
          "grad_norm": 1.9880663108612409
        },
        {
          "step": 1975,
          "loss": 0.18567562103271484,
          "grad_norm": 1.7948643407192002
        },
        {
          "step": 1980,
          "loss": 0.192509263753891,
          "grad_norm": 1.5653979278364938
        },
        {
          "step": 1985,
          "loss": 0.24821412563323975,
          "grad_norm": 1.664278207995178
        },
        {
          "step": 1990,
          "loss": 0.07932469248771667,
          "grad_norm": 1.1086413152036125
        },
        {
          "step": 1995,
          "loss": 0.10777055472135544,
          "grad_norm": 1.2407074137755918
        },
        {
          "step": 2000,
          "loss": 0.10097870230674744,
          "grad_norm": 1.6236198465620761
        }
      ],
      "final_accuracy": 0.9643,
      "checkpoint_path": "/content/content/checkpoints/transformer_deep_mnist/checkpoint_step_02000.pt",
      "elapsed_time": 30.880370378494263
    },
    {
      "experiment_name": "cnn_deep_mnist",
      "measurements": [
        {
          "step": 1000,
          "loss": 0.1302465945482254,
          "grad_norm": 1.3571241176620266
        },
        {
          "step": 1005,
          "loss": 0.02245449647307396,
          "grad_norm": 0.7234678260755836
        },
        {
          "step": 1010,
          "loss": 0.03766040876507759,
          "grad_norm": 1.290552451677699
        },
        {
          "step": 1015,
          "loss": 0.018503395840525627,
          "grad_norm": 0.710772674526346
        },
        {
          "step": 1020,
          "loss": 0.02393364906311035,
          "grad_norm": 0.8474008915055331
        },
        {
          "step": 1025,
          "loss": 0.019890859723091125,
          "grad_norm": 0.669035700307631
        },
        {
          "step": 1030,
          "loss": 0.003926761914044619,
          "grad_norm": 0.14786450249853522
        },
        {
          "step": 1035,
          "loss": 0.008558904752135277,
          "grad_norm": 0.3394698366364707
        },
        {
          "step": 1040,
          "loss": 0.10167354345321655,
          "grad_norm": 1.897047344454714
        },
        {
          "step": 1045,
          "loss": 0.04622070491313934,
          "grad_norm": 1.522756885547535
        },
        {
          "step": 1050,
          "loss": 0.07902117818593979,
          "grad_norm": 1.2281469658578905
        },
        {
          "step": 1055,
          "loss": 0.012469779700040817,
          "grad_norm": 0.42877494684772116
        },
        {
          "step": 1060,
          "loss": 0.05082966014742851,
          "grad_norm": 1.163387043139235
        },
        {
          "step": 1065,
          "loss": 0.13164949417114258,
          "grad_norm": 2.128012393210608
        },
        {
          "step": 1070,
          "loss": 0.02618279866874218,
          "grad_norm": 0.7577619958973121
        },
        {
          "step": 1075,
          "loss": 0.053244736045598984,
          "grad_norm": 1.1401490462094415
        },
        {
          "step": 1080,
          "loss": 0.10066437721252441,
          "grad_norm": 1.813693583187606
        },
        {
          "step": 1085,
          "loss": 0.038275569677352905,
          "grad_norm": 1.0212815478076416
        },
        {
          "step": 1090,
          "loss": 0.06112595275044441,
          "grad_norm": 1.3324524680377308
        },
        {
          "step": 1095,
          "loss": 0.013665173202753067,
          "grad_norm": 0.5292729565449217
        },
        {
          "step": 1100,
          "loss": 0.005018753930926323,
          "grad_norm": 0.1621833358115041
        },
        {
          "step": 1105,
          "loss": 0.04423188418149948,
          "grad_norm": 1.4190363061412572
        },
        {
          "step": 1110,
          "loss": 0.08059041947126389,
          "grad_norm": 1.5119085356819213
        },
        {
          "step": 1115,
          "loss": 0.018267596140503883,
          "grad_norm": 0.7713693432840314
        },
        {
          "step": 1120,
          "loss": 0.0010425668442621827,
          "grad_norm": 0.05009643786065434
        },
        {
          "step": 1125,
          "loss": 0.11912891268730164,
          "grad_norm": 2.304102358265564
        },
        {
          "step": 1130,
          "loss": 0.05019685626029968,
          "grad_norm": 2.061891541501678
        },
        {
          "step": 1135,
          "loss": 0.008317973464727402,
          "grad_norm": 0.5239732901297693
        },
        {
          "step": 1140,
          "loss": 0.011656270362436771,
          "grad_norm": 0.41959554660477655
        },
        {
          "step": 1145,
          "loss": 0.016283206641674042,
          "grad_norm": 0.6840084266444327
        },
        {
          "step": 1150,
          "loss": 0.0039029710460454226,
          "grad_norm": 0.15480731673457487
        },
        {
          "step": 1155,
          "loss": 0.029888316988945007,
          "grad_norm": 1.205321981246499
        },
        {
          "step": 1160,
          "loss": 0.007316412404179573,
          "grad_norm": 0.34266513769255963
        },
        {
          "step": 1165,
          "loss": 0.01508923526853323,
          "grad_norm": 0.45925930329019726
        },
        {
          "step": 1170,
          "loss": 0.017618509009480476,
          "grad_norm": 1.0441196289986243
        },
        {
          "step": 1175,
          "loss": 0.018851347267627716,
          "grad_norm": 0.8737651782586768
        },
        {
          "step": 1180,
          "loss": 0.04385726898908615,
          "grad_norm": 1.9164878646858061
        },
        {
          "step": 1185,
          "loss": 0.049991071224212646,
          "grad_norm": 1.4082367456276537
        },
        {
          "step": 1190,
          "loss": 0.08397290110588074,
          "grad_norm": 1.992326790180814
        },
        {
          "step": 1195,
          "loss": 0.008896236307919025,
          "grad_norm": 0.47644507679271214
        },
        {
          "step": 1200,
          "loss": 0.025815052911639214,
          "grad_norm": 1.072727895401003
        },
        {
          "step": 1205,
          "loss": 0.00447093928232789,
          "grad_norm": 0.21128790156186922
        },
        {
          "step": 1210,
          "loss": 0.09312310814857483,
          "grad_norm": 1.8211496586027895
        },
        {
          "step": 1215,
          "loss": 0.003673040773719549,
          "grad_norm": 0.12312817622956566
        },
        {
          "step": 1220,
          "loss": 0.014061970636248589,
          "grad_norm": 0.9360223714560348
        },
        {
          "step": 1225,
          "loss": 0.20140260457992554,
          "grad_norm": 2.8733537388781496
        },
        {
          "step": 1230,
          "loss": 0.05887317657470703,
          "grad_norm": 1.5150593814950466
        },
        {
          "step": 1235,
          "loss": 0.025473283603787422,
          "grad_norm": 1.1875627825681838
        },
        {
          "step": 1240,
          "loss": 0.03212884068489075,
          "grad_norm": 1.2414260074444088
        },
        {
          "step": 1245,
          "loss": 0.040131401270627975,
          "grad_norm": 0.9414613496614108
        },
        {
          "step": 1250,
          "loss": 0.00788295641541481,
          "grad_norm": 0.3759929996043292
        },
        {
          "step": 1255,
          "loss": 0.0971200093626976,
          "grad_norm": 1.6275571851086204
        },
        {
          "step": 1260,
          "loss": 0.011051693931221962,
          "grad_norm": 0.4275458715534887
        },
        {
          "step": 1265,
          "loss": 0.016506053507328033,
          "grad_norm": 0.42998768154057787
        },
        {
          "step": 1270,
          "loss": 0.014478940516710281,
          "grad_norm": 0.7052466650640733
        },
        {
          "step": 1275,
          "loss": 0.013037003576755524,
          "grad_norm": 0.7838431716965568
        },
        {
          "step": 1280,
          "loss": 0.08059641718864441,
          "grad_norm": 1.4907453934223271
        },
        {
          "step": 1285,
          "loss": 0.12264113873243332,
          "grad_norm": 2.1009734832145655
        },
        {
          "step": 1290,
          "loss": 0.023923709988594055,
          "grad_norm": 0.8285128115169641
        },
        {
          "step": 1295,
          "loss": 0.010502494871616364,
          "grad_norm": 0.29753229363787814
        },
        {
          "step": 1300,
          "loss": 0.030517272651195526,
          "grad_norm": 0.8804856401960464
        },
        {
          "step": 1305,
          "loss": 0.013005424290895462,
          "grad_norm": 0.5303203312497622
        },
        {
          "step": 1310,
          "loss": 0.10288916528224945,
          "grad_norm": 1.2665479554610384
        },
        {
          "step": 1315,
          "loss": 0.03765806928277016,
          "grad_norm": 1.281620061133337
        },
        {
          "step": 1320,
          "loss": 0.01519108284264803,
          "grad_norm": 0.7156252998290432
        },
        {
          "step": 1325,
          "loss": 0.0090263020247221,
          "grad_norm": 0.42630538158454445
        },
        {
          "step": 1330,
          "loss": 0.005175960250198841,
          "grad_norm": 0.20459542438305836
        },
        {
          "step": 1335,
          "loss": 0.0013782051391899586,
          "grad_norm": 0.07718448305614564
        },
        {
          "step": 1340,
          "loss": 0.012282712385058403,
          "grad_norm": 0.7171817137919566
        },
        {
          "step": 1345,
          "loss": 0.07593438774347305,
          "grad_norm": 1.64266120595593
        },
        {
          "step": 1350,
          "loss": 0.15226879715919495,
          "grad_norm": 1.8102136303640124
        },
        {
          "step": 1355,
          "loss": 0.11738403141498566,
          "grad_norm": 1.7636719299617771
        },
        {
          "step": 1360,
          "loss": 0.07426974177360535,
          "grad_norm": 1.7165548213004456
        },
        {
          "step": 1365,
          "loss": 0.06415344029664993,
          "grad_norm": 1.5514978051557553
        },
        {
          "step": 1370,
          "loss": 0.004306817427277565,
          "grad_norm": 0.20998179431927744
        },
        {
          "step": 1375,
          "loss": 0.014630025252699852,
          "grad_norm": 0.4956563429655359
        },
        {
          "step": 1380,
          "loss": 0.016527151688933372,
          "grad_norm": 0.6705152539686402
        },
        {
          "step": 1385,
          "loss": 0.00732597429305315,
          "grad_norm": 0.36388470076590435
        },
        {
          "step": 1390,
          "loss": 0.002518456894904375,
          "grad_norm": 0.07676370434456938
        },
        {
          "step": 1395,
          "loss": 0.03627420589327812,
          "grad_norm": 1.1310124036704703
        },
        {
          "step": 1400,
          "loss": 0.06107759103178978,
          "grad_norm": 1.3531152139781548
        },
        {
          "step": 1405,
          "loss": 0.09842373430728912,
          "grad_norm": 1.5746672584990733
        },
        {
          "step": 1410,
          "loss": 0.12779740989208221,
          "grad_norm": 1.4730908865487624
        },
        {
          "step": 1415,
          "loss": 0.015165720134973526,
          "grad_norm": 0.5901304436826778
        },
        {
          "step": 1420,
          "loss": 0.019802669063210487,
          "grad_norm": 0.6598027118513474
        },
        {
          "step": 1425,
          "loss": 0.005168694071471691,
          "grad_norm": 0.2449888177464766
        },
        {
          "step": 1430,
          "loss": 0.07372346520423889,
          "grad_norm": 1.586196981066841
        },
        {
          "step": 1435,
          "loss": 0.033128004521131516,
          "grad_norm": 1.2710524625248865
        },
        {
          "step": 1440,
          "loss": 0.07347384840250015,
          "grad_norm": 1.8960468007475253
        },
        {
          "step": 1445,
          "loss": 0.08011582493782043,
          "grad_norm": 1.4346776753071906
        },
        {
          "step": 1450,
          "loss": 0.09030821174383163,
          "grad_norm": 1.5438455982770913
        },
        {
          "step": 1455,
          "loss": 0.00256266794167459,
          "grad_norm": 0.09532480207571335
        },
        {
          "step": 1460,
          "loss": 0.03501515835523605,
          "grad_norm": 1.1329339745877114
        },
        {
          "step": 1465,
          "loss": 0.05134539306163788,
          "grad_norm": 1.3152550042091542
        },
        {
          "step": 1470,
          "loss": 0.056147489696741104,
          "grad_norm": 0.9679406275989733
        },
        {
          "step": 1475,
          "loss": 0.34909629821777344,
          "grad_norm": 1.3820475409872341
        },
        {
          "step": 1480,
          "loss": 0.0031417161226272583,
          "grad_norm": 0.06111336890791855
        },
        {
          "step": 1485,
          "loss": 0.019482042640447617,
          "grad_norm": 0.6046552227912888
        },
        {
          "step": 1490,
          "loss": 0.01713293045759201,
          "grad_norm": 0.44380738457045366
        },
        {
          "step": 1495,
          "loss": 0.137318953871727,
          "grad_norm": 1.2639720057166401
        },
        {
          "step": 1500,
          "loss": 0.03232815861701965,
          "grad_norm": 0.9752326718829402
        },
        {
          "step": 1505,
          "loss": 0.01313806138932705,
          "grad_norm": 0.5668521858699572
        },
        {
          "step": 1510,
          "loss": 0.03815401718020439,
          "grad_norm": 0.9001617266235712
        },
        {
          "step": 1515,
          "loss": 0.09845809638500214,
          "grad_norm": 1.5390194527796974
        },
        {
          "step": 1520,
          "loss": 0.06887715309858322,
          "grad_norm": 1.304976053159864
        },
        {
          "step": 1525,
          "loss": 0.0022941161878407,
          "grad_norm": 0.0744663001370083
        },
        {
          "step": 1530,
          "loss": 0.01298794336616993,
          "grad_norm": 0.44557113237349416
        },
        {
          "step": 1535,
          "loss": 0.0020998993422836065,
          "grad_norm": 0.09358108896129591
        },
        {
          "step": 1540,
          "loss": 0.006768714636564255,
          "grad_norm": 0.24682526072389738
        },
        {
          "step": 1545,
          "loss": 0.003738440340384841,
          "grad_norm": 0.15399274980734487
        },
        {
          "step": 1550,
          "loss": 0.013625695370137691,
          "grad_norm": 0.5322603805539009
        },
        {
          "step": 1555,
          "loss": 0.06418482959270477,
          "grad_norm": 1.8211139739892575
        },
        {
          "step": 1560,
          "loss": 0.023735864087939262,
          "grad_norm": 0.8302896327834932
        },
        {
          "step": 1565,
          "loss": 0.13706299662590027,
          "grad_norm": 1.6004008476027904
        },
        {
          "step": 1570,
          "loss": 0.03729450702667236,
          "grad_norm": 1.1730982193911688
        },
        {
          "step": 1575,
          "loss": 0.06280911713838577,
          "grad_norm": 1.3964329149774246
        },
        {
          "step": 1580,
          "loss": 0.12325533479452133,
          "grad_norm": 1.3464233185252472
        },
        {
          "step": 1585,
          "loss": 0.06361640244722366,
          "grad_norm": 1.5871250956404002
        },
        {
          "step": 1590,
          "loss": 0.004417305812239647,
          "grad_norm": 0.14551713304358396
        },
        {
          "step": 1595,
          "loss": 0.007895511575043201,
          "grad_norm": 0.18894725331822534
        },
        {
          "step": 1600,
          "loss": 0.014826069585978985,
          "grad_norm": 0.5703155239660549
        },
        {
          "step": 1605,
          "loss": 0.024990014731884003,
          "grad_norm": 0.9528668582215801
        },
        {
          "step": 1610,
          "loss": 0.008504016324877739,
          "grad_norm": 0.22590681144595698
        },
        {
          "step": 1615,
          "loss": 0.015377904288470745,
          "grad_norm": 0.6321566808563289
        },
        {
          "step": 1620,
          "loss": 0.026777949184179306,
          "grad_norm": 1.0249734254505771
        },
        {
          "step": 1625,
          "loss": 0.02398001402616501,
          "grad_norm": 0.5919407801607343
        },
        {
          "step": 1630,
          "loss": 0.040442634373903275,
          "grad_norm": 0.8300048227856035
        },
        {
          "step": 1635,
          "loss": 0.03159049525856972,
          "grad_norm": 1.020830216093034
        },
        {
          "step": 1640,
          "loss": 0.01262599416077137,
          "grad_norm": 0.5739504470108018
        },
        {
          "step": 1645,
          "loss": 0.005545193795114756,
          "grad_norm": 0.24714980860548738
        },
        {
          "step": 1650,
          "loss": 0.09883081167936325,
          "grad_norm": 1.7267080238117145
        },
        {
          "step": 1655,
          "loss": 0.005713093560189009,
          "grad_norm": 0.21057822344704716
        },
        {
          "step": 1660,
          "loss": 0.00254378211684525,
          "grad_norm": 0.09276412185214226
        },
        {
          "step": 1665,
          "loss": 0.009341650642454624,
          "grad_norm": 0.42176562497205455
        },
        {
          "step": 1670,
          "loss": 0.056306954473257065,
          "grad_norm": 1.5800792788720128
        },
        {
          "step": 1675,
          "loss": 0.052723050117492676,
          "grad_norm": 1.3404180058547677
        },
        {
          "step": 1680,
          "loss": 0.04555787146091461,
          "grad_norm": 1.0852701790248354
        },
        {
          "step": 1685,
          "loss": 0.022235507145524025,
          "grad_norm": 0.586436850310259
        },
        {
          "step": 1690,
          "loss": 0.010248208418488503,
          "grad_norm": 0.3311323772726216
        },
        {
          "step": 1695,
          "loss": 0.06884250044822693,
          "grad_norm": 1.5786509780529687
        },
        {
          "step": 1700,
          "loss": 0.04952515289187431,
          "grad_norm": 1.3543402666814015
        },
        {
          "step": 1705,
          "loss": 0.044530220329761505,
          "grad_norm": 1.170879553370461
        },
        {
          "step": 1710,
          "loss": 0.019312597811222076,
          "grad_norm": 0.6069545152253797
        },
        {
          "step": 1715,
          "loss": 0.01279513631016016,
          "grad_norm": 0.4641114081265322
        },
        {
          "step": 1720,
          "loss": 0.09504268318414688,
          "grad_norm": 1.2081173960489293
        },
        {
          "step": 1725,
          "loss": 0.015563912689685822,
          "grad_norm": 0.47388326778370427
        },
        {
          "step": 1730,
          "loss": 0.01960907131433487,
          "grad_norm": 0.4804219691648138
        },
        {
          "step": 1735,
          "loss": 0.020590437576174736,
          "grad_norm": 0.48932284605942444
        },
        {
          "step": 1740,
          "loss": 0.007415152154862881,
          "grad_norm": 0.37584663431898435
        },
        {
          "step": 1745,
          "loss": 0.08163674175739288,
          "grad_norm": 1.2227966867137257
        },
        {
          "step": 1750,
          "loss": 0.030609261244535446,
          "grad_norm": 1.1758072909322783
        },
        {
          "step": 1755,
          "loss": 0.06890248507261276,
          "grad_norm": 1.1504496870765653
        },
        {
          "step": 1760,
          "loss": 0.03312235325574875,
          "grad_norm": 0.9679864815047641
        },
        {
          "step": 1765,
          "loss": 0.008310497738420963,
          "grad_norm": 0.216909086836239
        },
        {
          "step": 1770,
          "loss": 0.0064088767394423485,
          "grad_norm": 0.19974474338129053
        },
        {
          "step": 1775,
          "loss": 0.01651945896446705,
          "grad_norm": 0.4309051034284519
        },
        {
          "step": 1780,
          "loss": 0.015293938107788563,
          "grad_norm": 0.5544648589572444
        },
        {
          "step": 1785,
          "loss": 0.043693576008081436,
          "grad_norm": 1.006021679396208
        },
        {
          "step": 1790,
          "loss": 0.17083370685577393,
          "grad_norm": 1.8402586535246932
        },
        {
          "step": 1795,
          "loss": 0.024099742993712425,
          "grad_norm": 0.6617439621751301
        },
        {
          "step": 1800,
          "loss": 0.005383716430515051,
          "grad_norm": 0.16971400225230898
        },
        {
          "step": 1805,
          "loss": 0.13103944063186646,
          "grad_norm": 1.8125444224723408
        },
        {
          "step": 1810,
          "loss": 0.010145142674446106,
          "grad_norm": 0.4179345900067691
        },
        {
          "step": 1815,
          "loss": 0.023547908291220665,
          "grad_norm": 0.7767321745334703
        },
        {
          "step": 1820,
          "loss": 0.01194551307708025,
          "grad_norm": 0.42472806363683213
        },
        {
          "step": 1825,
          "loss": 0.05359116569161415,
          "grad_norm": 1.1480245792913117
        },
        {
          "step": 1830,
          "loss": 0.05016210675239563,
          "grad_norm": 1.1128124367336545
        },
        {
          "step": 1835,
          "loss": 0.006567466072738171,
          "grad_norm": 0.23295231447890508
        },
        {
          "step": 1840,
          "loss": 0.008029462769627571,
          "grad_norm": 0.2787402992915711
        },
        {
          "step": 1845,
          "loss": 0.14166605472564697,
          "grad_norm": 2.798481301421582
        },
        {
          "step": 1850,
          "loss": 0.0014561014249920845,
          "grad_norm": 0.06552791291348765
        },
        {
          "step": 1855,
          "loss": 0.006173914298415184,
          "grad_norm": 0.2671454486049482
        },
        {
          "step": 1860,
          "loss": 0.009642447344958782,
          "grad_norm": 0.3550683620765274
        },
        {
          "step": 1865,
          "loss": 0.039738405495882034,
          "grad_norm": 1.3569893941826627
        },
        {
          "step": 1870,
          "loss": 0.07933542132377625,
          "grad_norm": 2.0444179664410345
        },
        {
          "step": 1875,
          "loss": 0.09872019290924072,
          "grad_norm": 1.1963111728803169
        },
        {
          "step": 1880,
          "loss": 0.013643935322761536,
          "grad_norm": 0.4543100949037603
        },
        {
          "step": 1885,
          "loss": 0.06754298508167267,
          "grad_norm": 1.6132906402599387
        },
        {
          "step": 1890,
          "loss": 0.013753494247794151,
          "grad_norm": 0.48873355688675785
        },
        {
          "step": 1895,
          "loss": 0.036807917058467865,
          "grad_norm": 1.159965784025143
        },
        {
          "step": 1900,
          "loss": 0.050821103155612946,
          "grad_norm": 1.333501804273655
        },
        {
          "step": 1905,
          "loss": 0.02637127973139286,
          "grad_norm": 0.8607332928940198
        },
        {
          "step": 1910,
          "loss": 0.009016754105687141,
          "grad_norm": 0.29958606404502197
        },
        {
          "step": 1915,
          "loss": 0.12335427105426788,
          "grad_norm": 2.007323035215081
        },
        {
          "step": 1920,
          "loss": 0.01117309182882309,
          "grad_norm": 0.31465050888576046
        },
        {
          "step": 1925,
          "loss": 0.012544533237814903,
          "grad_norm": 0.43526134375072767
        },
        {
          "step": 1930,
          "loss": 0.05267481505870819,
          "grad_norm": 1.6408538815790539
        },
        {
          "step": 1935,
          "loss": 0.005928391590714455,
          "grad_norm": 0.1715593876079384
        },
        {
          "step": 1940,
          "loss": 0.009109090082347393,
          "grad_norm": 0.39315211433634845
        },
        {
          "step": 1945,
          "loss": 0.005861187353730202,
          "grad_norm": 0.2735765186563162
        },
        {
          "step": 1950,
          "loss": 0.0171566940844059,
          "grad_norm": 0.5313651171632628
        },
        {
          "step": 1955,
          "loss": 0.006024799309670925,
          "grad_norm": 0.2817577576943221
        },
        {
          "step": 1960,
          "loss": 0.021314701065421104,
          "grad_norm": 0.9026898553529892
        },
        {
          "step": 1965,
          "loss": 0.016390684992074966,
          "grad_norm": 0.5880584621683573
        },
        {
          "step": 1970,
          "loss": 0.0045743887312710285,
          "grad_norm": 0.17624469690284153
        },
        {
          "step": 1975,
          "loss": 0.03377768024802208,
          "grad_norm": 1.1317370708016747
        },
        {
          "step": 1980,
          "loss": 0.01148285623639822,
          "grad_norm": 0.4750358706088756
        },
        {
          "step": 1985,
          "loss": 0.005892313551157713,
          "grad_norm": 0.33553349856681397
        },
        {
          "step": 1990,
          "loss": 0.0860178992152214,
          "grad_norm": 1.555616587444468
        },
        {
          "step": 1995,
          "loss": 0.008463436737656593,
          "grad_norm": 0.3623427233218788
        },
        {
          "step": 2000,
          "loss": 0.09477053582668304,
          "grad_norm": 1.8033988323590109
        }
      ],
      "final_accuracy": 0.9922,
      "checkpoint_path": "/content/content/checkpoints/cnn_deep_mnist/checkpoint_step_02000.pt",
      "elapsed_time": 20.018584966659546
    },
    {
      "experiment_name": "mlp_narrow_mnist",
      "measurements": [
        {
          "step": 1000,
          "loss": 0.1787329465150833,
          "grad_norm": 2.337926484833759
        },
        {
          "step": 1005,
          "loss": 0.18785235285758972,
          "grad_norm": 1.582614770529684
        },
        {
          "step": 1010,
          "loss": 0.4730665683746338,
          "grad_norm": 2.4479344390471924
        },
        {
          "step": 1015,
          "loss": 0.12203717231750488,
          "grad_norm": 0.9375412960924862
        },
        {
          "step": 1020,
          "loss": 0.07744871079921722,
          "grad_norm": 0.8807527795256148
        },
        {
          "step": 1025,
          "loss": 0.27981919050216675,
          "grad_norm": 2.3851516691968566
        },
        {
          "step": 1030,
          "loss": 0.20691345632076263,
          "grad_norm": 2.2551020360087444
        },
        {
          "step": 1035,
          "loss": 0.14884063601493835,
          "grad_norm": 1.438461948513849
        },
        {
          "step": 1040,
          "loss": 0.4394490718841553,
          "grad_norm": 1.7784187814537702
        },
        {
          "step": 1045,
          "loss": 0.411787211894989,
          "grad_norm": 2.2084066152664827
        },
        {
          "step": 1050,
          "loss": 0.21088361740112305,
          "grad_norm": 1.9039464887720003
        },
        {
          "step": 1055,
          "loss": 0.4535325765609741,
          "grad_norm": 4.007420678351936
        },
        {
          "step": 1060,
          "loss": 0.2871208190917969,
          "grad_norm": 2.7541659800095015
        },
        {
          "step": 1065,
          "loss": 0.13909310102462769,
          "grad_norm": 1.7341739955098896
        },
        {
          "step": 1070,
          "loss": 0.162841796875,
          "grad_norm": 1.5617929567213023
        },
        {
          "step": 1075,
          "loss": 0.10731393098831177,
          "grad_norm": 1.3736219574636177
        },
        {
          "step": 1080,
          "loss": 0.15181972086429596,
          "grad_norm": 1.4998889669902875
        },
        {
          "step": 1085,
          "loss": 0.15154936909675598,
          "grad_norm": 1.7646188178883064
        },
        {
          "step": 1090,
          "loss": 0.21282994747161865,
          "grad_norm": 1.5673236215514843
        },
        {
          "step": 1095,
          "loss": 0.29889246821403503,
          "grad_norm": 2.318812280073361
        },
        {
          "step": 1100,
          "loss": 0.1867036521434784,
          "grad_norm": 2.33403128917277
        },
        {
          "step": 1105,
          "loss": 0.25628426671028137,
          "grad_norm": 2.6391128458513324
        },
        {
          "step": 1110,
          "loss": 0.09963364154100418,
          "grad_norm": 1.1390437179589734
        },
        {
          "step": 1115,
          "loss": 0.2158428132534027,
          "grad_norm": 1.5165740313365237
        },
        {
          "step": 1120,
          "loss": 0.2272929549217224,
          "grad_norm": 2.3531091286191548
        },
        {
          "step": 1125,
          "loss": 0.22713345289230347,
          "grad_norm": 2.2628509950461364
        },
        {
          "step": 1130,
          "loss": 0.16151517629623413,
          "grad_norm": 1.9626464433230575
        },
        {
          "step": 1135,
          "loss": 0.3673056364059448,
          "grad_norm": 3.0973421149442504
        },
        {
          "step": 1140,
          "loss": 0.21601590514183044,
          "grad_norm": 1.3208605140542535
        },
        {
          "step": 1145,
          "loss": 0.15315447747707367,
          "grad_norm": 1.5534291675614786
        },
        {
          "step": 1150,
          "loss": 0.18870647251605988,
          "grad_norm": 1.3336910046596295
        },
        {
          "step": 1155,
          "loss": 0.24055171012878418,
          "grad_norm": 1.787146635825242
        },
        {
          "step": 1160,
          "loss": 0.28511863946914673,
          "grad_norm": 2.080801737325459
        },
        {
          "step": 1165,
          "loss": 0.1863076388835907,
          "grad_norm": 1.7371095594895263
        },
        {
          "step": 1170,
          "loss": 0.22176924347877502,
          "grad_norm": 2.101342015045231
        },
        {
          "step": 1175,
          "loss": 0.3113815486431122,
          "grad_norm": 1.8696947606358008
        },
        {
          "step": 1180,
          "loss": 0.09235310554504395,
          "grad_norm": 1.462015939308664
        },
        {
          "step": 1185,
          "loss": 0.2737727761268616,
          "grad_norm": 1.2589249582160875
        },
        {
          "step": 1190,
          "loss": 0.07333802431821823,
          "grad_norm": 0.829372939029508
        },
        {
          "step": 1195,
          "loss": 0.4617590010166168,
          "grad_norm": 1.976765802281097
        },
        {
          "step": 1200,
          "loss": 0.28415948152542114,
          "grad_norm": 1.5475654734328712
        },
        {
          "step": 1205,
          "loss": 0.3054645359516144,
          "grad_norm": 1.9177462619508667
        },
        {
          "step": 1210,
          "loss": 0.21564437448978424,
          "grad_norm": 2.0925567046693416
        },
        {
          "step": 1215,
          "loss": 0.300210565328598,
          "grad_norm": 1.4016088194277934
        },
        {
          "step": 1220,
          "loss": 0.37157127261161804,
          "grad_norm": 2.445008160475452
        },
        {
          "step": 1225,
          "loss": 0.17710822820663452,
          "grad_norm": 1.773032475508903
        },
        {
          "step": 1230,
          "loss": 0.3378983736038208,
          "grad_norm": 2.7444708189066316
        },
        {
          "step": 1235,
          "loss": 0.17749793827533722,
          "grad_norm": 1.921827958766921
        },
        {
          "step": 1240,
          "loss": 0.186885267496109,
          "grad_norm": 2.0256997851863097
        },
        {
          "step": 1245,
          "loss": 0.1936088651418686,
          "grad_norm": 2.12606217442799
        },
        {
          "step": 1250,
          "loss": 0.2776593863964081,
          "grad_norm": 1.6989420728381086
        },
        {
          "step": 1255,
          "loss": 0.3303922414779663,
          "grad_norm": 1.4800904065538059
        },
        {
          "step": 1260,
          "loss": 0.25710922479629517,
          "grad_norm": 1.4375075965253727
        },
        {
          "step": 1265,
          "loss": 0.19018858671188354,
          "grad_norm": 1.4456744713313285
        },
        {
          "step": 1270,
          "loss": 0.1627320647239685,
          "grad_norm": 1.40896774209116
        },
        {
          "step": 1275,
          "loss": 0.4291347861289978,
          "grad_norm": 2.1346578456891114
        },
        {
          "step": 1280,
          "loss": 0.1686055213212967,
          "grad_norm": 1.875681847112458
        },
        {
          "step": 1285,
          "loss": 0.19474440813064575,
          "grad_norm": 2.3214070765383727
        },
        {
          "step": 1290,
          "loss": 0.3482152223587036,
          "grad_norm": 2.4903752648292183
        },
        {
          "step": 1295,
          "loss": 0.1437319666147232,
          "grad_norm": 2.0475563952925118
        },
        {
          "step": 1300,
          "loss": 0.20928321778774261,
          "grad_norm": 1.5351645479869054
        },
        {
          "step": 1305,
          "loss": 0.307818740606308,
          "grad_norm": 2.17261463617423
        },
        {
          "step": 1310,
          "loss": 0.15813587605953217,
          "grad_norm": 1.486794047560809
        },
        {
          "step": 1315,
          "loss": 0.2358790934085846,
          "grad_norm": 2.0327621290237117
        },
        {
          "step": 1320,
          "loss": 0.2946632504463196,
          "grad_norm": 2.0774611671160326
        },
        {
          "step": 1325,
          "loss": 0.2886117994785309,
          "grad_norm": 1.5936848845018328
        },
        {
          "step": 1330,
          "loss": 0.239882230758667,
          "grad_norm": 1.5607189804501074
        },
        {
          "step": 1335,
          "loss": 0.2387063056230545,
          "grad_norm": 1.3948364705247855
        },
        {
          "step": 1340,
          "loss": 0.195302814245224,
          "grad_norm": 1.4882448897223062
        },
        {
          "step": 1345,
          "loss": 0.24031968414783478,
          "grad_norm": 2.269158614188525
        },
        {
          "step": 1350,
          "loss": 0.11170946061611176,
          "grad_norm": 1.3139418365290545
        },
        {
          "step": 1355,
          "loss": 0.4928920865058899,
          "grad_norm": 3.1122955941412167
        },
        {
          "step": 1360,
          "loss": 0.10019693523645401,
          "grad_norm": 0.9598528157632499
        },
        {
          "step": 1365,
          "loss": 0.2651262581348419,
          "grad_norm": 2.6480663673252605
        },
        {
          "step": 1370,
          "loss": 0.12113175541162491,
          "grad_norm": 1.2559931293048208
        },
        {
          "step": 1375,
          "loss": 0.13097155094146729,
          "grad_norm": 1.42185230208225
        },
        {
          "step": 1380,
          "loss": 0.4069148302078247,
          "grad_norm": 1.854384288716075
        },
        {
          "step": 1385,
          "loss": 0.2138473391532898,
          "grad_norm": 1.8701185413911072
        },
        {
          "step": 1390,
          "loss": 0.21536974608898163,
          "grad_norm": 2.997729089541808
        },
        {
          "step": 1395,
          "loss": 0.2172362059354782,
          "grad_norm": 2.3882690681783214
        },
        {
          "step": 1400,
          "loss": 0.4302977919578552,
          "grad_norm": 2.1897671174208133
        },
        {
          "step": 1405,
          "loss": 0.48678895831108093,
          "grad_norm": 2.3146517271433225
        },
        {
          "step": 1410,
          "loss": 0.27060192823410034,
          "grad_norm": 1.799527628172761
        },
        {
          "step": 1415,
          "loss": 0.16906096041202545,
          "grad_norm": 1.6538474804359122
        },
        {
          "step": 1420,
          "loss": 0.24002483487129211,
          "grad_norm": 1.5433782959646085
        },
        {
          "step": 1425,
          "loss": 0.11833775043487549,
          "grad_norm": 1.163303978948337
        },
        {
          "step": 1430,
          "loss": 0.27101731300354004,
          "grad_norm": 1.444169702175711
        },
        {
          "step": 1435,
          "loss": 0.19214597344398499,
          "grad_norm": 1.5969036192303419
        },
        {
          "step": 1440,
          "loss": 0.27142706513404846,
          "grad_norm": 2.1781247523688543
        },
        {
          "step": 1445,
          "loss": 0.37695106863975525,
          "grad_norm": 2.982421687381034
        },
        {
          "step": 1450,
          "loss": 0.3118423521518707,
          "grad_norm": 1.6405855978057218
        },
        {
          "step": 1455,
          "loss": 0.27149447798728943,
          "grad_norm": 2.5443367448302228
        },
        {
          "step": 1460,
          "loss": 0.35696014761924744,
          "grad_norm": 2.0774891283504595
        },
        {
          "step": 1465,
          "loss": 0.4329347014427185,
          "grad_norm": 1.7848855654751985
        },
        {
          "step": 1470,
          "loss": 0.231892392039299,
          "grad_norm": 2.6145619922898797
        },
        {
          "step": 1475,
          "loss": 0.284863144159317,
          "grad_norm": 2.550392269298393
        },
        {
          "step": 1480,
          "loss": 0.10848185420036316,
          "grad_norm": 2.188083590813033
        },
        {
          "step": 1485,
          "loss": 0.1671430617570877,
          "grad_norm": 1.4276181032959168
        },
        {
          "step": 1490,
          "loss": 0.2573392391204834,
          "grad_norm": 3.1345978713384195
        },
        {
          "step": 1495,
          "loss": 0.24676772952079773,
          "grad_norm": 2.6188074242721187
        },
        {
          "step": 1500,
          "loss": 0.5589322447776794,
          "grad_norm": 2.9274453696129834
        },
        {
          "step": 1505,
          "loss": 0.1466885507106781,
          "grad_norm": 1.4427591792041763
        },
        {
          "step": 1510,
          "loss": 0.31977277994155884,
          "grad_norm": 2.2506851516683257
        },
        {
          "step": 1515,
          "loss": 0.22852209210395813,
          "grad_norm": 1.6151243698989568
        },
        {
          "step": 1520,
          "loss": 0.15778040885925293,
          "grad_norm": 1.3627754806617984
        },
        {
          "step": 1525,
          "loss": 0.20982971787452698,
          "grad_norm": 1.814686402510359
        },
        {
          "step": 1530,
          "loss": 0.20743709802627563,
          "grad_norm": 1.1224947524098798
        },
        {
          "step": 1535,
          "loss": 0.20966395735740662,
          "grad_norm": 2.043025465971131
        },
        {
          "step": 1540,
          "loss": 0.21410301327705383,
          "grad_norm": 2.303735831047822
        },
        {
          "step": 1545,
          "loss": 0.17282900214195251,
          "grad_norm": 1.8726010021582666
        },
        {
          "step": 1550,
          "loss": 0.10789620876312256,
          "grad_norm": 1.1710558131136317
        },
        {
          "step": 1555,
          "loss": 0.25459024310112,
          "grad_norm": 1.6900444472334306
        },
        {
          "step": 1560,
          "loss": 0.20426225662231445,
          "grad_norm": 2.4183607300720693
        },
        {
          "step": 1565,
          "loss": 0.1541498750448227,
          "grad_norm": 2.238236083227608
        },
        {
          "step": 1570,
          "loss": 0.17244143784046173,
          "grad_norm": 1.7033911938665705
        },
        {
          "step": 1575,
          "loss": 0.3376964330673218,
          "grad_norm": 2.136864391048369
        },
        {
          "step": 1580,
          "loss": 0.15939046442508698,
          "grad_norm": 1.8424762447344578
        },
        {
          "step": 1585,
          "loss": 0.21600429713726044,
          "grad_norm": 1.8151737199265732
        },
        {
          "step": 1590,
          "loss": 0.15071752667427063,
          "grad_norm": 1.1879614158021405
        },
        {
          "step": 1595,
          "loss": 0.036897510290145874,
          "grad_norm": 0.5829465188034887
        },
        {
          "step": 1600,
          "loss": 0.15735764801502228,
          "grad_norm": 1.4182212854978073
        },
        {
          "step": 1605,
          "loss": 0.12790367007255554,
          "grad_norm": 1.562217582243682
        },
        {
          "step": 1610,
          "loss": 0.16878359019756317,
          "grad_norm": 2.0786910789647335
        },
        {
          "step": 1615,
          "loss": 0.12481905519962311,
          "grad_norm": 1.1779647740277857
        },
        {
          "step": 1620,
          "loss": 0.3200317919254303,
          "grad_norm": 2.2084160294950137
        },
        {
          "step": 1625,
          "loss": 0.23750613629817963,
          "grad_norm": 2.012584934507067
        },
        {
          "step": 1630,
          "loss": 0.13312268257141113,
          "grad_norm": 1.676253186358143
        },
        {
          "step": 1635,
          "loss": 0.32960596680641174,
          "grad_norm": 2.3558319098683875
        },
        {
          "step": 1640,
          "loss": 0.26947489380836487,
          "grad_norm": 1.9444381860188413
        },
        {
          "step": 1645,
          "loss": 0.17968207597732544,
          "grad_norm": 1.863354916846226
        },
        {
          "step": 1650,
          "loss": 0.39366060495376587,
          "grad_norm": 3.076174415204117
        },
        {
          "step": 1655,
          "loss": 0.1611049473285675,
          "grad_norm": 1.5327011299689675
        },
        {
          "step": 1660,
          "loss": 0.18889790773391724,
          "grad_norm": 1.7697252107634265
        },
        {
          "step": 1665,
          "loss": 0.17356924712657928,
          "grad_norm": 1.5111809382708894
        },
        {
          "step": 1670,
          "loss": 0.2872525155544281,
          "grad_norm": 2.0005969626185345
        },
        {
          "step": 1675,
          "loss": 0.12407524883747101,
          "grad_norm": 1.1417217998421836
        },
        {
          "step": 1680,
          "loss": 0.14446517825126648,
          "grad_norm": 1.4562474221159112
        },
        {
          "step": 1685,
          "loss": 0.08813387155532837,
          "grad_norm": 1.4423821987950507
        },
        {
          "step": 1690,
          "loss": 0.2073887139558792,
          "grad_norm": 2.275362176613858
        },
        {
          "step": 1695,
          "loss": 0.16679984331130981,
          "grad_norm": 1.6248117694869537
        },
        {
          "step": 1700,
          "loss": 0.21869269013404846,
          "grad_norm": 1.1547444523944415
        },
        {
          "step": 1705,
          "loss": 0.2781713604927063,
          "grad_norm": 1.8418567841774296
        },
        {
          "step": 1710,
          "loss": 0.20399540662765503,
          "grad_norm": 1.7214739379043158
        },
        {
          "step": 1715,
          "loss": 0.25312381982803345,
          "grad_norm": 2.4583272278865294
        },
        {
          "step": 1720,
          "loss": 0.27544769644737244,
          "grad_norm": 1.4466866686750048
        },
        {
          "step": 1725,
          "loss": 0.19371181726455688,
          "grad_norm": 1.7079678319492717
        },
        {
          "step": 1730,
          "loss": 0.23363205790519714,
          "grad_norm": 1.7346544199922604
        },
        {
          "step": 1735,
          "loss": 0.2874718904495239,
          "grad_norm": 2.0085324569081795
        },
        {
          "step": 1740,
          "loss": 0.19077898561954498,
          "grad_norm": 2.15279020828628
        },
        {
          "step": 1745,
          "loss": 0.07794323563575745,
          "grad_norm": 0.8952757589676581
        },
        {
          "step": 1750,
          "loss": 0.27791327238082886,
          "grad_norm": 1.600556003169256
        },
        {
          "step": 1755,
          "loss": 0.22907187044620514,
          "grad_norm": 2.3707132543118496
        },
        {
          "step": 1760,
          "loss": 0.20549194514751434,
          "grad_norm": 2.1088708284736475
        },
        {
          "step": 1765,
          "loss": 0.1785586178302765,
          "grad_norm": 1.2697721858849635
        },
        {
          "step": 1770,
          "loss": 0.1259564459323883,
          "grad_norm": 1.4528415424254495
        },
        {
          "step": 1775,
          "loss": 0.16561031341552734,
          "grad_norm": 2.0360025122744547
        },
        {
          "step": 1780,
          "loss": 0.2112373560667038,
          "grad_norm": 2.224576815920282
        },
        {
          "step": 1785,
          "loss": 0.2836930751800537,
          "grad_norm": 2.1751840990067044
        },
        {
          "step": 1790,
          "loss": 0.2487122118473053,
          "grad_norm": 2.534657159254401
        },
        {
          "step": 1795,
          "loss": 0.12024277448654175,
          "grad_norm": 1.2346954839416269
        },
        {
          "step": 1800,
          "loss": 0.12425123155117035,
          "grad_norm": 1.2714167304450679
        },
        {
          "step": 1805,
          "loss": 0.10440954566001892,
          "grad_norm": 1.258407226189709
        },
        {
          "step": 1810,
          "loss": 0.35659167170524597,
          "grad_norm": 2.3226689781112846
        },
        {
          "step": 1815,
          "loss": 0.23269200325012207,
          "grad_norm": 1.94831041317476
        },
        {
          "step": 1820,
          "loss": 0.19718196988105774,
          "grad_norm": 1.7580543013405843
        },
        {
          "step": 1825,
          "loss": 0.13532227277755737,
          "grad_norm": 1.1864572214064906
        },
        {
          "step": 1830,
          "loss": 0.24061219394207,
          "grad_norm": 1.8354744527053521
        },
        {
          "step": 1835,
          "loss": 0.30374830961227417,
          "grad_norm": 3.2888998034077797
        },
        {
          "step": 1840,
          "loss": 0.10335984081029892,
          "grad_norm": 1.030389966833402
        },
        {
          "step": 1845,
          "loss": 0.13611528277397156,
          "grad_norm": 2.1881059735532498
        },
        {
          "step": 1850,
          "loss": 0.14082016050815582,
          "grad_norm": 1.6958058773883382
        },
        {
          "step": 1855,
          "loss": 0.23609714210033417,
          "grad_norm": 2.761995314562974
        },
        {
          "step": 1860,
          "loss": 0.2328520566225052,
          "grad_norm": 1.5939202616838006
        },
        {
          "step": 1865,
          "loss": 0.21335512399673462,
          "grad_norm": 1.6708911182691082
        },
        {
          "step": 1870,
          "loss": 0.16894574463367462,
          "grad_norm": 1.722151385536093
        },
        {
          "step": 1875,
          "loss": 0.16899095475673676,
          "grad_norm": 1.6017549685393282
        },
        {
          "step": 1880,
          "loss": 0.1577882170677185,
          "grad_norm": 1.4621259742355526
        },
        {
          "step": 1885,
          "loss": 0.13541117310523987,
          "grad_norm": 1.1215736304954993
        },
        {
          "step": 1890,
          "loss": 0.24273322522640228,
          "grad_norm": 1.6519369378860453
        },
        {
          "step": 1895,
          "loss": 0.14996619522571564,
          "grad_norm": 1.6375897157145756
        },
        {
          "step": 1900,
          "loss": 0.2096371054649353,
          "grad_norm": 1.5293673294777819
        },
        {
          "step": 1905,
          "loss": 0.1404818594455719,
          "grad_norm": 1.1837481062429815
        },
        {
          "step": 1910,
          "loss": 0.20107576251029968,
          "grad_norm": 1.7149742589051034
        },
        {
          "step": 1915,
          "loss": 0.14327824115753174,
          "grad_norm": 1.5289287601090156
        },
        {
          "step": 1920,
          "loss": 0.13818176090717316,
          "grad_norm": 1.7727393951199815
        },
        {
          "step": 1925,
          "loss": 0.13241922855377197,
          "grad_norm": 2.3439578572255297
        },
        {
          "step": 1930,
          "loss": 0.27748122811317444,
          "grad_norm": 2.1090581181204664
        },
        {
          "step": 1935,
          "loss": 0.1351727396249771,
          "grad_norm": 1.7577117936806406
        },
        {
          "step": 1940,
          "loss": 0.14345505833625793,
          "grad_norm": 1.6975990096623903
        },
        {
          "step": 1945,
          "loss": 0.04893887788057327,
          "grad_norm": 0.9116321377018276
        },
        {
          "step": 1950,
          "loss": 0.3131624758243561,
          "grad_norm": 2.5361212763839083
        },
        {
          "step": 1955,
          "loss": 0.30819982290267944,
          "grad_norm": 1.920329076015131
        },
        {
          "step": 1960,
          "loss": 0.21962429583072662,
          "grad_norm": 1.4143513840662818
        },
        {
          "step": 1965,
          "loss": 0.23629230260849,
          "grad_norm": 1.2586659938602713
        },
        {
          "step": 1970,
          "loss": 0.11029604077339172,
          "grad_norm": 0.9568715276630624
        },
        {
          "step": 1975,
          "loss": 0.09303663671016693,
          "grad_norm": 1.10140531334438
        },
        {
          "step": 1980,
          "loss": 0.2815067172050476,
          "grad_norm": 2.912865766180291
        },
        {
          "step": 1985,
          "loss": 0.0707729160785675,
          "grad_norm": 0.906267820131415
        },
        {
          "step": 1990,
          "loss": 0.3071979582309723,
          "grad_norm": 2.1116811100659434
        },
        {
          "step": 1995,
          "loss": 0.20482860505580902,
          "grad_norm": 1.8366120532875212
        },
        {
          "step": 2000,
          "loss": 0.2408912181854248,
          "grad_norm": 2.1818214358736934
        }
      ],
      "final_accuracy": 0.9465,
      "checkpoint_path": "/content/content/checkpoints/mlp_narrow_mnist/checkpoint_step_02000.pt",
      "elapsed_time": 18.885535717010498
    }
  ]
}