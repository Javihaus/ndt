# -*- coding: utf-8 -*-
"""TransitionPhase_Adam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11VeREkNn70tgYtPCnMZYTfWBYizgEzk7
"""

#!pip install torch torchvision -q

"""
PHASE SPACE EXPANSION VALIDATION
Runtime: ~2 hours on A100
Goal: Determine if discrete jumps are real or artifacts

Experiments:
1. Sampling frequency test
2. Multiple estimators test
3. Correlation with learning events
4. Activation space analysis (KEY TEST)
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from typing import Dict, List, Tuple
import pickle

# ============================================================================
# SETUP
# ============================================================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Device: {device}")

# Fast dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)

# ============================================================================
# DIMENSIONALITY ESTIMATORS
# ============================================================================

class DimensionalityEstimators:
    """Multiple ways to estimate effective dimensionality"""

    @staticmethod
    def stable_rank(matrix: torch.Tensor) -> float:
        """Stable rank: ||A||_F^2 / ||A||_2^2"""
        S = torch.linalg.svdvals(matrix.float())
        return (S.sum() ** 2 / (S ** 2).sum()).item()

    @staticmethod
    def participation_ratio(matrix: torch.Tensor) -> float:
        """Participation ratio: (sum σ)^2 / sum(σ^2)"""
        S = torch.linalg.svdvals(matrix.float())
        return (S.sum() ** 2 / (S ** 2).sum()).item()

    @staticmethod
    def pca_90(matrix: torch.Tensor) -> float:
        """Number of components for 90% variance"""
        S = torch.linalg.svdvals(matrix.float())
        S_squared = S ** 2
        cumsum = torch.cumsum(S_squared / S_squared.sum(), dim=0)
        return (cumsum < 0.90).sum().item() + 1

    @staticmethod
    def nuclear_norm_ratio(matrix: torch.Tensor) -> float:
        """Nuclear norm / Frobenius norm"""
        S = torch.linalg.svdvals(matrix.float())
        nuclear = S.sum()
        frobenius = torch.sqrt((S ** 2).sum())
        return (nuclear / frobenius).item()

# ============================================================================
# ACTIVATION ANALYZER
# ============================================================================

class ActivationAnalyzer:
    """Analyze representation changes in activation space"""

    def __init__(self, model: nn.Module, layer_name: str):
        self.activations = []
        self.layer_name = layer_name

        # Register hook
        for name, module in model.named_modules():
            if name == layer_name:
                module.register_forward_hook(self.hook)
                break

    def hook(self, module, input, output):
        self.activations.append(output.detach().cpu())

    def compute_statistics(self, dataloader, device) -> Dict:
        """Compute activation statistics"""
        self.activations = []

        with torch.no_grad():
            for inputs, _ in dataloader:
                inputs = inputs.to(device)
                _ = self.model(inputs)  # Trigger hook

        # Concatenate all activations
        all_acts = torch.cat(self.activations, dim=0)
        all_acts = all_acts.reshape(all_acts.size(0), -1)  # Flatten spatial dims

        return {
            'mean': all_acts.mean(0),
            'std': all_acts.std(0),
            'effective_dim': DimensionalityEstimators.stable_rank(all_acts.T),
            'sparsity': (all_acts.abs() < 0.1).float().mean().item()
        }

# ============================================================================
# NETWORK
# ============================================================================

class SimpleResNet(nn.Module):
    """Minimal ResNet for fast training"""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()

        # Residual blocks
        self.layer1 = self._make_layer(64, 64, 2)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, 10)

    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):
        layers = []
        layers.append(nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1))
        layers.append(nn.BatchNorm2d(out_channels))
        layers.append(nn.ReLU())

        for _ in range(num_blocks - 1):
            layers.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU())

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

# ============================================================================
# METRICS TRACKER
# ============================================================================

class MetricsTracker:
    """Track all metrics during training"""

    def __init__(self, model: nn.Module, testloader, device):
        self.model = model
        self.testloader = testloader
        self.device = device
        self.metrics = {
            'step': [],
            'loss': [],
            'grad_norm': [],
            'weight_norm': [],
            # Multiple dimensionality estimators
            'dim_stable_rank': [],
            'dim_participation': [],
            'dim_pca90': [],
            'dim_nuclear': [],
            # Activation statistics
            'activation_dim': [],
            'activation_sparsity': [],
        }

        # Setup activation analyzer for penultimate layer
        self.act_analyzer = ActivationAnalyzer(model, 'layer3')
        self.act_analyzer.model = model

    def compute_metrics(self, step: int, loss: float, optimizer) -> Dict:
        """Compute all metrics at current step"""

        # Basic metrics
        self.metrics['step'].append(step)
        self.metrics['loss'].append(loss)

        # Gradient norm
        total_grad_norm = 0.0
        for p in self.model.parameters():
            if p.grad is not None:
                total_grad_norm += p.grad.norm().item() ** 2
        self.metrics['grad_norm'].append(np.sqrt(total_grad_norm))

        # Weight norm
        total_weight_norm = 0.0
        for p in self.model.parameters():
            total_weight_norm += p.norm().item() ** 2
        self.metrics['weight_norm'].append(np.sqrt(total_weight_norm))

        # Compute effective dimensionality using MULTIPLE estimators
        # Use fc layer as proxy (fast to compute)
        W = self.model.fc.weight.detach().cpu()

        self.metrics['dim_stable_rank'].append(
            DimensionalityEstimators.stable_rank(W))
        self.metrics['dim_participation'].append(
            DimensionalityEstimators.participation_ratio(W))
        self.metrics['dim_pca90'].append(
            DimensionalityEstimators.pca_90(W))
        self.metrics['dim_nuclear'].append(
            DimensionalityEstimators.nuclear_norm_ratio(W))

        # Activation analysis (expensive, do less frequently)
        if step % 10 == 0:
            act_stats = self.act_analyzer.compute_statistics(self.testloader, self.device)
            self.metrics['activation_dim'].append(act_stats['effective_dim'])
            self.metrics['activation_sparsity'].append(act_stats['sparsity'])
        else:
            # Pad with None for alignment
            self.metrics['activation_dim'].append(None)
            self.metrics['activation_sparsity'].append(None)

        return self.metrics

# ============================================================================
# TRAINING LOOP WITH HIGH-FREQUENCY CHECKPOINTING
# ============================================================================

def train_with_tracking(checkpoint_freq: int = 5, num_epochs: int = 20):
    """
    Train with frequent metric tracking

    Args:
        checkpoint_freq: Steps between metric computation (default=5 for high freq)
        num_epochs: Number of training epochs
    """

    print(f"\n{'='*70}")
    print(f"EXPERIMENT: checkpoint_freq={checkpoint_freq}")
    print(f"{'='*70}\n")

    model = SimpleResNet().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    tracker = MetricsTracker(model, testloader, device)

    step = 0
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # Track metrics at checkpoint frequency
            if step % checkpoint_freq == 0:
                avg_loss = running_loss / (i + 1)
                tracker.compute_metrics(step, avg_loss, optimizer)

                if step % (checkpoint_freq * 10) == 0:
                    print(f"Step {step:4d} | Loss: {avg_loss:.4f} | "
                          f"Dim: {tracker.metrics['dim_stable_rank'][-1]:.2f}")

            step += 1

        print(f"Epoch {epoch+1}/{num_epochs} complete")

    return tracker.metrics

# ============================================================================
# ANALYSIS FUNCTIONS
# ============================================================================

def detect_jumps(timeseries: List[float], threshold: float = 2.0) -> Tuple[List[int], List[float]]:
    """Detect discrete jumps using z-score of first differences"""
    # Remove None values
    clean_series = [x for x in timeseries if x is not None]

    if len(clean_series) < 10:
        return [], []

    diffs = np.diff(clean_series)
    z_scores = np.abs((diffs - np.mean(diffs)) / (np.std(diffs) + 1e-8))

    jump_indices = np.where(z_scores > threshold)[0]
    jump_magnitudes = z_scores[jump_indices]

    return jump_indices.tolist(), jump_magnitudes.tolist()

def analyze_correlations(metrics: Dict) -> Dict:
    """Analyze correlations between different metrics"""

    correlations = {}

    # Test if dimensionality jumps correlate with:
    # 1. Loss changes
    # 2. Gradient norm changes
    # 3. Each other (cross-estimator validation)

    dim_metrics = ['dim_stable_rank', 'dim_participation', 'dim_pca90', 'dim_nuclear']

    for dim_metric in dim_metrics:
        # Correlation with loss
        loss_corr, loss_p = stats.spearmanr(metrics[dim_metric], metrics['loss'])
        correlations[f'{dim_metric}_loss'] = (loss_corr, loss_p)

        # Correlation with gradient norm
        grad_corr, grad_p = stats.spearmanr(metrics[dim_metric], metrics['grad_norm'])
        correlations[f'{dim_metric}_grad'] = (grad_corr, grad_p)

    # Cross-estimator correlations
    for i, dim1 in enumerate(dim_metrics):
        for dim2 in dim_metrics[i+1:]:
            corr, p = stats.spearmanr(metrics[dim1], metrics[dim2])
            correlations[f'{dim1}_vs_{dim2}'] = (corr, p)

    return correlations

def plot_results(metrics_low_freq: Dict, metrics_high_freq: Dict):
    """Plot comprehensive results"""

    fig, axes = plt.subplots(4, 2, figsize=(16, 16))

    # Plot 1: Sampling frequency comparison
    ax = axes[0, 0]
    ax.plot(metrics_low_freq['step'], metrics_low_freq['dim_stable_rank'],
            'o-', label='Low freq (every 50 steps)', alpha=0.7)
    ax.plot(metrics_high_freq['step'], metrics_high_freq['dim_stable_rank'],
            '.-', label='High freq (every 5 steps)', alpha=0.7)
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Stable Rank')
    ax.set_title('SAMPLING FREQUENCY TEST')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 2: Multiple estimators
    ax = axes[0, 1]
    estimators = ['dim_stable_rank', 'dim_participation', 'dim_pca90', 'dim_nuclear']
    for est in estimators:
        # Normalize for comparison
        values = np.array(metrics_high_freq[est])
        normalized = (values - values.min()) / (values.max() - values.min() + 1e-8)
        ax.plot(metrics_high_freq['step'], normalized, label=est.replace('dim_', ''))
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Normalized Dimensionality')
    ax.set_title('MULTIPLE ESTIMATORS TEST')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 3: Loss correlation
    ax = axes[1, 0]
    ax2 = ax.twinx()
    ax.plot(metrics_high_freq['step'], metrics_high_freq['dim_stable_rank'],
            'b-', label='Dimensionality')
    ax2.plot(metrics_high_freq['step'], metrics_high_freq['loss'],
             'r-', label='Loss', alpha=0.7)
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Dimensionality', color='b')
    ax2.set_ylabel('Loss', color='r')
    ax.set_title('DIMENSIONALITY vs LOSS')
    ax.grid(True, alpha=0.3)

    # Plot 4: Gradient correlation
    ax = axes[1, 1]
    ax2 = ax.twinx()
    ax.plot(metrics_high_freq['step'], metrics_high_freq['dim_stable_rank'],
            'b-', label='Dimensionality')
    ax2.plot(metrics_high_freq['step'], metrics_high_freq['grad_norm'],
             'g-', label='Gradient Norm', alpha=0.7)
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Dimensionality', color='b')
    ax2.set_ylabel('Gradient Norm', color='g')
    ax.set_title('DIMENSIONALITY vs GRADIENTS')
    ax.grid(True, alpha=0.3)

    # Plot 5: Activation space analysis (KEY TEST)
    ax = axes[2, 0]
    # Filter out None values
    act_steps = [s for s, v in zip(metrics_high_freq['step'],
                                     metrics_high_freq['activation_dim']) if v is not None]
    act_dims = [v for v in metrics_high_freq['activation_dim'] if v is not None]

    ax.plot(act_steps, act_dims, 'o-', color='purple', linewidth=2)
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Activation Effective Dimensionality')
    ax.set_title('ACTIVATION SPACE ANALYSIS (KEY TEST)')
    ax.grid(True, alpha=0.3)

    # Plot 6: Weight space vs Activation space
    ax = axes[2, 1]
    weight_dims = [metrics_high_freq['dim_stable_rank'][i]
                   for i, v in enumerate(metrics_high_freq['activation_dim']) if v is not None]
    ax.scatter(weight_dims, act_dims, alpha=0.6)
    ax.set_xlabel('Weight Space Dimensionality')
    ax.set_ylabel('Activation Space Dimensionality')
    ax.set_title('WEIGHT vs ACTIVATION CORRELATION')
    ax.grid(True, alpha=0.3)

    # Plot 7: Jump detection
    ax = axes[3, 0]
    jumps_idx, jumps_mag = detect_jumps(metrics_high_freq['dim_stable_rank'], threshold=2.0)
    ax.plot(metrics_high_freq['step'], metrics_high_freq['dim_stable_rank'], 'b-', alpha=0.5)
    if jumps_idx:
        jump_steps = [metrics_high_freq['step'][i] for i in jumps_idx]
        jump_values = [metrics_high_freq['dim_stable_rank'][i] for i in jumps_idx]
        ax.scatter(jump_steps, jump_values, color='red', s=100, zorder=5,
                   label=f'{len(jumps_idx)} jumps detected (z>2)')
    ax.set_xlabel('Training Step')
    ax.set_ylabel('Dimensionality')
    ax.set_title(f'JUMP DETECTION (max z-score: {max(jumps_mag) if jumps_mag else 0:.2f})')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 8: Summary statistics
    ax = axes[3, 1]
    ax.axis('off')

    # Compute summary
    correlations = analyze_correlations(metrics_high_freq)

    summary_text = "VALIDATION SUMMARY\n" + "="*40 + "\n\n"

    # Test 1: Sampling artifact?
    jumps_low, _ = detect_jumps(metrics_low_freq['dim_stable_rank'], threshold=2.0)
    jumps_high, mags_high = detect_jumps(metrics_high_freq['dim_stable_rank'], threshold=2.0)

    summary_text += f"1. SAMPLING TEST:\n"
    summary_text += f"   Low freq: {len(jumps_low)} jumps\n"
    summary_text += f"   High freq: {len(jumps_high)} jumps\n"
    if len(jumps_high) > 0:
        summary_text += f"   Max z-score: {max(mags_high):.2f}\n"
    summary_text += f"   → {'REAL' if len(jumps_high) > 0 else 'ARTIFACT'}\n\n"

    # Test 2: Estimator robust?
    estimator_agreement = []
    for est in ['dim_participation', 'dim_pca90', 'dim_nuclear']:
        j, m = detect_jumps(metrics_high_freq[est], threshold=2.0)
        estimator_agreement.append(len(j) > 0)

    summary_text += f"2. ESTIMATOR TEST:\n"
    summary_text += f"   Stable rank: {len(jumps_high) > 0}\n"
    summary_text += f"   Other estimators: {sum(estimator_agreement)}/3 agree\n"
    summary_text += f"   → {'ROBUST' if sum(estimator_agreement) >= 2 else 'ESTIMATOR DEPENDENT'}\n\n"

    # Test 3: Correlates with learning?
    dim_loss_corr = correlations['dim_stable_rank_loss'][0]
    dim_grad_corr = correlations['dim_stable_rank_grad'][0]

    summary_text += f"3. CORRELATION TEST:\n"
    summary_text += f"   Dim-Loss: ρ={dim_loss_corr:.3f}\n"
    summary_text += f"   Dim-Grad: ρ={dim_grad_corr:.3f}\n"
    summary_text += f"   → {'LEARNING EVENT' if abs(dim_loss_corr) > 0.5 else 'INDEPENDENT'}\n\n"

    # Test 4: Activation space changes?
    if len(act_dims) > 2:
        act_jumps, act_mags = detect_jumps(act_dims, threshold=2.0)
        summary_text += f"4. ACTIVATION TEST (KEY):\n"
        summary_text += f"   Activation jumps: {len(act_jumps)}\n"
        summary_text += f"   Weight jumps: {len(jumps_high)}\n"
        if len(act_jumps) > 0 and len(jumps_high) > 0:
            summary_text += f"   → REAL PHENOMENON\n"
            summary_text += f"   (representations actually change)\n"
        else:
            summary_text += f"   → WEIGHT SPACE NOISE\n"
            summary_text += f"   (activations don't change)\n"
    else:
        summary_text += f"4. ACTIVATION TEST:\n   Insufficient data\n"

    ax.text(0.1, 0.9, summary_text, transform=ax.transAxes,
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    plt.savefig('validation_results.png', dpi=150, bbox_inches='tight')
    print("\nPlot saved to: validation_results.png")
    plt.show()

# ============================================================================
# MAIN EXPERIMENT
# ============================================================================

print("\n" + "="*70)
print("PHASE SPACE EXPANSION VALIDATION EXPERIMENT")
print("="*70)
print("\nThis will test 4 hypotheses:")
print("1. Are jumps sampling artifacts? (high vs low frequency)")
print("2. Are jumps estimator-dependent? (multiple measures)")
print("3. Do jumps correlate with learning events? (loss, gradients)")
print("4. Do ACTIVATIONS change during jumps? (KEY TEST)")
print("\nStarting experiments...\n")

# Experiment 1: Low frequency checkpoints (baseline, like your original)
print("\n" + "="*70)
print("Running LOW FREQUENCY experiment (baseline)...")
print("="*70)
metrics_low_freq = train_with_tracking(checkpoint_freq=50, num_epochs=20)

# Experiment 2: High frequency checkpoints (detect sampling artifacts)
print("\n" + "="*70)
print("Running HIGH FREQUENCY experiment (artifact test)...")
print("="*70)
metrics_high_freq = train_with_tracking(checkpoint_freq=5, num_epochs=20)

# Analysis
print("\n" + "="*70)
print("ANALYZING RESULTS...")
print("="*70)

plot_results(metrics_low_freq, metrics_high_freq)

# Save raw data
with open('validation_data.pkl', 'wb') as f:
    pickle.dump({
        'low_freq': metrics_low_freq,
        'high_freq': metrics_high_freq
    }, f)

print("\n" + "="*70)
print("VALIDATION COMPLETE")
print("="*70)
print("\nResults saved to:")
print("  - validation_results.png (plots)")
print("  - validation_data.pkl (raw data)")
print("\nLook at Plot 8 (bottom right) for the summary.")
print("The KEY test is Plot 5: Do activations actually change?")
print("\n" + "="*70)